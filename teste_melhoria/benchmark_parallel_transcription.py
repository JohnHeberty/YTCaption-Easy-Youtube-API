"""
Benchmark: Single-Core vs Multi-Core Whisper Transcription
Compara performance entre transcri√ß√£o sequencial e paralela por chunks.
"""
import asyncio
import time
from pathlib import Path
import sys

# Adicionar src ao path
sys.path.insert(0, str(Path(__file__).parent.parent))

from loguru import logger
from src.infrastructure.whisper.transcription_service import WhisperTranscriptionService
from teste_melhoria.whisper_parallel_service import WhisperParallelTranscriptionService
from src.domain.entities import VideoFile


async def benchmark_single_core(video_file: VideoFile, model: str = "base"):
    """
    Benchmark: Transcri√ß√£o single-core (m√©todo atual).
    """
    logger.info("=" * 60)
    logger.info("üîµ BENCHMARK: SINGLE-CORE TRANSCRIPTION")
    logger.info("=" * 60)
    
    service = WhisperTranscriptionService(
        model_name=model,
        device="cpu"
    )
    
    start_time = time.time()
    
    try:
        transcription = await service.transcribe(video_file, language="auto")
        
        elapsed_time = time.time() - start_time
        
        logger.info("‚úÖ Single-core transcription completed!")
        logger.info(f"‚è±Ô∏è  Total time: {elapsed_time:.2f}s")
        logger.info(f"üìù Segments: {len(transcription.segments)}")
        logger.info(f"üåç Language: {transcription.language}")
        
        return {
            'method': 'single-core',
            'time': elapsed_time,
            'segments': len(transcription.segments),
            'language': transcription.language,
            'transcription': transcription
        }
        
    except Exception as e:
        logger.error(f"‚ùå Single-core failed: {e}")
        return None


async def benchmark_multi_core(
    video_file: VideoFile,
    model: str = "base",
    num_workers: int = 4,
    chunk_duration: int = 120
):
    """
    Benchmark: Transcri√ß√£o multi-core com chunks paralelos.
    """
    logger.info("=" * 60)
    logger.info("üü¢ BENCHMARK: MULTI-CORE TRANSCRIPTION (PARALLEL CHUNKS)")
    logger.info("=" * 60)
    
    service = WhisperParallelTranscriptionService(
        model_name=model,
        device="cpu",
        num_workers=num_workers,
        chunk_duration_seconds=chunk_duration
    )
    
    start_time = time.time()
    
    try:
        transcription = await service.transcribe(video_file, language="auto")
        
        elapsed_time = time.time() - start_time
        
        logger.info("‚úÖ Multi-core transcription completed!")
        logger.info(f"‚è±Ô∏è  Total time: {elapsed_time:.2f}s")
        logger.info(f"üë∑ Workers: {num_workers}")
        logger.info(f"üì¶ Chunk duration: {chunk_duration}s")
        logger.info(f"üìù Segments: {len(transcription.segments)}")
        logger.info(f"üåç Language: {transcription.language}")
        
        return {
            'method': 'multi-core',
            'time': elapsed_time,
            'workers': num_workers,
            'chunk_duration': chunk_duration,
            'segments': len(transcription.segments),
            'language': transcription.language,
            'transcription': transcription
        }
        
    except Exception as e:
        logger.error(f"‚ùå Multi-core failed: {e}")
        return None


def compare_results(single_result, multi_result):
    """
    Compara resultados dos dois m√©todos.
    """
    logger.info("=" * 60)
    logger.info("üìä COMPARISON RESULTS")
    logger.info("=" * 60)
    
    if not single_result or not multi_result:
        logger.error("‚ùå Cannot compare - one or both methods failed")
        return
    
    # Tempos
    single_time = single_result['time']
    multi_time = multi_result['time']
    speedup = single_time / multi_time
    improvement_pct = ((single_time - multi_time) / single_time) * 100
    
    logger.info("\n‚è±Ô∏è  TIME COMPARISON:")
    logger.info(f"  Single-core: {single_time:.2f}s")
    logger.info(f"  Multi-core:  {multi_time:.2f}s ({multi_result['workers']} workers)")
    logger.info(f"  Speedup:     {speedup:.2f}x")
    logger.info(f"  Improvement: {improvement_pct:.1f}% faster")
    
    # Qualidade
    logger.info("\nüìù QUALITY COMPARISON:")
    logger.info(f"  Single-core segments: {single_result['segments']}")
    logger.info(f"  Multi-core segments:  {multi_result['segments']}")
    
    segment_diff = abs(single_result['segments'] - multi_result['segments'])
    segment_diff_pct = (segment_diff / single_result['segments']) * 100
    logger.info(f"  Difference:           {segment_diff} segments ({segment_diff_pct:.1f}%)")
    
    # Idioma
    logger.info("\nüåç LANGUAGE DETECTION:")
    logger.info(f"  Single-core: {single_result['language']}")
    logger.info(f"  Multi-core:  {multi_result['language']}")
    logger.info(f"  Match:       {'‚úÖ YES' if single_result['language'] == multi_result['language'] else '‚ùå NO'}")
    
    # Texto (primeiros 200 chars de cada)
    single_text = single_result['transcription'].get_full_text()[:200]
    multi_text = multi_result['transcription'].get_full_text()[:200]
    
    logger.info("\nüìÑ TEXT PREVIEW (first 200 chars):")
    logger.info(f"  Single: {single_text}...")
    logger.info(f"  Multi:  {multi_text}...")
    
    # Conclus√£o
    logger.info("\n" + "=" * 60)
    logger.info("üéØ CONCLUSION:")
    logger.info("=" * 60)
    
    if speedup > 1.5:
        logger.info(f"‚úÖ Multi-core is SIGNIFICANTLY FASTER ({speedup:.2f}x speedup)")
        logger.info(f"   Recommended for production with {multi_result['workers']} workers")
    elif speedup > 1.1:
        logger.info(f"‚úÖ Multi-core is FASTER ({speedup:.2f}x speedup)")
        logger.info(f"   Consider using for high-load scenarios")
    else:
        logger.info(f"‚ö†Ô∏è  Multi-core has MINIMAL improvement ({speedup:.2f}x)")
        logger.info(f"   Overhead may be too high - single-core recommended")
    
    if segment_diff_pct > 10:
        logger.warning(f"‚ö†Ô∏è  Quality difference is SIGNIFICANT ({segment_diff_pct:.1f}%)")
        logger.warning(f"   Review chunk boundaries and overlap strategies")
    else:
        logger.info(f"‚úÖ Quality is COMPARABLE ({segment_diff_pct:.1f}% difference)")


async def main():
    """
    Executa benchmark completo.
    """
    logger.info("üöÄ Starting Whisper Transcription Benchmark")
    logger.info("=" * 60)
    
    # Configura√ß√£o
    VIDEO_PATH = Path("./temp/test_video.mp3")  # Ajustar para v√≠deo de teste
    MODEL = "base"
    NUM_WORKERS = 4  # Ajustar conforme CPUs dispon√≠veis
    CHUNK_DURATION = 120  # 2 minutos por chunk
    
    # Verificar se arquivo existe
    if not VIDEO_PATH.exists():
        logger.error(f"‚ùå Test video not found: {VIDEO_PATH}")
        logger.info("üìù Please download a test video first:")
        logger.info("   Example: yt-dlp -o ./temp/test_video.mp4 'https://youtube.com/watch?v=...'")
        return
    
    # Criar VideoFile entity
    video_file = VideoFile(file_path=VIDEO_PATH)
    
    logger.info(f"üìπ Test video: {VIDEO_PATH.name}")
    logger.info(f"üì¶ Video size: {video_file.file_size_mb:.2f} MB")
    logger.info(f"ü§ñ Model: {MODEL}")
    logger.info(f"üë∑ Workers: {NUM_WORKERS}")
    logger.info(f"‚è±Ô∏è  Chunk duration: {CHUNK_DURATION}s")
    logger.info("")
    
    # Benchmark 1: Single-core
    single_result = await benchmark_single_core(video_file, MODEL)
    
    logger.info("\n‚è∏Ô∏è  Waiting 5 seconds before next test...\n")
    await asyncio.sleep(5)
    
    # Benchmark 2: Multi-core
    multi_result = await benchmark_multi_core(
        video_file,
        MODEL,
        NUM_WORKERS,
        CHUNK_DURATION
    )
    
    # Compara√ß√£o
    compare_results(single_result, multi_result)
    
    logger.info("\n" + "=" * 60)
    logger.info("‚úÖ Benchmark completed!")
    logger.info("=" * 60)


if __name__ == "__main__":
    # Configurar logger
    logger.remove()
    logger.add(
        sys.stdout,
        format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>",
        level="INFO"
    )
    
    # Executar benchmark
    asyncio.run(main())
