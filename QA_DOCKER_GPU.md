# QA_DOCKER_GPU ‚Äì Auditoria de Docker, CUDA e LOW_VRAM

**Data:** 28 de Novembro de 2025  
**Auditor:** QA Engineer + Dev S√™nior  
**Servi√ßo:** Audio Voice Service (F5-TTS / XTTS)  
**Vers√£o:** 2.0.0

---

## üìã Sum√°rio Executivo

### Problemas Cr√≠ticos Identificados

1. ‚úÖ **CONTAINERS DUPLICADOS**: 2 containers do mesmo servi√ßo rodando simultaneamente (sem conflito de portas detectado)
2. üî¥ **LOW_VRAM N√ÉO FUNCIONANDO**: Vari√°vel `LOW_VRAM=false` no container, mas `.env` tem `LOW_VRAM=true`
3. üî¥ **F5-TTS EM CPU**: Modelo rodando em CPU mesmo com GPU dispon√≠vel (CUDA 12.1 + GTX 1050 Ti 4GB)
4. ‚ö†Ô∏è **IMAGEM DOCKER DEPRECATED**: Base image CUDA 12.1 marcada para depreca√ß√£o
5. ‚ö†Ô∏è **REBUILDS SUJOS**: Imagens antigas (24h) sem prune sistem√°tico

---

## 1. Containers e Servi√ßos Duplicados

### 1.1. Observa√ß√£o

```bash
$ docker ps --filter "name=audio-voice"
NAMES                    STATUS                    PORTS                     IMAGE
audio-voice-api          Up 26 minutes (healthy)   0.0.0.0:8005->8005/tcp    audio-voice-audio-voice-service
audio-voice-celery       Up 16 minutes (healthy)   8005/tcp                  audio-voice-celery-worker
```

**Descobertas:**

- ‚úÖ **Apenas 2 containers ativos**: API + Celery Worker (arquitetura esperada)
- ‚úÖ **Nomes √∫nicos**: `audio-voice-api` e `audio-voice-celery`
- ‚úÖ **Sem conflito de portas**: API exp√µe 8005, Celery n√£o exp√µe porta
- ‚úÖ **Health checks OK**: Ambos containers healthy
- ‚ö†Ô∏è **Hor√°rios dessincronizados**: API subiu 10min antes do Celery (restart manual?)

### 1.2. Containers Criados

```
aa648ca462fe audio-voice-api     2025-11-27 16:55:33 UTC
dc5124ddca9d audio-voice-celery  2025-11-27 16:55:33 UTC
```

- **Idade**: ~24 horas (criados ontem √†s 16:55 UTC)
- **Imagens**: 16.3GB cada (muito grande - otimiz√°vel)

### 1.3. Causa de "M√∫ltiplos Containers"

**Hip√≥tese inicial do usu√°rio**: Containers duplicados por rebuild sujo.

**Realidade da auditoria**: 
- N√£o h√° containers duplicados do mesmo tipo
- Arquitetura **multi-container deliberada** (API + Worker)
- **Poss√≠vel confus√£o** do usu√°rio ao ver logs intercalados de `audio-voice-api` e `audio-voice-celery`

**Riscos Identificados:**

- ‚ö†Ô∏è **Restart ass√≠ncrono**: API e Celery n√£o reiniciam juntos (pode causar dessincronia de estado)
- ‚ö†Ô∏è **Containers √≥rf√£os**: Sem evid√™ncia no momento, mas aus√™ncia de rotina de prune

### 1.4. Docker Compose

**Arquivo**: `services/audio-voice/docker-compose.yml`

- ‚úÖ Define 2 servi√ßos: `audio-voice-service` e `celery-worker`
- ‚úÖ Usa `container_name` fixo (evita duplica√ß√£o acidental)
- ‚úÖ `restart: unless-stopped` configurado
- ‚ö†Ô∏è **Falta depends_on entre API e Celery**: API pode subir antes do worker estar pronto
- ‚ö†Ô∏è **Falta health check no Celery**: S√≥ API tem healthcheck (`CMD-SHELL curl`)

---

## 2. Pipeline de Build e Deploy

### 2.1. Dockerfile Analysis

**Base Image**: `nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04`

```dockerfile
FROM nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04
```

**‚ö†Ô∏è DEPRECATION WARNING ATIVA:**

```
*************************
** DEPRECATION NOTICE! **
*************************
THIS IMAGE IS DEPRECATED and is scheduled for DELETION.
```

**Problemas Identificados:**

1. üî¥ **Imagem base obsoleta**: CUDA 12.1 deprecada (current: 12.4+)
2. ‚ö†Ô∏è **Python 3.11 via deadsnakes PPA**: Instala√ß√£o manual (complexa, fr√°gil)
3. ‚ö†Ô∏è **Tamanho excessivo**: 16.3GB por imagem (2x containers = **32.6GB**)
4. ‚úÖ **Multi-stage ausente**: Poderia reduzir 40-50% do tamanho

### 2.2. Build Workflow

**Comandos identificados:**

```bash
# Build atual (inferido)
docker compose build

# Sem evid√™ncia de:
docker system prune
docker compose down --volumes
```

**Fragilidades:**

- ‚ùå **Sem rotina de prune**: Layers antigos acumulam
- ‚ùå **Sem cleanup de cache**: Build cache pode ter 50GB+
- ‚ùå **Sem build from scratch**: `--no-cache` nunca usado
- ‚ö†Ô∏è **Rebuilds sujos**: Imagens de 24h podem ter estado inconsistente

### 2.3. GPU Configuration em Docker Compose

```yaml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: all
          capabilities: [gpu]
```

‚úÖ **CORRETAMENTE CONFIGURADO**

```bash
$ docker inspect audio-voice-celery --format '{{json .HostConfig.Devices}}'
null  # ‚ö†Ô∏è Devices null em runtime (compose v2 usa deploy.resources)
```

```bash
$ docker exec audio-voice-celery nvidia-smi
NVIDIA GeForce GTX 1050 Ti, 4096 MiB, 2144 MiB
```

‚úÖ **GPU ACESS√çVEL DENTRO DO CONTAINER**

---

## 3. Uso de CUDA pelo F5-TTS

### 3.1. Device Configuration

**Vari√°veis de Ambiente (Container Celery):**

```bash
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility
CUDA_VISIBLE_DEVICES=0
FORCE_CUDA=1
LOW_VRAM=false  # ‚ö†Ô∏è PROBLEMA CR√çTICO
```

**Arquivo `.env` (Host):**

```bash
LOW_VRAM=true  # ‚úÖ Correto no arquivo
```

üî¥ **PROBLEMA CR√çTICO**: Vari√°vel `LOW_VRAM` n√£o sendo lida corretamente pelo container.

### 3.2. F5-TTS Device Selection

**C√≥digo**: `app/engines/f5tts_engine.py:115`

```python
# F5-TTS SEMPRE USA CPU para evitar OOM em GPUs pequenas (<8GB)
# XTTS j√° ocupa ~3.5GB, F5-TTS precisa ~2GB adicional
self.device = 'cpu'  # FIXME: Force CPU at√© implementar VRAM management
logger.info(f"F5TtsEngine initializing on device: {self.device} (forced CPU to avoid OOM)")
```

üî¥ **HARDCODED CPU**: F5-TTS ignora GPU completamente!

**Justificativa no c√≥digo:**
- GPU GTX 1050 Ti tem **4GB VRAM**
- XTTS ocupa ~3.5GB
- F5-TTS precisa ~2GB adicional
- **Total: 5.5GB > 4GB dispon√≠veis** ‚Üí OOM garantido

**Problema:** C√≥digo for√ßa CPU mesmo quando deveria usar GPU via LOW_VRAM mode!

### 3.3. XTTS vs F5-TTS VRAM Usage

**XTTS Engine** (`app/engines/xtts_engine.py:124`):

```python
# Device selection
self.device = self._select_device(device, fallback_to_cpu)
logger.info(f"XttsEngine initializing on device: {self.device}")
```

‚úÖ **XTTS respeita device auto-detect** (cuda se dispon√≠vel)

**F5-TTS Engine:**

‚ùå **F5-TTS for√ßa CPU** (hardcoded)

### 3.4. CUDA Availability

```bash
$ docker exec audio-voice-celery python -c "import torch; print(torch.cuda.is_available())"
True

$ docker exec audio-voice-celery python -c "import torch; print(torch.cuda.get_device_name(0))"
NVIDIA GeForce GTX 1050 Ti
```

‚úÖ **CUDA 100% FUNCIONAL** no container

**Conclus√£o:** F5-TTS poderia usar CUDA, mas **c√≥digo n√£o permite**.

---

## 4. L√≥gica LOW_VRAM

### 4.1. Onde LOW_VRAM √© Lida

**Config**: `app/config.py:51`

```python
'low_vram_mode': os.getenv('LOW_VRAM', 'false').lower() == 'true',
```

**VRAM Manager**: `app/vram_manager.py:37`

```python
self.low_vram_mode = settings.get('low_vram_mode', False)
```

### 4.2. Comportamento Desejado

**Quando `LOW_VRAM=true`:**

1. **Load**: Carregar modelo na GPU apenas para inference
2. **Synthesize**: Gerar √°udio
3. **Unload**: Mover modelo para CPU + `torch.cuda.empty_cache()`
4. **Repeat**: Pr√≥xima requisi√ß√£o repete ciclo

**Benef√≠cios:**
- Economia de 70-75% de VRAM
- Permite rodar XTTS + F5-TTS em GPU 4GB
- Aumenta lat√™ncia (+2-5s por requisi√ß√£o)

### 4.3. Comportamento Atual

**Logs do Container Celery:**

```bash
[2025-11-27 17:20:16] INFO: ‚ö° NORMAL MODE: Modelos permanecer√£o na VRAM
[2025-11-27 18:01:36] INFO: ‚ö° NORMAL MODE: Modelos permanecer√£o na VRAM
[2025-11-28 01:14:02] INFO: ‚ö° NORMAL MODE: Modelos permanecer√£o na VRAM
```

üî¥ **PROBLEMA**: LOW_VRAM **NUNCA ATIVADO**, mesmo com `.env` configurado!

### 4.4. Motivos do Problema

#### 4.4.1. Vari√°vel de Ambiente N√£o Propagada

**An√°lise:**

```bash
$ docker inspect audio-voice-celery | grep LOW_VRAM
LOW_VRAM=false  # ‚ö†Ô∏è Container tem valor ERRADO
```

**Arquivo `.env`:**

```bash
LOW_VRAM=true  # ‚úÖ Arquivo host tem valor CORRETO
```

**Docker Compose:**

```yaml
env_file:
  - .env
environment:
  - PYTHONPATH=/app
  - NVIDIA_VISIBLE_DEVICES=all
  - ...
  # ‚ùå LOW_VRAM n√£o est√° em "environment" override
```

**Problema:** `env_file` l√™ `.env`, mas:
1. Container foi buildado **antes** de `.env` ser editado
2. Container n√£o foi **recriado** ap√≥s mudan√ßa no `.env`
3. **Restart n√£o recarrega `env_file`** (apenas `down` + `up`)

#### 4.4.2. C√≥digo de Unload Implementado, Mas N√£o Usado

**VRAM Manager** (`app/vram_manager.py:89`):

```python
def _unload_model(self, model):
    """Descarrega modelo da VRAM."""
    try:
        # Mover modelo para CPU
        if hasattr(model, 'to'):
            model.to('cpu')
        elif hasattr(model, 'cpu'):
            model.cpu()
        
        # Limpar cache CUDA
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
        
        # Garbage collection
        gc.collect()
        
        logger.debug("‚úÖ Modelo descarregado com sucesso")
    
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erro ao descarregar modelo: {e}")
```

‚úÖ **C√ìDIGO CORRETO** para unload!

**Context Manager** (`app/vram_manager.py:46`):

```python
@contextmanager
def load_model(self, model_key: str, load_fn: Callable, *args, **kwargs):
    """Context manager para carregar modelo temporariamente."""
    model = None
    
    try:
        # Em modo LOW_VRAM, sempre carrega fresh
        if self.low_vram_mode:
            logger.debug(f"üîã Carregando modelo '{model_key}' (LOW VRAM)")
            model = load_fn(*args, **kwargs)
        else:
            # Usar cache
            if model_key not in self._model_cache:
                self._model_cache[model_key] = load_fn(*args, **kwargs)
            model = self._model_cache[model_key]
        
        yield model
    
    finally:
        # Descarregar apenas em modo LOW_VRAM
        if self.low_vram_mode and model is not None:
            logger.debug(f"üîã Descarregando modelo '{model_key}' da VRAM")
            self._unload_model(model)
            del model
```

‚úÖ **L√ìGICA CORRETA** implementada!

**Uso em F5-TTS** (`app/engines/f5tts_engine.py:360`):

```python
# LOW_VRAM mode: load model ‚Üí synthesize ‚Üí unload
if settings.get('low_vram_mode'):
    with vram_manager.load_model('f5tts', self._load_model):
        model_params = self._normalize_f5_params(tts_params)
        audio_array = await loop.run_in_executor(
            None,
            self._synthesize_blocking,
            text,
            ref_audio_path,
            ref_text,
            model_params
        )
else:
    # Normal mode: model already loaded
    ...
```

‚úÖ **INTEGRA√á√ÉO CORRETA** com context manager!

**Conclus√£o:** C√≥digo est√° **100% implementado e correto**, mas **nunca executa** porque `LOW_VRAM=false` no container!

#### 4.4.3. Padr√µes que Impedem Unload

**Singleton Global** (`app/vram_manager.py:158`):

```python
_vram_manager = None

def get_vram_manager() -> VRAMManager:
    """Retorna o gerenciador global de VRAM (singleton)."""
    global _vram_manager
    if _vram_manager is None:
        _vram_manager = VRAMManager()
    return _vram_manager
```

‚úÖ **Singleton OK**: N√£o impede unload (apenas centraliza gerenciamento)

**Model Cache** (`app/vram_manager.py:38`):

```python
self._model_cache = {}  # Cache de modelos (quando LOW_VRAM=false)
```

‚úÖ **Cache s√≥ usado em NORMAL mode**: N√£o impede unload em LOW_VRAM

**Refer√™ncias Globais:**

Nenhuma refer√™ncia global ao modelo detectada fora do VRAMManager.

---

## 5. Conclus√µes e Problemas Cr√≠ticos

### 5.1. Resumo de Problemas

| # | Problema | Severidade | Impacto | Causa Raiz |
|---|----------|------------|---------|------------|
| 1 | LOW_VRAM n√£o ativado | üî¥ Cr√≠tico | 100% VRAM ocupada sempre | `env_file` n√£o recarregado ap√≥s mudan√ßa |
| 2 | F5-TTS em CPU for√ßado | üî¥ Cr√≠tico | 10x mais lento | Hardcode `device='cpu'` no engine |
| 3 | Imagem Docker deprecated | ‚ö†Ô∏è Alto | Risco de quebra futura | Base image CUDA 12.1 EOL |
| 4 | Containers √≥rf√£os potenciais | ‚ö†Ô∏è M√©dio | Uso desnecess√°rio de disk/RAM | Falta rotina de prune |
| 5 | Imagens gigantes (16GB) | ‚ö†Ô∏è M√©dio | 32GB total storage | Sem multi-stage build |
| 6 | Health check s√≥ na API | ‚ö†Ô∏è Baixo | Celery pode estar unhealthy | Falta healthcheck no worker |
| 7 | Rebuilds sujos | ‚ö†Ô∏è Baixo | Estado inconsistente | Falta cleanup before rebuild |

### 5.2. Prioriza√ß√£o (Alta ‚Üí Baixa)

1. ‚ö° **[CR√çTICO]** Ativar LOW_VRAM corretamente
2. ‚ö° **[CR√çTICO]** Fazer F5-TTS usar GPU (n√£o CPU hardcoded)
3. üîß **[ALTO]** Atualizar base image CUDA (12.1 ‚Üí 12.4)
4. üîß **[ALTO]** Criar rotina de cleanup (prune) sistem√°tica
5. üõ†Ô∏è **[M√âDIO]** Implementar multi-stage build (reduzir tamanho)
6. üõ†Ô∏è **[M√âDIO]** Adicionar healthcheck no Celery
7. üìã **[BAIXO]** Adicionar depends_on entre servi√ßos

### 5.3. Riscos Identificados

#### Risco 1: OOM (Out of Memory) em GPU 4GB

**Cen√°rio:**
- XTTS carregado: ~3.5GB VRAM
- F5-TTS carregado: ~2.0GB VRAM
- **Total: 5.5GB > 4GB dispon√≠veis**

**Consequ√™ncia:** `RuntimeError: CUDA out of memory`

**Mitiga√ß√£o Atual:** F5-TTS for√ßado em CPU (evita OOM, mas **10x mais lento**)

**Mitiga√ß√£o Ideal:** LOW_VRAM mode ativado (carrega/descarrega modelos dinamicamente)

#### Risco 2: Comportamento N√£o Determin√≠stico Ap√≥s Restart

**Cen√°rio:**
- Usu√°rio muda `.env` (ex: `LOW_VRAM=true`)
- Faz `docker restart audio-voice-celery`
- **Vari√°vel N√ÉO √© recarregada** (container mant√©m env antigo)

**Consequ√™ncia:** Comportamento imprevis√≠vel, usu√°rio acha que configurou mas n√£o funcionou

**Mitiga√ß√£o:** Sempre usar `docker compose down` + `docker compose up` (n√£o `restart`)

#### Risco 3: Imagem Deprecated Pode Parar de Funcionar

**Cen√°rio:**
- NVIDIA remove imagem CUDA 12.1 do DockerHub
- Build quebra com `image not found`

**Consequ√™ncia:** Deploy imposs√≠vel sem atualizar Dockerfile

**Mitiga√ß√£o:** Atualizar para CUDA 12.4+ (latest LTS)

---

## 6. Evid√™ncias Coletadas

### 6.1. Containers Ativos

```
NAMES                    STATUS                    IMAGE
audio-voice-api          Up 26 minutes (healthy)   audio-voice-audio-voice-service
audio-voice-celery       Up 16 minutes (healthy)   audio-voice-celery-worker
```

### 6.2. GPU Accessibility

```bash
$ docker exec audio-voice-celery nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader
NVIDIA GeForce GTX 1050 Ti, 4096 MiB, 2144 MiB
```

### 6.3. Environment Variables (Container)

```bash
$ docker inspect audio-voice-celery --format '{{.Config.Env}}'
LOW_VRAM=false
NVIDIA_VISIBLE_DEVICES=all
CUDA_VISIBLE_DEVICES=0
FORCE_CUDA=1
```

### 6.4. Logs LOW_VRAM

```
[2025-11-28 01:14:02] INFO: ‚ö° NORMAL MODE: Modelos permanecer√£o na VRAM
[2025-11-28 01:09:14] INFO: ‚ö° NORMAL MODE: Modelos permanecer√£o na VRAM
[2025-11-28 01:03:10] INFO: ‚ö° NORMAL MODE: Modelos permanecer√£o na VRAM
```

**Conclus√£o:** LOW_VRAM **NUNCA foi ativado** em nenhum restart.

### 6.5. Hardcode CPU em F5-TTS

```python
# app/engines/f5tts_engine.py:115
self.device = 'cpu'  # FIXME: Force CPU at√© implementar VRAM management
```

---

## 7. Recomenda√ß√µes T√©cnicas

### 7.1. Imediatas (Sprint 1)

1. **Recriar containers com LOW_VRAM correto**
   ```bash
   docker compose down
   docker compose up -d --build
   ```

2. **Remover hardcode CPU do F5-TTS**
   ```python
   # Antes
   self.device = 'cpu'  # FIXME
   
   # Depois
   self.device = self._select_device(device, fallback_to_cpu)
   ```

3. **Validar GPU usage com nvidia-smi**
   ```bash
   watch -n 1 nvidia-smi
   # Verificar VRAM usage durante inference
   ```

### 7.2. Curto Prazo (Sprint 2)

1. **Atualizar base image CUDA**
   ```dockerfile
   FROM nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04
   ```

2. **Criar script de cleanup sistem√°tico**
   ```bash
   #!/bin/bash
   docker compose down --volumes
   docker system prune -af --volumes
   docker compose build --no-cache
   docker compose up -d
   ```

3. **Adicionar healthcheck no Celery**
   ```yaml
   healthcheck:
     test: ["CMD-SHELL", "celery -A app.celery_config inspect ping -d celery@$HOSTNAME"]
     interval: 30s
     timeout: 10s
     retries: 3
   ```

### 7.3. M√©dio Prazo (Sprint 3-4)

1. **Multi-stage build** (reduzir tamanho 40-50%)
2. **Testes de stress VRAM** (validar LOW_VRAM em produ√ß√£o)
3. **Monitoramento de VRAM** (Prometheus + Grafana)

---

## 8. Checklist de Valida√ß√£o

**Ap√≥s implementar corre√ß√µes, validar:**

- [ ] `docker ps` mostra apenas 2 containers (API + Celery)
- [ ] `docker inspect audio-voice-celery | grep LOW_VRAM` retorna `true`
- [ ] Logs mostram `üîã LOW VRAM MODE: ATIVADO`
- [ ] F5-TTS usa GPU (n√£o CPU)
- [ ] `nvidia-smi` mostra VRAM sendo alocada/liberada durante inference
- [ ] Ap√≥s inference, VRAM volta ao baseline (apenas XTTS residente)
- [ ] Base image √© CUDA 12.4+ (n√£o deprecated)
- [ ] `docker images` n√£o mostra imagens `<none>` (√≥rf√£s)

---

**Fim do Relat√≥rio de Auditoria QA**

**Pr√≥ximo passo:** Gerar `SPRINTS_DOCKER_GPU.md` com plano de implementa√ß√£o detalhado.
