# üìä AN√ÅLISE v4 - PROBLEMAS IDENTIFICADOS E SOLU√á√ïES PROPOSTAS

**Data:** 2025-11-01  
**Analista:** Desenvolvedor Python S√™nior - Especialista em Aplica√ß√µes Resilientes  
**Objetivo:** An√°lise profunda dos problemas relatados e proposi√ß√£o de solu√ß√µes t√©cnicas

---

## üéØ PROBLEMAS RELATADOS PELO USU√ÅRIO

### 1. **Remover Isolamento de Voz com IA (OpenUnmix + Torch)**
**Justificativa do Usu√°rio:** "Testei mas n√£o √© satisfat√≥rio"

### 2. **Servi√ßo 100% CPU (Remover GPU)**
**Objetivo:** Reduzir depend√™ncias, diminuir carga de instala√ß√£o, subir servi√ßo mais r√°pido

### 3. **Orchestrator Aceita Requisi√ß√µes Duplicadas**
**Problema:** Se recebe 2 inputs iguais ao mesmo tempo, processa 2 vezes ao inv√©s de 1

### 4. **Normalizer n√£o Mostra Progresso Durante Chunking**
**Problema:** Quando processa em lotes (chunks), s√≥ atualiza progresso no final

---

## üîç AN√ÅLISE T√âCNICA DETALHADA

---

## PROBLEMA 1: Isolamento de Voz com OpenUnmix + Torch

### üîé Arquivos Afetados (Encontrados na Busca)

#### **audio-normalization/app/config.py**
```python
# Linhas 81-86
'openunmix': {
    'model_name': os.getenv('OPENUNMIX_MODEL_NAME', 'umx'),
    'target': os.getenv('OPENUNMIX_TARGET', 'vocals'),
    'device': os.getenv('OPENUNMIX_DEVICE', 'cpu'),
    'pretrained': os.getenv('OPENUNMIX_PRETRAINED', 'true').lower() == 'true',
}
```
**IMPACTO:** Configura√ß√£o completa do OpenUnmix que precisa ser removida.

---

#### **audio-normalization/app/processor.py**
**Importa√ß√µes (Linhas 19-29):**
```python
# Para isolamento vocal com openunmix
try:
    import torch
    import openunmix
    OPENUNMIX_AVAILABLE = True
    TORCH_AVAILABLE = True
    logger.info("‚úÖ PyTorch e OpenUnmix dispon√≠veis para isolamento vocal")
except ImportError:
    OPENUNMIX_AVAILABLE = False
    TORCH_AVAILABLE = False
    logger.warning("‚ö†Ô∏è OpenUnmix n√£o dispon√≠vel. Isolamento vocal ser√° desabilitado")
```

**Atributos da Classe (Linhas 35-38):**
```python
self._openunmix_model = None
self.device = None  # Will be set when loading model
self._detect_device()
```

**M√©todos Relacionados a GPU:**
- `_detect_device()` (linhas 40-64): Detecta CUDA/GPU e configura device
- `_test_gpu()` (linhas 66-91): Testa funcionamento da GPU
- `_load_openunmix_model()` (linhas 253-300): Carrega modelo OpenUnmix
- `_isolate_vocals()` (m√©todo que usa o modelo)

**Uso no Processamento (Linha 186):**
```python
logger.info(f"üìã Processing params: noise={job.remove_noise}, highpass={job.apply_highpass_filter}, vocals={job.isolate_vocals}")
```

**Aplica√ß√£o no Pipeline (Linhas 523-534):**
```python
# 1. Isolamento vocal (primeiro, pois pode afetar outras opera√ß√µes)
if job.isolate_vocals:
    try:
        logger.info("Aplicando isolamento vocal...")
        audio = await self._isolate_vocals(audio)
        if not is_chunk:
            current_progress += progress_step
            job.progress = current_progress
            if self.job_store:
                self.job_store.update_job(job)
```

**TOTAL DE REFER√äNCIAS:** 100+ matches encontrados (torch, cuda, gpu, openunmix, isolate_vocals)

---

#### **audio-normalization/app/models.py**
**Campo no AudioProcessingRequest (Linha 20):**
```python
class AudioProcessingRequest(BaseModel):
    ...
    isolate_vocals: bool = False
```

**Campo no Job (Linha 40):**
```python
class Job(BaseModel):
    ...
    isolate_vocals: bool = False
```

**Uso na String de Opera√ß√µes (Linhas 55-56):**
```python
if self.isolate_vocals:
    operations.append("v")
```

**Uso no create_new (Linhas 62-66, 80-81, 96):**
```python
@classmethod
def create_new(cls, ..., isolate_vocals: bool = False) -> "Job":
    ...
    "v" if isolate_vocals else ""
    ...
    isolate_vocals=isolate_vocals,
```

---

#### **audio-normalization/app/main.py**
**Form Parameter (Linha 135):**
```python
isolate_vocals: str = Form("false")
```

**Docstring (Linha 147):**
```python
- **isolate_vocals**: Isola vocais usando OpenUnmix (padr√£o: False)
```

**Convers√£o (Linha 172):**
```python
isolate_vocals_bool = str_to_bool(isolate_vocals)
```

**Log (Linha 177):**
```python
logger.info(f"  isolate_vocals: '{isolate_vocals}' -> {isolate_vocals_bool}")
```

**Passagem para Job (Linha 192):**
```python
isolate_vocals=isolate_vocals_bool
```

---

#### **audio-normalization/requirements.txt**
```
# === ML-BASED VOCAL ISOLATION ===
openunmix==1.3.0
torch==2.9.0
torchaudio==2.9.0
```
**IMPACTO:** Depend√™ncias PESADAS que ser√£o removidas (~2GB+ de download)

---

#### **orchestrator/modules/config.py**
**Default (Linha 67):**
```python
"default_isolate_vocals": os.getenv("DEFAULT_ISOLATE_VOCALS", "true").lower() == "true",
```

**Config do Microservi√ßo (Linha 104):**
```python
"default_params": {
    ...
    "isolate_vocals": False
}
```

---

#### **orchestrator/modules/models.py**
**PipelineJob (Linha 88):**
```python
isolate_vocals: bool = False
```

**PipelineRequest (Linha 185):**
```python
isolate_vocals: Optional[bool] = Field(settings["default_isolate_vocals"], description="Isolar vocais (separa voz de m√∫sica)")
```

---

#### **orchestrator/modules/orchestrator.py**
**Linha 456 (form data):**
```python
"isolate_vocals": _bool_to_str(job.isolate_vocals if job.isolate_vocals is not None else defaults.get("isolate_vocals", False)),
```

---

#### **orchestrator/main.py**
**Linha 150:**
```python
isolate_vocals=request.isolate_vocals if request.isolate_vocals is not None else False
```

---

### ‚úÖ SOLU√á√ÉO PROPOSTA - PROBLEMA 1

**A√ß√£o:** Remo√ß√£o completa e limpa do recurso de isolamento vocal

**Arquivos a Modificar:**

1. **`services/audio-normalization/requirements.txt`**
   - Remover: `openunmix`, `torch`, `torchaudio`

2. **`services/audio-normalization/app/config.py`**
   - Remover: Se√ß√£o `openunmix` completa

3. **`services/audio-normalization/app/processor.py`**
   - Remover: Importa√ß√µes `torch`, `openunmix`
   - Remover: `OPENUNMIX_AVAILABLE`, `TORCH_AVAILABLE`
   - Remover: `self._openunmix_model`, `self.device`
   - Remover: M√©todos `_detect_device()`, `_test_gpu()`, `_load_openunmix_model()`, `_isolate_vocals()`
   - Remover: Bloco de isolamento vocal em `_apply_processing_operations()`

4. **`services/audio-normalization/app/models.py`**
   - Remover: Campo `isolate_vocals` de `AudioProcessingRequest`
   - Remover: Campo `isolate_vocals` de `Job`
   - Remover: `"v"` da string de opera√ß√µes
   - Remover: Par√¢metro `isolate_vocals` de `create_new()`

5. **`services/audio-normalization/app/main.py`**
   - Remover: Form parameter `isolate_vocals`
   - Remover: Docstring sobre `isolate_vocals`
   - Remover: Convers√£o `isolate_vocals_bool`
   - Remover: Log de `isolate_vocals`
   - Remover: Passagem de `isolate_vocals` para Job

6. **`services/audio-normalization/app/celery_tasks.py`**
   - Remover: Refer√™ncia `vocals=` do log (linha 186)

7. **`orchestrator/modules/config.py`**
   - Remover: `default_isolate_vocals`
   - Remover: `isolate_vocals` de `default_params`

8. **`orchestrator/modules/models.py`**
   - Remover: Campo `isolate_vocals` de `PipelineJob`
   - Remover: Campo `isolate_vocals` de `PipelineRequest`

9. **`orchestrator/modules/orchestrator.py`**
   - Remover: `isolate_vocals` do form data (linha 456)

10. **`orchestrator/main.py`**
    - Remover: `isolate_vocals` da cria√ß√£o de job (linha 150)

**Benef√≠cios Esperados:**
- ‚úÖ Redu√ß√£o de ~2GB+ em depend√™ncias
- ‚úÖ Startup ~3-5x mais r√°pido do servi√ßo
- ‚úÖ Menor uso de mem√≥ria RAM (~500MB-1GB economizados)
- ‚úÖ C√≥digo mais simples e maint√≠vel
- ‚úÖ Sem necessidade de CUDA/GPU

---

## PROBLEMA 2: Refer√™ncias a GPU no C√≥digo (Garantir 100% CPU)

### üîé Locais Encontrados

#### **audio-normalization/app/processor.py**

**1. Atributo `self.device` (Linha 36):**
```python
self.device = None  # Will be set when loading model
```
**IMPACTO:** Usado para selecionar GPU/CPU - ser√° removido junto com torch

**2. M√©todo `_detect_device()` (Linhas 40-64):**
- Detecta CUDA
- Configura `self.device = 'cuda'` ou `'cpu'`
- Logs sobre GPU dispon√≠vel
**IMPACTO:** M√©todo completo ser√° removido

**3. M√©todo `_test_gpu()` (Linhas 66-91):**
- Testa tensor na GPU
- Verifica mem√≥ria GPU
- `torch.cuda.empty_cache()`
**IMPACTO:** M√©todo completo ser√° removido

**4. Chamadas `torch.cuda.*`:**
- `torch.cuda.is_available()` (linha 48)
- `torch.cuda.device_count()` (linha 51)
- `torch.cuda.get_device_name(0)` (linha 52)
- `torch.version.cuda` (linha 53)
- `torch.cuda.memory_allocated(0)` (linha 77)
- `torch.cuda.memory_reserved(0)` (linha 78)
- `torch.cuda.empty_cache()` (linha 86)
**IMPACTO:** Todas ser√£o removidas com a remo√ß√£o do torch

**5. Logs relacionados a GPU:**
- Linha 54: `"üéÆ CUDA DISPON√çVEL!"`
- Linha 55: `"GPUs detectadas: {device_count}"`
- Linha 56: `"GPU 0: {device_name}"`
- Linha 57: `"CUDA Version: {cuda_version}"`
- Linha 60: `"‚úÖ Usando GPU (CUDA) para processamento de √°udio"`
- Linha 80: `"üî• GPU funcionando corretamente!"`
**IMPACTO:** Logs ser√£o removidos

---

### ‚úÖ SOLU√á√ÉO PROPOSTA - PROBLEMA 2

**A√ß√£o:** Remover todas as refer√™ncias a GPU/CUDA/Torch

**Arquivos a Modificar:**

1. **`services/audio-normalization/app/processor.py`**
   - Remover: Todas as importa√ß√µes torch/cuda
   - Remover: Atributo `self.device`
   - Remover: M√©todo `_detect_device()` (n√£o chamar no `__init__`)
   - Remover: M√©todo `_test_gpu()`
   - Remover: Todos os logs relacionados a GPU/CUDA
   - Garantir: Apenas processamento com `pydub`, `scipy`, `numpy`, `librosa`, `soundfile`

**Verifica√ß√£o Final:**
```bash
# Ap√≥s modifica√ß√µes, rodar:
grep -r "gpu\|cuda\|torch\|GPU\|CUDA" services/audio-normalization/app/
# Deve retornar 0 resultados
```

**Benef√≠cios Esperados:**
- ‚úÖ C√≥digo 100% CPU
- ‚úÖ Sem depend√™ncias de GPU/CUDA
- ‚úÖ Funciona em qualquer servidor Linux b√°sico
- ‚úÖ Docker build mais r√°pido
- ‚úÖ Imagem Docker menor

---

## PROBLEMA 3: Orchestrator Aceita Requisi√ß√µes Duplicadas

### üîé An√°lise do Problema

**Comportamento Atual:**
```
Client 1: POST /process {"url": "video123"} -> job_id: abc-123
Client 2: POST /process {"url": "video123"} -> job_id: def-456
```
**Resultado:** 2 jobs diferentes processando o MESMO v√≠deo simultaneamente

**Comportamento Esperado:**
```
Client 1: POST /process {"url": "video123"} -> job_id: abc-123
Client 2: POST /process {"url": "video123"} -> job_id: abc-123 (MESMO job)
```
**Resultado:** 1 job processado, ambos os clients recebem mesmo job_id

---

### üîé An√°lise do C√≥digo Atual

#### **orchestrator/modules/models.py - PipelineJob.create_new()**
```python
# Linha ~85
@classmethod
def create_new(cls, youtube_url: str, ...) -> "PipelineJob":
    job_id = hashlib.md5(f"{youtube_url}{datetime.now().isoformat()}".encode()).hexdigest()[:16]
    ...
```

**PROBLEMA IDENTIFICADO:**
- ‚ùå Usa `datetime.now()` no hash
- ‚ùå Cada requisi√ß√£o, mesmo com mesma URL, gera job_id diferente
- ‚ùå N√£o h√° verifica√ß√£o de job existente antes de criar novo

---

### üîé Como Microservi√ßos Resolvem Isso

#### **audio-normalization/app/models.py - Job.create_new()**
```python
# Linha ~88
job_id = "{}_{}".format(
    hashlib.md5(filename.encode('utf-8')).hexdigest()[:12], 
    operation_string
)
```

**SOLU√á√ÉO DOS MICROSERVI√áOS:**
- ‚úÖ Hash baseado em `filename + operations`
- ‚úÖ N√ÉO usa timestamp
- ‚úÖ Mesmos par√¢metros = mesmo job_id
- ‚úÖ Redis Store previne duplica√ß√£o (mesma key)

---

### ‚úÖ SOLU√á√ÉO PROPOSTA - PROBLEMA 3

**A√ß√£o:** Implementar Idempot√™ncia no Orchestrator (igual aos microservi√ßos)

**Estrat√©gia:**

1. **Modificar `PipelineJob.create_new()`**
   ```python
   # ANTES (n√£o idempotente):
   job_id = hashlib.md5(f"{youtube_url}{datetime.now().isoformat()}".encode()).hexdigest()[:16]
   
   # DEPOIS (idempotente):
   # Hash baseado em: URL + language + operations (sem timestamp)
   operation_string = f"{youtube_url}_{language}_{language_out or 'none'}"
   operation_string += f"_noise{remove_noise}_mono{convert_to_mono}"
   operation_string += f"_highpass{apply_highpass_filter}_16k{set_sample_rate_16k}"
   job_id = hashlib.md5(operation_string.encode()).hexdigest()[:16]
   ```

2. **Adicionar Verifica√ß√£o no Endpoint `/process`**
   ```python
   # orchestrator/main.py
   @app.post("/process")
   async def process_youtube_video(request: PipelineRequest):
       # 1. Gera job_id ANTES de criar job
       job_id = PipelineJob.generate_id(
           youtube_url=request.youtube_url,
           language=request.language,
           # ... outros params
       )
       
       # 2. Verifica se job j√° existe no Redis
       existing_job = redis_store.get_job(job_id)
       if existing_job:
           # Job j√° existe - retorna o existente
           if existing_job.status in [PipelineStatus.PROCESSING, PipelineStatus.COMPLETED]:
               logger.info(f"‚ôªÔ∏è Job {job_id} j√° existe (status: {existing_job.status}) - retornando job existente")
               return PipelineResponse(
                   job_id=job_id,
                   status=existing_job.status.value,
                   message="Job j√° est√° sendo processado ou foi completado"
               )
       
       # 3. Cria novo job apenas se n√£o existe
       job = PipelineJob.create_with_id(job_id, ...)
       redis_store.save_job(job)
       ...
   ```

3. **Separar `generate_id()` de `create_new()`**
   ```python
   # orchestrator/modules/models.py
   class PipelineJob:
       @staticmethod
       def generate_id(youtube_url: str, language: str, ...) -> str:
           """Gera ID determin√≠stico baseado em par√¢metros"""
           operation_string = f"{youtube_url}_{language}_{language_out or 'none'}"
           operation_string += f"_noise{remove_noise}_mono{convert_to_mono}"
           operation_string += f"_highpass{apply_highpass_filter}_16k{set_sample_rate_16k}"
           return hashlib.md5(operation_string.encode()).hexdigest()[:16]
       
       @classmethod
       def create_with_id(cls, job_id: str, ...) -> "PipelineJob":
           """Cria job com ID pr√©-definido"""
           return cls(id=job_id, ...)
   ```

**Arquivos a Modificar:**

1. **`orchestrator/modules/models.py`**
   - Adicionar m√©todo `PipelineJob.generate_id()` (est√°tico)
   - Modificar `PipelineJob.create_new()` para usar `generate_id()` (sem timestamp)
   - Adicionar m√©todo `PipelineJob.create_with_id()`

2. **`orchestrator/main.py`**
   - Modificar endpoint `/process`:
     - Gerar job_id ANTES de criar job
     - Verificar se job_id j√° existe no Redis
     - Se existe e est√° ativo, retornar job existente
     - Se n√£o existe, criar novo job

**Benef√≠cios Esperados:**
- ‚úÖ Idempot√™ncia: mesma requisi√ß√£o = mesmo job
- ‚úÖ Economia de recursos (n√£o processa duplicados)
- ‚úÖ Consist√™ncia com microservi√ßos
- ‚úÖ Melhor UX (usu√°rio n√£o cria jobs duplicados por engano)

---

## PROBLEMA 4: Normalizer N√£o Mostra Progresso Durante Chunking

### üîé An√°lise do Problema

**Comportamento Atual:**
- Quando arquivo > `streaming_threshold_mb` (50MB), usa chunking
- Processa em lotes (chunks) sequencialmente
- **Progresso s√≥ √© atualizado AP√ìS processar TODOS os chunks**
- Orchestrator fica sem feedback durante todo o processamento

**Comportamento Esperado:**
- Progresso deve ser atualizado **A CADA CHUNK** processado
- Orchestrator deve ver progresso gradual: 0% ‚Üí 25% ‚Üí 50% ‚Üí 75% ‚Üí 100%

---

### üîé An√°lise do C√≥digo

#### **audio-normalization/app/processor.py**

**M√©todo `_process_audio_with_streaming()` (Linhas ~438-600):**

```python
async def _process_audio_with_streaming(self, job: Job):
    """Processa √°udio grande em chunks"""
    
    # ... split em chunks ...
    
    # Loop de processamento
    for i, chunk_file in enumerate(chunk_files):
        chunk_num = i + 1
        logger.info(f"üì¶ Processando chunk {chunk_num}/{total_chunks}...")
        
        # Carrega chunk
        chunk_audio = AudioSegment.from_file(...)
        
        # PROCESSA chunk
        processed_chunk = await self._apply_processing_operations(
            chunk_audio, job, is_chunk=True  # ‚Üê is_chunk=True
        )
        
        # Salva chunk processado
        processed_chunks.append(processed_chunk)
        
        # ‚ùå PROBLEMA: Progresso N√ÉO √© atualizado aqui
        # Deveria ter:
        # job.progress = (chunk_num / total_chunks) * 90.0
        # self.job_store.update_job(job)
    
    # ‚úÖ Progresso s√≥ √© atualizado DEPOIS de processar todos
    job.progress = 90.0
    if self.job_store: self.job_store.update_job(job)
```

**M√©todo `_apply_processing_operations()` (Linhas ~510-590):**

```python
async def _apply_processing_operations(self, audio, job, is_chunk: bool = False):
    """Aplica opera√ß√µes de processamento"""
    
    # Se for um chunk, o progresso N√ÉO √© gerenciado aqui
    if not is_chunk:
        progress_step = 80.0 / operations_count
        current_progress = 10.0
    
    # Isolamento vocal
    if job.isolate_vocals:
        audio = await self._isolate_vocals(audio)
        if not is_chunk:  # ‚Üê S√≥ atualiza se N√ÉO for chunk
            current_progress += progress_step
            job.progress = current_progress
            if self.job_store:
                self.job_store.update_job(job)
    
    # ... outras opera√ß√µes (mesmo padr√£o) ...
```

**PROBLEMA IDENTIFICADO:**
- ‚ùå Flag `is_chunk=True` desabilita atualiza√ß√£o de progresso
- ‚ùå Loop de chunks n√£o atualiza progresso entre chunks
- ‚ùå Progresso fica "congelado" em 10% por minutos

---

### ‚úÖ SOLU√á√ÉO PROPOSTA - PROBLEMA 4

**A√ß√£o:** Atualizar progresso A CADA CHUNK processado

**Estrat√©gia:**

1. **Adicionar atualiza√ß√£o de progresso no loop de chunks**
   ```python
   # audio-normalization/app/processor.py
   async def _process_audio_with_streaming(self, job: Job):
       ...
       for i, chunk_file in enumerate(chunk_files):
           chunk_num = i + 1
           logger.info(f"üì¶ Processando chunk {chunk_num}/{total_chunks}...")
           
           # Carrega chunk
           chunk_audio = AudioSegment.from_file(...)
           
           # ATUALIZA PROGRESSO ANTES DE PROCESSAR
           # Progresso: 10% (prepara√ß√£o) + 80% (processamento de chunks) + 10% (merge/finaliza√ß√£o)
           chunk_progress = 10.0 + (chunk_num / total_chunks) * 70.0  # 10-80%
           job.progress = chunk_progress
           if self.job_store:
               self.job_store.update_job(job)
               logger.info(f"üìä Progresso atualizado: {chunk_progress:.1f}%")
           
           # Processa chunk
           processed_chunk = await self._apply_processing_operations(
               chunk_audio, job, is_chunk=True
           )
           
           # Salva chunk processado
           processed_chunks.append(processed_chunk)
           
           # ATUALIZA PROGRESSO AP√ìS PROCESSAR
           chunk_progress_after = 10.0 + ((chunk_num + 0.5) / total_chunks) * 70.0
           job.progress = chunk_progress_after
           if self.job_store:
               self.job_store.update_job(job)
               logger.info(f"‚úÖ Chunk {chunk_num}/{total_chunks} processado ({chunk_progress_after:.1f}%)")
       
       # Merge de chunks (10% final)
       job.progress = 85.0
       if self.job_store: self.job_store.update_job(job)
       logger.info("üîó Mesclando chunks...")
       
       # ... merge ...
       
       job.progress = 90.0
       if self.job_store: self.job_store.update_job(job)
   ```

2. **Adicionar logs detalhados de progresso**
   ```python
   logger.info(f"üìä Progresso: {chunk_num}/{total_chunks} chunks ({job.progress:.1f}%)")
   ```

**Arquivos a Modificar:**

1. **`services/audio-normalization/app/processor.py`**
   - M√©todo `_process_audio_with_streaming()`:
     - Adicionar atualiza√ß√£o de progresso ANTES de processar chunk
     - Adicionar atualiza√ß√£o de progresso AP√ìS processar chunk
     - Calcular progresso proporcional: `10 + (chunk_num / total_chunks) * 70`
     - Adicionar logs de progresso detalhados

**C√°lculo de Progresso Proposto:**
```
0-10%:   Prepara√ß√£o (split em chunks)
10-80%:  Processamento de chunks (70% / N chunks)
80-90%:  Merge de chunks
90-100%: Finaliza√ß√£o e save
```

**Exemplo com 4 chunks:**
```
Chunk 1: 10% ‚Üí 27.5%  (processando) ‚Üí 28.75% (processado)
Chunk 2: 28.75% ‚Üí 45%  (processando) ‚Üí 46.25% (processado)
Chunk 3: 46.25% ‚Üí 62.5% (processando) ‚Üí 63.75% (processado)
Chunk 4: 63.75% ‚Üí 80%  (processando) ‚Üí 80% (processado)
Merge:   85% ‚Üí 90%
Save:    95% ‚Üí 100%
```

**Benef√≠cios Esperados:**
- ‚úÖ Orchestrator v√™ progresso em tempo real
- ‚úÖ Usu√°rio sabe que processamento est√° avan√ßando
- ‚úÖ Melhor UX (n√£o parece travado)
- ‚úÖ Facilita debugging (logs detalhados)
- ‚úÖ Permite cancelamento inteligente no futuro

---

## üìä RESUMO DAS MODIFICA√á√ïES

### Arquivos a Modificar (Total: 11 arquivos)

#### **audio-normalization** (7 arquivos)
1. `requirements.txt` - Remover torch, openunmix, torchaudio
2. `app/config.py` - Remover se√ß√£o openunmix
3. `app/processor.py` - Remover GPU/torch/openunmix + adicionar progresso em chunks
4. `app/models.py` - Remover campo isolate_vocals
5. `app/main.py` - Remover par√¢metro isolate_vocals
6. `app/celery_tasks.py` - Remover log de vocals

#### **orchestrator** (4 arquivos)
7. `modules/config.py` - Remover default_isolate_vocals
8. `modules/models.py` - Remover isolate_vocals + adicionar generate_id()
9. `modules/orchestrator.py` - Remover isolate_vocals do form data
10. `main.py` - Remover isolate_vocals + adicionar verifica√ß√£o de duplicados

---

## üéØ ORDEM DE IMPLEMENTA√á√ÉO RECOMENDADA

### **FASE 1: Remo√ß√£o de Isolamento Vocal**
1. Modificar `audio-normalization/requirements.txt`
2. Modificar `audio-normalization/app/processor.py` (remover m√©todos GPU)
3. Modificar `audio-normalization/app/config.py`
4. Modificar `audio-normalization/app/models.py`
5. Modificar `audio-normalization/app/main.py`
6. Modificar `audio-normalization/app/celery_tasks.py`

### **FASE 2: Remo√ß√£o do Orchestrator**
7. Modificar `orchestrator/modules/config.py`
8. Modificar `orchestrator/modules/models.py`
9. Modificar `orchestrator/modules/orchestrator.py`
10. Modificar `orchestrator/main.py`

### **FASE 3: Implementar Progresso em Chunks**
11. Modificar `audio-normalization/app/processor.py` (adicionar updates de progresso)

### **FASE 4: Implementar Idempot√™ncia**
12. Modificar `orchestrator/modules/models.py` (generate_id)
13. Modificar `orchestrator/main.py` (verifica√ß√£o de duplicados)

---

## ‚úÖ VALIDA√á√ÉO P√ìS-IMPLEMENTA√á√ÉO

### Testes Obrigat√≥rios:

1. **Verificar Remo√ß√£o Completa de GPU/Torch:**
   ```bash
   grep -r "gpu\|cuda\|torch\|openunmix\|isolate_vocals" services/audio-normalization/
   # Deve retornar 0 resultados (exceto em coment√°rios hist√≥ricos)
   ```

2. **Verificar Progresso em Chunks:**
   - Upload arquivo > 50MB
   - Monitorar endpoint `/jobs/{job_id}`
   - Verificar se progresso atualiza continuamente (n√£o fica parado)

3. **Verificar Idempot√™ncia:**
   - Enviar 2 requisi√ß√µes id√™nticas simultaneamente
   - Verificar se retornam o MESMO job_id
   - Verificar se apenas 1 job √© processado no Redis

4. **Build e Startup:**
   - `docker-compose build audio-normalization`
   - Verificar tempo de build (deve ser menor)
   - Verificar tempo de startup (deve ser mais r√°pido)
   - Verificar tamanho da imagem (deve ser menor)

---

## üöÄ BENEF√çCIOS ESPERADOS TOTAIS

### Performance:
- ‚úÖ Startup ~3-5x mais r√°pido
- ‚úÖ Build ~2-3x mais r√°pido
- ‚úÖ Redu√ß√£o de ~2GB em depend√™ncias

### Recursos:
- ‚úÖ Redu√ß√£o de ~500MB-1GB RAM
- ‚úÖ Imagem Docker ~1GB menor
- ‚úÖ Sem necessidade de GPU/CUDA

### UX:
- ‚úÖ Progresso vis√≠vel em tempo real
- ‚úÖ N√£o processa requisi√ß√µes duplicadas
- ‚úÖ Feedback cont√≠nuo durante processamento

### Manutenibilidade:
- ‚úÖ C√≥digo mais simples
- ‚úÖ Menos depend√™ncias
- ‚úÖ Mais f√°cil de debugar
- ‚úÖ Funciona em qualquer servidor Linux

---

**FIM DA AN√ÅLISE v4**
