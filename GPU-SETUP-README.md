# üöÄ Setup Autom√°tico de GPU para Containers LXC Proxmox

Este guia explica como usar o script `gpu-fix.sh` para configurar automaticamente o NVIDIA Container Toolkit em containers LXC do Proxmox.

## üìã Pr√©-requisitos

### No Host Proxmox (obrigat√≥rio)

1. **GPU NVIDIA configurada** no host Proxmox
2. **Driver NVIDIA instalado** no host
3. **GPU Passthrough configurado** para o container LXC

#### Configura√ß√£o no Host Proxmox

No arquivo `/etc/pve/lxc/<CONTAINER_ID>.conf`, adicione:

```bash
# Habilita features necess√°rias
features: nesting=1

# GPU Passthrough - Dispositivos
lxc.cgroup2.devices.allow: c 195:* rwm
lxc.cgroup2.devices.allow: c 510:* rwm

# Monta dispositivos GPU
lxc.mount.entry: /dev/nvidia0 dev/nvidia0 none bind,optional,create=file 0 0
lxc.mount.entry: /dev/nvidiactl dev/nvidiactl none bind,optional,create=file 0 0
lxc.mount.entry: /dev/nvidia-uvm dev/nvidia-uvm none bind,optional,create=file 0 0
lxc.mount.entry: /dev/nvidia-uvm-tools dev/nvidia-uvm-tools none bind,optional,create=file 0 0

# Monta nvidia-smi e bibliotecas essenciais
lxc.mount.entry: /usr/bin/nvidia-smi usr/bin/nvidia-smi none bind,optional,create=file 0 0
lxc.mount.entry: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1 usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1 none bind,optional,create=file 0 0

# ‚≠ê IMPORTANTE: Para PyTorch funcionar, adicione tamb√©m:
lxc.mount.entry: /usr/lib/x86_64-linux-gnu/libcuda.so usr/lib/x86_64-linux-gnu/libcuda.so none bind,optional,create=file 0 0
lxc.mount.entry: /usr/lib/x86_64-linux-gnu/libcuda.so.1 usr/lib/x86_64-linux-gnu/libcuda.so.1 none bind,optional,create=file 0 0
lxc.mount.entry: /usr/lib/x86_64-linux-gnu/libcuda.so.550.163.01 usr/lib/x86_64-linux-gnu/libcuda.so.550.163.01 none bind,optional,create=file 0 0
```

**Nota**: Substitua `<CONTAINER_ID>` pelo ID do seu container e ajuste a vers√£o do driver (550.163.01) conforme necess√°rio.

Ap√≥s editar, reinicie o container:
```bash
pct stop <CONTAINER_ID>
pct start <CONTAINER_ID>
```

### No Container LXC

- **Debian 11+** ou **Ubuntu 20.04+**
- **Docker instalado** (opcional, mas recomendado)
- **Acesso root** no container

## üéØ Uso do Script

### 1. Copiar o script para o container

```bash
# Op√ß√£o 1: Via wget/curl (se tiver o script em um servidor web)
wget https://seu-servidor.com/gpu-fix.sh
chmod +x gpu-fix.sh

# Op√ß√£o 2: Via scp do host
scp gpu-fix.sh root@<IP_DO_CONTAINER>:/root/

# Op√ß√£o 3: Copiar e colar o conte√∫do
nano gpu-fix.sh
# Cole o conte√∫do e salve (Ctrl+X, Y, Enter)
chmod +x gpu-fix.sh
```

### 2. Executar o script

```bash
sudo bash gpu-fix.sh
```

O script ir√°:
1. ‚úÖ Verificar permiss√µes root
2. ‚úÖ Detectar a distribui√ß√£o Linux
3. ‚úÖ Verificar disponibilidade da GPU
4. ‚úÖ Remover instala√ß√µes antigas conflitantes
5. ‚úÖ Configurar reposit√≥rio NVIDIA
6. ‚úÖ Instalar NVIDIA Container Toolkit
7. ‚úÖ Configurar Docker runtime
8. ‚úÖ Aplicar configura√ß√µes espec√≠ficas para LXC
9. ‚úÖ Configurar libcuda.so (se dispon√≠vel)
10. ‚úÖ Testar a instala√ß√£o
11. ‚úÖ Gerar relat√≥rio

### 3. Verificar instala√ß√£o

```bash
# Teste 1: nvidia-smi
nvidia-smi

# Teste 2: Docker info
docker info | grep -i runtime

# Teste 3: Container de teste
docker run --rm --runtime=nvidia --gpus all \
  nvidia/cuda:12.4.1-base-ubuntu22.04 nvidia-smi
```

## üìä Output Esperado

```
==========================================
NVIDIA Container Toolkit Installer
Para Proxmox LXC com GPU Passthrough
==========================================

[‚úì] Executando como root
[INFO] Distribui√ß√£o detectada: debian 12
[‚úì] Dispositivos NVIDIA encontrados
[‚úì] Limpeza conclu√≠da
[‚úì] Reposit√≥rio configurado
[‚úì] NVIDIA Container Toolkit instalado
[‚úì] Docker runtime configurado
[‚úì] Configura√ß√£o LXC aplicada (no-cgroups=true, mode=legacy)
[‚úì] Docker reiniciado
==========================================
[INFO] Testando configura√ß√£o...
==========================================
[‚úì] Runtime nvidia detectado
[‚úì] nvidia-container-cli funcionando
[‚úì] Container teste executou nvidia-smi com sucesso!
==========================================
[INFO] INSTALA√á√ÉO CONCLU√çDA
==========================================
```

## üîß Troubleshooting

### Problema: PyTorch n√£o detecta GPU

**Sintoma:**
```python
import torch
print(torch.cuda.is_available())  # False
```

**Solu√ß√£o:**

Certifique-se de que os bind mounts do `libcuda.so` est√£o configurados no host Proxmox (veja se√ß√£o "Pr√©-requisitos" acima).

Dentro do container, verifique:
```bash
ls -la /usr/lib/x86_64-linux-gnu/libcuda*
```

Se n√£o aparecer, adicione os bind mounts no arquivo `/etc/pve/lxc/<CONTAINER_ID>.conf` do host Proxmox.

### Problema: "Error 803: driver/cuda combination"

**Causa:** Incompatibilidade de vers√£o entre driver e CUDA toolkit.

**Solu√ß√£o:**

Verifique as vers√µes:
```bash
# Vers√£o do driver
cat /proc/driver/nvidia/version

# Vers√£o CUDA no container Docker
docker exec <container> nvcc --version
```

Se incompat√≠veis, use uma imagem Docker com CUDA compat√≠vel ou atualize o driver.

### Problema: "could not select device driver nvidia"

**Causa:** Runtime nvidia n√£o configurado.

**Solu√ß√£o:**

Execute o script novamente ou configure manualmente:
```bash
nvidia-ctk runtime configure --runtime=docker
systemctl restart docker
```

### Problema: Dispositivos /dev/nvidia* n√£o existem

**Causa:** GPU passthrough n√£o configurado no Proxmox.

**Solu√ß√£o:**

Verifique a configura√ß√£o LXC no host Proxmox (veja "Pr√©-requisitos").

## üìÅ Logs

O script gera um log completo em:
```
/var/log/nvidia-container-toolkit-install.log
```

Para ver o log:
```bash
cat /var/log/nvidia-container-toolkit-install.log
```

## üê≥ Uso com Docker Compose

Adicione ao seu `docker-compose.yml`:

```yaml
services:
  seu-servico:
    image: sua-imagem
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
```

## ‚ú® Features do Script

- ‚úÖ **Detec√ß√£o autom√°tica** da distribui√ß√£o
- ‚úÖ **Cleanup inteligente** de instala√ß√µes antigas
- ‚úÖ **Workarounds para LXC** (no-cgroups, legacy mode)
- ‚úÖ **Testes autom√°ticos** ap√≥s instala√ß√£o
- ‚úÖ **Logging completo** de todas opera√ß√µes
- ‚úÖ **Output colorido** para f√°cil leitura
- ‚úÖ **Idempotente** - pode ser executado m√∫ltiplas vezes
- ‚úÖ **Error handling** robusto

## üîÑ Atualiza√ß√£o

Para atualizar o NVIDIA Container Toolkit:

```bash
# Execute o script novamente
sudo bash gpu-fix.sh
```

O script automaticamente remove vers√µes antigas e instala a mais recente.

## üìö Refer√™ncias

- [NVIDIA Container Toolkit Documentation](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/)
- [Proxmox GPU Passthrough Wiki](https://pve.proxmox.com/wiki/PCI(e)_Passthrough)
- [Docker GPU Support](https://docs.docker.com/config/containers/resource_constraints/#gpu)

## üÜò Suporte

Em caso de problemas, consulte:
1. Logs: `/var/log/nvidia-container-toolkit-install.log`
2. Documenta√ß√£o: `GPU-TROUBLESHOOTING.md`
3. Teste manual: Execute os comandos da se√ß√£o "Verificar instala√ß√£o"

---

**Desenvolvido para YTCaption Audio-Voice Service**  
Script testado em: Debian 12, Ubuntu 22.04 (Proxmox LXC)  
√öltima atualiza√ß√£o: 2025-11-29
