# SPRINTS_DOCKER_GPU ‚Äì Plano de Implementa√ß√£o QA

**Baseado em:** `QA_DOCKER_GPU.md`  
**Data:** 28 de Novembro de 2025  
**Metodologia:** Test-Driven QA (Testes ‚Üí Implementa√ß√£o ‚Üí Valida√ß√£o)  
**Estimativa Total:** 4-6 horas (dividido em 4 sprints)

---

## üìã Objetivo Geral

Corrigir os problemas cr√≠ticos identificados na auditoria:

1. ‚úÖ Ativar `LOW_VRAM` mode corretamente
2. ‚úÖ Fazer F5-TTS usar GPU (remover hardcode CPU)
3. ‚úÖ Padronizar ciclo de vida dos containers (cleanup + rebuild limpo)
4. ‚úÖ Atualizar base image CUDA (deprecated ‚Üí current)
5. ‚úÖ Garantir observabilidade (logs, healthchecks, monitoramento VRAM)

---

## üèÉ Sprint 1 ‚Äì Padronizar Ciclo de Vida dos Containers

**Dura√ß√£o:** 45-60 minutos  
**Prioridade:** üî¥ Cr√≠tica  
**Objetivo:** Garantir que n√£o existam m√∫ltiplos containers √≥rf√£os e que o ciclo de subir/derrubar seja claro e reproduz√≠vel.

### Tarefas

#### 1.1. Criar Script de Cleanup Sistem√°tico

**Teste:**
```bash
# scripts/docker-cleanup-audio-voice.sh
#!/bin/bash
set -e

echo "üßπ Iniciando cleanup do servi√ßo audio-voice..."

# Valida√ß√£o: script deve falhar se houver containers rodando que n√£o sejam do compose
if docker ps --filter "name=audio-voice" --format '{{.Names}}' | grep -v -E "(audio-voice-api|audio-voice-celery)"; then
    echo "‚ùå ERRO: Containers desconhecidos detectados!"
    exit 1
fi

echo "‚úÖ Valida√ß√£o de containers passou"
exit 0
```

**Implementa√ß√£o:**
```bash
# scripts/docker-cleanup-audio-voice.sh
#!/bin/bash
set -e

cd "$(dirname "$0")/../services/audio-voice"

echo "üßπ Parando servi√ßos audio-voice..."
docker compose down --volumes --remove-orphans

echo "üóëÔ∏è Removendo imagens antigas do audio-voice..."
docker images | grep "audio-voice" | awk '{print $3}' | xargs -r docker rmi -f || true

echo "üßΩ Limpando sistema Docker (prune seletivo)..."
docker system prune -f --filter "label=com.example.service=audio-voice"

echo "‚úÖ Cleanup conclu√≠do!"
```

**Valida√ß√£o:**
```bash
bash scripts/docker-cleanup-audio-voice.sh
docker ps --filter "name=audio-voice"  # Deve retornar vazio
docker images | grep "audio-voice"      # Deve retornar vazio
```

- [ ] Script criado em `scripts/docker-cleanup-audio-voice.sh`
- [ ] Execut√°vel: `chmod +x scripts/docker-cleanup-audio-voice.sh`
- [ ] Teste: Executar e validar que n√£o h√° containers/imagens restantes

#### 1.2. Criar Script de Rebuild Limpo

**Teste:**
```bash
# scripts/rebuild-audio-voice.sh (validation only)
#!/bin/bash
set -e

# Verificar se .env existe
if [ ! -f "services/audio-voice/.env" ]; then
    echo "‚ùå .env n√£o encontrado!"
    exit 1
fi

# Verificar se LOW_VRAM est√° definido
if ! grep -q "^LOW_VRAM=" "services/audio-voice/.env"; then
    echo "‚ùå LOW_VRAM n√£o definido no .env!"
    exit 1
fi

echo "‚úÖ Pr√©-condi√ß√µes para rebuild OK"
```

**Implementa√ß√£o:**
```bash
# scripts/rebuild-audio-voice.sh
#!/bin/bash
set -e

cd "$(dirname "$0")/../services/audio-voice"

echo "üî® Rebuild limpo do audio-voice..."

# 1. Cleanup completo
bash ../../scripts/docker-cleanup-audio-voice.sh

# 2. Rebuild sem cache
echo "üì¶ Building imagens (sem cache)..."
docker compose build --no-cache

# 3. Subir servi√ßos
echo "üöÄ Iniciando servi√ßos..."
docker compose up -d

# 4. Aguardar health checks
echo "‚è≥ Aguardando health checks..."
sleep 30

# 5. Validar
echo "üîç Validando containers..."
if docker ps --filter "name=audio-voice-api" --filter "health=healthy" | grep -q "audio-voice-api"; then
    echo "‚úÖ API healthy"
else
    echo "‚ùå API n√£o est√° healthy!"
    docker logs audio-voice-api --tail 50
    exit 1
fi

if docker ps --filter "name=audio-voice-celery" --filter "health=healthy" | grep -q "audio-voice-celery"; then
    echo "‚úÖ Celery healthy"
else
    echo "‚ö†Ô∏è Celery sem healthcheck (OK se esperado)"
fi

echo "‚úÖ Rebuild conclu√≠do com sucesso!"
```

**Valida√ß√£o:**
```bash
bash scripts/rebuild-audio-voice.sh
docker ps --filter "name=audio-voice"  # Deve mostrar 2 containers healthy
```

- [ ] Script criado em `scripts/rebuild-audio-voice.sh`
- [ ] Execut√°vel: `chmod +x scripts/rebuild-audio-voice.sh`
- [ ] Teste: Rebuild completo e verificar health

#### 1.3. Adicionar Target Makefile (Opcional)

**Implementa√ß√£o:**
```makefile
# services/audio-voice/Makefile
.PHONY: cleanup rebuild restart logs

cleanup:
	@echo "üßπ Cleanup audio-voice..."
	@bash ../../scripts/docker-cleanup-audio-voice.sh

rebuild:
	@echo "üî® Rebuild audio-voice..."
	@bash ../../scripts/rebuild-audio-voice.sh

restart:
	@echo "üîÑ Restart audio-voice..."
	docker compose restart

logs:
	@echo "üìã Logs audio-voice..."
	docker compose logs -f --tail=100

logs-celery:
	@echo "üìã Logs Celery..."
	docker logs audio-voice-celery -f --tail=100
```

**Valida√ß√£o:**
```bash
cd services/audio-voice
make cleanup
make rebuild
make logs-celery  # Verificar logs
```

- [ ] Makefile criado
- [ ] Testar todos os targets

#### 1.4. Verifica√ß√£o de Container √önico por Servi√ßo

**Teste:**
```bash
# test-single-container.sh
#!/bin/bash

API_COUNT=$(docker ps --filter "name=audio-voice-api" --format '{{.Names}}' | wc -l)
CELERY_COUNT=$(docker ps --filter "name=audio-voice-celery" --format '{{.Names}}' | wc -l)

if [ "$API_COUNT" -ne 1 ]; then
    echo "‚ùå ERRO: $API_COUNT containers API (esperado: 1)"
    exit 1
fi

if [ "$CELERY_COUNT" -ne 1 ]; then
    echo "‚ùå ERRO: $CELERY_COUNT containers Celery (esperado: 1)"
    exit 1
fi

echo "‚úÖ Apenas 1 container de cada tipo rodando"
```

**Valida√ß√£o:**
```bash
bash test-single-container.sh
```

- [ ] Teste criado
- [ ] Executar ap√≥s rebuild e confirmar sucesso

---

## üèÉ Sprint 2 ‚Äì Garantir F5-TTS em CUDA

**Dura√ß√£o:** 60-90 minutos  
**Prioridade:** üî¥ Cr√≠tica  
**Objetivo:** Ajustar Dockerfile/compose + c√≥digo para que F5-TTS rode em GPU (n√£o CPU hardcoded).

### Tarefas

#### 2.1. Atualizar Base Image CUDA

**Teste:**
```bash
# Verificar se imagem est√° deprecated
docker pull nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04 2>&1 | grep -i "deprec" && echo "‚ùå DEPRECATED" || echo "‚úÖ OK"
```

**Implementa√ß√£o:**
```dockerfile
# services/audio-voice/Dockerfile
# ANTES
# FROM nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04

# DEPOIS
FROM nvidia/cuda:12.4.1-cudnn9-runtime-ubuntu22.04
```

**Valida√ß√£o:**
```bash
cd services/audio-voice
docker build -t test-cuda-image . 2>&1 | grep -i "deprec"  # N√£o deve retornar nada
docker run --rm test-cuda-image nvidia-smi  # Deve funcionar
```

- [ ] Dockerfile atualizado
- [ ] Build de teste sem warnings de deprecation

#### 2.2. Garantir `--gpus` no Compose

**Valida√ß√£o Atual:**
```yaml
# services/audio-voice/docker-compose.yml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: all
          capabilities: [gpu]
```

‚úÖ **J√Å EST√Å CORRETO** (Docker Compose v2 usa `deploy.resources`)

**Teste Adicional:**
```bash
# Verificar se GPU est√° acess√≠vel
docker exec audio-voice-celery nvidia-smi --query-gpu=name --format=csv,noheader
```

- [ ] Validar que GPU est√° acess√≠vel
- [ ] Confirmar que CUDA 12.4 funciona

#### 2.3. Adicionar Verifica√ß√£o CUDA no Startup

**Implementa√ß√£o:**
```python
# services/audio-voice/app/cuda_check.py
"""
CUDA Availability Check
Executa no startup para validar GPU
"""
import logging
import torch

logger = logging.getLogger(__name__)

def check_cuda():
    """Verifica disponibilidade de CUDA e loga informa√ß√µes"""
    if not torch.cuda.is_available():
        logger.warning("‚ö†Ô∏è CUDA n√£o dispon√≠vel! Modelos rodar√£o em CPU.")
        return False
    
    gpu_name = torch.cuda.get_device_name(0)
    vram_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
    
    logger.info(f"‚úÖ CUDA dispon√≠vel: {gpu_name}")
    logger.info(f"üìä VRAM Total: {vram_total:.2f} GB")
    
    # Verificar se √© GPU pequena (<6GB)
    if vram_total < 6.0:
        logger.warning(f"‚ö†Ô∏è GPU pequena detectada ({vram_total:.2f}GB). Recomenda-se LOW_VRAM=true")
    
    return True

if __name__ == "__main__":
    check_cuda()
```

**Integra√ß√£o no startup:**
```python
# services/audio-voice/run.py (adicionar no in√≠cio)
from app.cuda_check import check_cuda

# Logo ap√≥s imports
logger.info("üöÄ Starting Audio Voice Service")
check_cuda()  # ‚Üê ADICIONAR AQUI
```

**Valida√ß√£o:**
```bash
docker logs audio-voice-api --tail 10 | grep "CUDA"
# Deve mostrar:
# ‚úÖ CUDA dispon√≠vel: NVIDIA GeForce GTX 1050 Ti
# üìä VRAM Total: 4.00 GB
# ‚ö†Ô∏è GPU pequena detectada (4.00GB). Recomenda-se LOW_VRAM=true
```

- [ ] `cuda_check.py` criado
- [ ] Integrado em `run.py`
- [ ] Logs confirmam GPU detectada

#### 2.4. Remover Hardcode CPU do F5-TTS

**Teste (antes da mudan√ßa):**
```bash
docker exec audio-voice-celery grep -n "self.device = 'cpu'" /app/app/engines/f5tts_engine.py
# Deve retornar linha 115
```

**Implementa√ß√£o:**
```python
# services/audio-voice/app/engines/f5tts_engine.py

# ANTES (linha 115)
# self.device = 'cpu'  # FIXME: Force CPU at√© implementar VRAM management
# logger.info(f"F5TtsEngine initializing on device: {self.device} (forced CPU to avoid OOM)")

# DEPOIS
self.device = self._select_device(device, fallback_to_cpu)
logger.info(f"F5TtsEngine initializing on device: {self.device}")

# Se LOW_VRAM desativado e GPU pequena, avisar
settings = get_settings()
if self.device == 'cuda' and not settings.get('low_vram_mode'):
    if torch.cuda.is_available():
        vram_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if vram_gb < 6.0:
            logger.warning(
                f"‚ö†Ô∏è GPU pequena ({vram_gb:.2f}GB) sem LOW_VRAM! "
                f"Recomenda-se LOW_VRAM=true para evitar OOM."
            )
```

**Valida√ß√£o:**
```bash
# Rebuild
make rebuild

# Verificar logs
docker logs audio-voice-celery 2>&1 | grep "F5TtsEngine initializing"
# Deve mostrar: F5TtsEngine initializing on device: cuda
```

- [ ] C√≥digo atualizado
- [ ] Rebuild executado
- [ ] Logs confirmam F5-TTS usando CUDA

#### 2.5. Criar Teste de Uso de GPU

**Teste:**
```python
# services/audio-voice/tests/test_gpu_usage.py
"""
Testa se F5-TTS est√° realmente usando GPU
"""
import pytest
import torch
from app.engines.f5tts_engine import F5TtsEngine

def test_f5tts_uses_gpu():
    """Verifica se F5-TTS inicializa em CUDA quando dispon√≠vel"""
    if not torch.cuda.is_available():
        pytest.skip("CUDA n√£o dispon√≠vel")
    
    engine = F5TtsEngine(device='cuda', fallback_to_cpu=False)
    
    assert engine.device == 'cuda', f"F5-TTS n√£o est√° em CUDA! Device: {engine.device}"
    
    # Verificar se modelo est√° em GPU (se j√° carregado)
    if engine.tts is not None:
        # F5-TTS API n√£o exp√µe device diretamente, mas podemos checar VRAM
        allocated_before = torch.cuda.memory_allocated()
        # Load model se lazy
        if hasattr(engine, '_load_model'):
            engine._load_model()
        allocated_after = torch.cuda.memory_allocated()
        
        assert allocated_after > allocated_before, "Nenhuma VRAM alocada (modelo n√£o em GPU?)"

def test_f5tts_fallback_cpu():
    """Verifica fallback para CPU quando GPU n√£o dispon√≠vel"""
    # Simular CUDA indispon√≠vel
    engine = F5TtsEngine(device='cpu', fallback_to_cpu=True)
    assert engine.device == 'cpu'
```

**Valida√ß√£o:**
```bash
cd services/audio-voice
docker exec audio-voice-celery pytest tests/test_gpu_usage.py -v
```

- [ ] Teste criado
- [ ] Executado com sucesso

---

## üèÉ Sprint 3 ‚Äì Corrigir Comportamento LOW_VRAM

**Dura√ß√£o:** 60-90 minutos  
**Prioridade:** üî¥ Cr√≠tica  
**Objetivo:** Fazer com que LOW_VRAM=true seja lido corretamente e modelos sejam carregados/descarregados dinamicamente.

### Tarefas

#### 3.1. Validar `.env` Atual

**Teste:**
```bash
# Verificar se .env tem LOW_VRAM correto
grep "^LOW_VRAM=" services/audio-voice/.env
# Deve retornar: LOW_VRAM=true
```

**Implementa√ß√£o (se necess√°rio):**
```bash
# Garantir que .env tem valor correto
cd services/audio-voice
if ! grep -q "^LOW_VRAM=true" .env; then
    echo "Corrigindo LOW_VRAM no .env..."
    sed -i 's/^LOW_VRAM=.*/LOW_VRAM=true/' .env
fi
```

- [ ] `.env` verificado e corrigido se necess√°rio

#### 3.2. For√ßar Recria√ß√£o de Containers (n√£o restart)

**Problema:** `docker compose restart` N√ÉO recarrega `env_file`

**Solu√ß√£o:**
```bash
cd services/audio-voice
docker compose down
docker compose up -d
```

**Valida√ß√£o:**
```bash
docker inspect audio-voice-celery --format '{{.Config.Env}}' | grep LOW_VRAM
# Deve retornar: LOW_VRAM=true
```

- [ ] Containers recriados (down + up)
- [ ] Vari√°vel LOW_VRAM=true confirmada no container

#### 3.3. Implementar Logs de Debug para LOW_VRAM

**Implementa√ß√£o:**
```python
# services/audio-voice/app/vram_manager.py (in√≠cio do __init__)

def __init__(self):
    settings = get_settings()
    self.low_vram_mode = settings.get('low_vram_mode', False)
    
    # Debug: Logar valor lido
    import os
    env_value = os.getenv('LOW_VRAM', 'NOT_SET')
    logger.info(f"üîç DEBUG: LOW_VRAM env={env_value}, parsed={self.low_vram_mode}")
    
    self._model_cache = {}
    
    if self.low_vram_mode:
        logger.info("üîã LOW VRAM MODE: ATIVADO - Modelos ser√£o carregados/descarregados automaticamente")
    else:
        logger.info("‚ö° NORMAL MODE: Modelos permanecer√£o na VRAM")
```

**Valida√ß√£o:**
```bash
docker logs audio-voice-celery 2>&1 | grep "DEBUG: LOW_VRAM"
# Deve mostrar:
# üîç DEBUG: LOW_VRAM env=true, parsed=True
# üîã LOW VRAM MODE: ATIVADO
```

- [ ] Logs de debug adicionados
- [ ] Rebuild executado
- [ ] Logs confirmam LOW_VRAM=true sendo lido

#### 3.4. Adicionar Logs Durante Load/Unload

**Implementa√ß√£o:**
```python
# services/audio-voice/app/vram_manager.py (m√©todo load_model)

@contextmanager
def load_model(self, model_key: str, load_fn: Callable, *args, **kwargs):
    model = None
    
    try:
        if self.low_vram_mode:
            logger.info(f"üîã LOW_VRAM: Carregando modelo '{model_key}' na GPU...")
            model = load_fn(*args, **kwargs)
            
            # Log VRAM usage ap√≥s load
            if torch.cuda.is_available():
                allocated = torch.cuda.memory_allocated() / 1024**3
                logger.info(f"üìä VRAM alocada ap√≥s load: {allocated:.2f} GB")
        else:
            # Usar cache
            if model_key not in self._model_cache:
                logger.info(f"‚ö° Carregando modelo '{model_key}' (primeira vez)")
                self._model_cache[model_key] = load_fn(*args, **kwargs)
            else:
                logger.debug(f"‚ö° Usando modelo '{model_key}' do cache")
            model = self._model_cache[model_key]
        
        yield model
    
    finally:
        # Descarregar apenas em modo LOW_VRAM
        if self.low_vram_mode and model is not None:
            logger.info(f"üîã LOW_VRAM: Descarregando modelo '{model_key}' da VRAM...")
            
            # Log VRAM antes
            if torch.cuda.is_available():
                before = torch.cuda.memory_allocated() / 1024**3
                
            self._unload_model(model)
            del model
            
            # Log VRAM depois
            if torch.cuda.is_available():
                after = torch.cuda.memory_allocated() / 1024**3
                freed = before - after
                logger.info(f"üìä VRAM liberada: {freed:.2f} GB (antes={before:.2f}, depois={after:.2f})")
```

**Valida√ß√£o:**
```bash
# Fazer uma requisi√ß√£o de s√≠ntese
curl -X POST http://localhost:8005/jobs \
  -H "Content-Type: application/json" \
  -d '{
    "mode": "dubbing_with_clone",
    "text": "Teste de VRAM",
    "language": "pt-BR",
    "voice_id": "82f8f815-ac80-4415-8091-7ebf833912ca"
  }'

# Monitorar logs
docker logs audio-voice-celery -f

# Deve mostrar:
# üîã LOW_VRAM: Carregando modelo 'f5tts' na GPU...
# üìä VRAM alocada ap√≥s load: 2.34 GB
# (processamento)
# üîã LOW_VRAM: Descarregando modelo 'f5tts' da VRAM...
# üìä VRAM liberada: 2.10 GB (antes=2.34, depois=0.24)
```

- [ ] Logs detalhados implementados
- [ ] Rebuild executado
- [ ] Teste de s√≠ntese mostra load/unload correto

#### 3.5. Criar Teste de VRAM Management

**Teste:**
```python
# services/audio-voice/tests/test_vram_management.py
"""
Testa comportamento de LOW_VRAM mode
"""
import pytest
import torch
from app.vram_manager import get_vram_manager
from app.config import get_settings

@pytest.fixture
def vram_manager():
    return get_vram_manager()

def test_low_vram_mode_enabled(vram_manager):
    """Verifica se LOW_VRAM mode est√° ativado quando configurado"""
    settings = get_settings()
    
    # Se LOW_VRAM=true no .env
    if settings.get('low_vram_mode'):
        assert vram_manager.low_vram_mode is True
    else:
        pytest.skip("LOW_VRAM n√£o configurado")

def test_vram_freed_after_inference(vram_manager):
    """Verifica se VRAM √© liberada ap√≥s inference em modo LOW_VRAM"""
    if not torch.cuda.is_available():
        pytest.skip("CUDA n√£o dispon√≠vel")
    
    if not vram_manager.low_vram_mode:
        pytest.skip("LOW_VRAM n√£o ativado")
    
    # Baseline VRAM
    torch.cuda.empty_cache()
    baseline = torch.cuda.memory_allocated()
    
    # Simular carregamento de modelo
    def dummy_load():
        # Alocar tensor grande
        return torch.randn(1000, 1000, 1000, device='cuda')
    
    with vram_manager.load_model('test', dummy_load):
        during = torch.cuda.memory_allocated()
        assert during > baseline, "VRAM n√£o aumentou durante load"
    
    # Ap√≥s context manager, VRAM deve voltar ao baseline
    torch.cuda.synchronize()
    after = torch.cuda.memory_allocated()
    
    # Toler√¢ncia de 100MB
    assert abs(after - baseline) < 100 * 1024**2, \
        f"VRAM n√£o foi liberada! Baseline={baseline/1024**2:.0f}MB, After={after/1024**2:.0f}MB"
```

**Valida√ß√£o:**
```bash
docker exec audio-voice-celery pytest tests/test_vram_management.py -v -s
```

- [ ] Teste criado
- [ ] Executado com sucesso (VRAM liberada confirmada)

---

## üèÉ Sprint 4 ‚Äì QA Final e Observabilidade

**Dura√ß√£o:** 45-60 minutos  
**Prioridade:** ‚ö†Ô∏è Alta  
**Objetivo:** Garantir que tudo est√° est√°vel, observ√°vel e documentado.

### Tarefas

#### 4.1. Validar Ciclo Completo

**Teste End-to-End:**
```bash
#!/bin/bash
# tests/e2e-test-low-vram.sh

set -e

echo "üß™ Teste E2E: LOW_VRAM mode"

# 1. Cleanup
echo "1Ô∏è‚É£ Cleanup..."
bash scripts/docker-cleanup-audio-voice.sh

# 2. Rebuild
echo "2Ô∏è‚É£ Rebuild..."
bash scripts/rebuild-audio-voice.sh

# 3. Aguardar startup
echo "3Ô∏è‚É£ Aguardando startup completo (60s)..."
sleep 60

# 4. Verificar LOW_VRAM nos logs
echo "4Ô∏è‚É£ Verificando LOW_VRAM mode..."
if docker logs audio-voice-celery 2>&1 | grep -q "üîã LOW VRAM MODE: ATIVADO"; then
    echo "‚úÖ LOW_VRAM ativado"
else
    echo "‚ùå LOW_VRAM N√ÉO est√° ativado!"
    exit 1
fi

# 5. Fazer clone de voz
echo "5Ô∏è‚É£ Clonando voz de teste..."
CLONE_RESPONSE=$(curl -s -X POST http://localhost:8005/voices/clone \
  -F "audio=@services/audio-voice/tests/Teste.ogg" \
  -F "language=pt-BR" \
  -F "voice_name=TesteLowVRAM")

VOICE_ID=$(echo $CLONE_RESPONSE | jq -r '.voice_id')
echo "Voice ID: $VOICE_ID"

# 6. Aguardar job de clone
sleep 10

# 7. Fazer s√≠ntese com F5-TTS
echo "6Ô∏è‚É£ Sintetizando com F5-TTS..."
JOB_RESPONSE=$(curl -s -X POST http://localhost:8005/jobs \
  -H "Content-Type: application/json" \
  -d "{
    \"mode\": \"dubbing_with_clone\",
    \"text\": \"Este √© um teste completo do modo LOW VRAM com F5-TTS em CUDA.\",
    \"language\": \"pt-BR\",
    \"voice_id\": \"$VOICE_ID\",
    \"quality_profile\": \"f5tts_balanced\"
  }")

JOB_ID=$(echo $JOB_RESPONSE | jq -r '.job_id')
echo "Job ID: $JOB_ID"

# 8. Aguardar processamento
echo "7Ô∏è‚É£ Aguardando processamento (at√© 5min)..."
for i in {1..60}; do
    STATUS=$(curl -s http://localhost:8005/jobs/$JOB_ID | jq -r '.status')
    echo "   Status: $STATUS (tentativa $i/60)"
    
    if [ "$STATUS" == "completed" ]; then
        echo "‚úÖ Job completado!"
        break
    elif [ "$STATUS" == "failed" ]; then
        echo "‚ùå Job falhou!"
        docker logs audio-voice-celery --tail 100
        exit 1
    fi
    
    sleep 5
done

# 9. Verificar logs de VRAM
echo "8Ô∏è‚É£ Verificando logs de VRAM management..."
if docker logs audio-voice-celery 2>&1 | grep -q "üìä VRAM liberada:"; then
    echo "‚úÖ VRAM foi liberada ap√≥s s√≠ntese"
else
    echo "‚ö†Ô∏è N√£o encontrado log de VRAM liberada (pode ser normal se cache usado)"
fi

# 10. Verificar uso de GPU (n√£o CPU)
echo "9Ô∏è‚É£ Verificando se F5-TTS usou GPU..."
if docker logs audio-voice-celery 2>&1 | grep -q "F5TtsEngine initializing on device: cuda"; then
    echo "‚úÖ F5-TTS usando CUDA"
else
    echo "‚ùå F5-TTS N√ÉO est√° usando CUDA!"
    exit 1
fi

echo "üéâ Teste E2E PASSOU!"
```

**Valida√ß√£o:**
```bash
bash tests/e2e-test-low-vram.sh
```

- [ ] Script E2E criado
- [ ] Executado com sucesso

#### 4.2. Adicionar Health Check no Celery

**Implementa√ß√£o:**
```yaml
# services/audio-voice/docker-compose.yml

celery-worker:
  # ... (existente)
  healthcheck:
    test: ["CMD-SHELL", "python -c \"from celery import Celery; app = Celery(); app.broker_connection().ensure_connection(max_retries=3)\" || exit 1"]
    interval: 30s
    timeout: 10s
    retries: 5
    start_period: 60s
```

**Valida√ß√£o:**
```bash
docker compose up -d
sleep 60
docker ps --filter "name=audio-voice-celery" --filter "health=healthy"
# Deve mostrar container healthy
```

- [ ] Health check adicionado
- [ ] Containers recriados
- [ ] Health check passing

#### 4.3. Criar Endpoint de Monitoramento VRAM

**Implementa√ß√£o:**
```python
# services/audio-voice/app/main.py (adicionar endpoint)

from app.vram_manager import get_vram_manager

@app.get("/admin/vram", tags=["Admin"])
async def get_vram_stats():
    """
    Retorna estat√≠sticas de uso de VRAM.
    
    √ötil para monitoramento e debugging de LOW_VRAM mode.
    """
    vram_mgr = get_vram_manager()
    stats = vram_mgr.get_vram_stats()
    
    return {
        "vram": stats,
        "timestamp": datetime.now().isoformat()
    }
```

**Valida√ß√£o:**
```bash
curl -s http://localhost:8005/admin/vram | jq
# Deve retornar:
# {
#   "vram": {
#     "available": true,
#     "low_vram_mode": true,
#     "allocated_gb": 0.24,
#     "reserved_gb": 0.50,
#     "free_gb": 2.14,
#     "total_gb": 4.00,
#     "cached_models": 0
#   },
#   "timestamp": "2025-11-28T01:30:00"
# }
```

- [ ] Endpoint criado
- [ ] Testado e retornando dados corretos

#### 4.4. Ajustar Logs para Monitoramento

**Implementa√ß√£o:**
```python
# services/audio-voice/app/engines/f5tts_engine.py (no final de generate_dubbing)

# Ap√≥s s√≠ntese bem-sucedida
logger.info(
    f"‚úÖ F5-TTS synthesis complete: {duration:.2f}s, {len(audio_bytes)} bytes "
    f"[device={self.device}, low_vram={settings.get('low_vram_mode')}]"
)
```

**Valida√ß√£o:**
```bash
docker logs audio-voice-celery 2>&1 | grep "F5-TTS synthesis complete"
# Deve mostrar device e low_vram mode
```

- [ ] Logs aprimorados
- [ ] Informa√ß√µes de device/VRAM vis√≠veis

#### 4.5. Documentar Uso e Troubleshooting

**Implementa√ß√£o:**
```markdown
# services/audio-voice/VRAM_TROUBLESHOOTING.md

# VRAM Troubleshooting Guide

## Como verificar se LOW_VRAM est√° ativado

```bash
# 1. Verificar .env
grep LOW_VRAM services/audio-voice/.env
# Deve retornar: LOW_VRAM=true

# 2. Verificar container
docker inspect audio-voice-celery --format '{{.Config.Env}}' | grep LOW_VRAM
# Deve retornar: LOW_VRAM=true

# 3. Verificar logs
docker logs audio-voice-celery 2>&1 | grep "LOW VRAM MODE"
# Deve mostrar: üîã LOW VRAM MODE: ATIVADO
```

## Se LOW_VRAM n√£o estiver ativado

1. **Edite `.env`:**
   ```bash
   cd services/audio-voice
   sed -i 's/^LOW_VRAM=.*/LOW_VRAM=true/' .env
   ```

2. **IMPORTANTE: N√£o use `docker restart`! Use:**
   ```bash
   docker compose down
   docker compose up -d
   ```

3. **Verifique novamente:**
   ```bash
   docker logs audio-voice-celery 2>&1 | grep "LOW VRAM MODE"
   ```

## Como monitorar uso de VRAM

### Tempo real (nvidia-smi)
```bash
watch -n 1 nvidia-smi
```

### Endpoint HTTP
```bash
curl -s http://localhost:8005/admin/vram | jq
```

### Logs detalhados
```bash
docker logs audio-voice-celery -f | grep -E "(VRAM|carregando|descarregando)"
```

## Troubleshooting: OOM (Out of Memory)

Se voc√™ ver `RuntimeError: CUDA out of memory`:

1. ‚úÖ **Certifique-se que LOW_VRAM est√° ativado** (veja acima)
2. ‚úÖ **Reduza concorr√™ncia do Celery:**
   ```yaml
   # docker-compose.yml
   command: ... --concurrency=1  # ‚Üê Deve ser 1!
   ```
3. ‚úÖ **N√£o rode XTTS e F5-TTS simultaneamente** (LOW_VRAM evita isso)
4. ‚ö†Ô∏è **Se ainda falhar:** GPU pode ser muito pequena (<4GB), use CPU:
   ```env
   F5TTS_DEVICE=cpu
   XTTS_DEVICE=cuda  # Apenas XTTS em GPU
   ```
```

- [ ] Documento criado
- [ ] Instru√ß√µes validadas

---

## ‚úÖ Checklist Final de Valida√ß√£o

Ap√≥s completar todas as sprints, validar:

### Containers
- [ ] `docker ps` mostra apenas 2 containers (API + Celery)
- [ ] Ambos containers mostram `(healthy)`
- [ ] N√£o h√° containers √≥rf√£os (`docker ps -a` sem `<none>`)

### LOW_VRAM
- [ ] `docker inspect audio-voice-celery | grep LOW_VRAM` retorna `true`
- [ ] Logs mostram `üîã LOW VRAM MODE: ATIVADO`
- [ ] Durante s√≠ntese, logs mostram:
  - `üîã LOW_VRAM: Carregando modelo 'f5tts' na GPU...`
  - `üìä VRAM alocada ap√≥s load: X.XX GB`
  - `üîã LOW_VRAM: Descarregando modelo 'f5tts' da VRAM...`
  - `üìä VRAM liberada: X.XX GB`

### F5-TTS em CUDA
- [ ] Logs mostram `F5TtsEngine initializing on device: cuda`
- [ ] `nvidia-smi` mostra VRAM sendo alocada durante s√≠ntese
- [ ] Ap√≥s s√≠ntese, VRAM volta ao baseline (XTTS apenas)

### Docker
- [ ] Base image √© `nvidia/cuda:12.4.1` (n√£o deprecated)
- [ ] Build n√£o mostra warnings de deprecation
- [ ] `docker images | grep audio-voice` n√£o mostra `<none>`

### Testes
- [ ] `pytest tests/test_gpu_usage.py` passa
- [ ] `pytest tests/test_vram_management.py` passa
- [ ] `bash tests/e2e-test-low-vram.sh` passa

### Observabilidade
- [ ] `curl http://localhost:8005/admin/vram` retorna stats corretos
- [ ] Health checks passando (API + Celery)
- [ ] Logs cont√™m informa√ß√µes de device e VRAM usage

---

## üìä Estimativa de Tempo

| Sprint | Tarefas | Tempo Estimado | Complexidade |
|--------|---------|----------------|--------------|
| Sprint 1 | Padronizar ciclo de vida | 45-60 min | Baixa |
| Sprint 2 | F5-TTS em CUDA | 60-90 min | M√©dia |
| Sprint 3 | Corrigir LOW_VRAM | 60-90 min | Alta |
| Sprint 4 | QA final | 45-60 min | M√©dia |
| **TOTAL** | - | **3.5-5 horas** | - |

---

## üéØ Pr√≥ximos Passos

Ap√≥s concluir TODAS as sprints:

1. ‚úÖ Marcar todos os checkboxes acima
2. ‚úÖ Commitar mudan√ßas com mensagem descritiva:
   ```bash
   git add -A
   git commit -m "fix(audio-voice): Ativar LOW_VRAM + F5-TTS em CUDA

   - Corrigido LOW_VRAM n√£o sendo lido (env_file reload)
   - Removido hardcode CPU do F5-TTS (agora usa CUDA)
   - Atualizado base image CUDA (12.1 ‚Üí 12.4)
   - Implementado scripts de cleanup e rebuild sistem√°ticos
   - Adicionado health check no Celery
   - Criado endpoint /admin/vram para monitoramento
   - Adicionados testes de GPU usage e VRAM management
   
   Fixes #<issue_number>"
   ```
3. ‚úÖ Testar em ambiente staging (se dispon√≠vel)
4. ‚úÖ Deploy em produ√ß√£o

---

**Fim do Plano de Implementa√ß√£o**

**Pr√≥ximo passo:** Executar Sprint 1!
