# üìù Audio Transcriber - Transcri√ß√£o e Tradu√ß√£o

O **Audio Transcriber** √© respons√°vel por converter √°udio em texto usando modelos de speech-to-text (Whisper) e realizar tradu√ß√µes quando necess√°rio.

## üéØ Fun√ß√£o

- Transcri√ß√£o de √°udio para texto usando OpenAI Whisper
- Detec√ß√£o autom√°tica de idioma
- Tradu√ß√£o entre idiomas
- Gera√ß√£o de timestamps precisos
- Segmenta√ß√£o inteligente do texto
- M√∫ltiplos formatos de sa√≠da (SRT, VTT, TXT, JSON)

## üîß Configura√ß√£o

### Vari√°veis de Ambiente Principais

```bash
# Servidor
HOST=0.0.0.0
PORT=8002

# Redis
REDIS_URL=redis://localhost:6379/2

# Whisper/OpenAI
OPENAI_API_KEY=sk-...                    # Chave da OpenAI (opcional)
WHISPER_MODEL=base                       # tiny, base, small, medium, large
USE_LOCAL_WHISPER=true                   # Usar Whisper local vs API

# Processamento
MAX_FILE_SIZE_MB=100
TRANSCRIPTION_TIMEOUT_SECONDS=600
TEMP_DIR=./temp
TRANSCRIPTIONS_DIR=./transcriptions

# Cache
CACHE_TTL_HOURS=24
```

### Inicializa√ß√£o

```bash
cd services/audio-transcriber

# Instalar depend√™ncias
pip install -r requirements.txt

# Download do modelo Whisper (primeira execu√ß√£o)
python -c "import whisper; whisper.load_model('base')"

# Iniciar servi√ßo
python run.py
```

## üì° API Endpoints

### Jobs Principais

#### `POST /jobs`
Cria job de transcri√ß√£o.

**Request** (multipart/form-data):
```
file: [arquivo_audio.wav]           # Arquivo de √°udio normalizado
language_in: "auto"                 # Idioma de entrada ("auto", "pt", "en", etc.)
language_out: "en"                  # Idioma de sa√≠da (opcional, para tradu√ß√£o)
```

**Response:**
```json
{
  "id": "trans_xyz789abc123",
  "status": "queued",
  "progress": 0.0,
  "created_at": "2025-10-29T10:10:00Z",
  "original_filename": "normalized_abc123def456.wav",
  "file_size": 16234567,
  "language_in": "auto",
  "language_out": "en",
  "detected_language": null,
  "model_used": "base"
}
```

#### `GET /jobs/{job_id}`
Consulta status do job de transcri√ß√£o.

**Response:**
```json
{
  "id": "trans_xyz789abc123",
  "status": "completed",
  "progress": 100.0,
  "created_at": "2025-10-29T10:10:00Z",
  "updated_at": "2025-10-29T10:15:30Z",
  "completed_at": "2025-10-29T10:15:30Z",
  "original_filename": "normalized_abc123def456.wav",
  "transcription_filename": "transcription_xyz789abc123.srt",
  "file_size": 16234567,
  "duration": 180.5,
  "processing_time": 330.2,
  "language_in": "auto",
  "language_out": "en",
  "detected_language": "pt",
  "model_used": "base",
  "word_count": 425,
  "segment_count": 18,
  "confidence_avg": 0.92,
  "audio_info": {
    "sample_rate": 16000,
    "channels": 1,
    "format": "wav",
    "duration": 180.5
  }
}
```

#### `GET /jobs/{job_id}/download`
Download do arquivo de transcri√ß√£o (SRT padr√£o).

**Response**: Arquivo SRT com headers:
```
Content-Type: text/plain; charset=utf-8
Content-Disposition: attachment; filename="transcription_xyz789abc123.srt"
```

#### `GET /jobs/{job_id}/text`
Obt√©m apenas o texto da transcri√ß√£o.

**Response:**
```json
{
  "text": "Ol√°, bem-vindos ao meu canal. Hoje vamos falar sobre intelig√™ncia artificial e como ela est√° mudando o mundo. Primeiro, vamos entender o que √© machine learning..."
}
```

#### `GET /jobs/{job_id}/transcription`
Obt√©m transcri√ß√£o completa com segments e timestamps.

**Response:**
```json
{
  "job_id": "trans_xyz789abc123",
  "detected_language": "pt",
  "translated_to": "en",
  "full_text": "Hello, welcome to my channel. Today we're going to talk about artificial intelligence...",
  "segments": [
    {
      "id": 0,
      "start": 0.0,
      "end": 3.2,
      "duration": 3.2,
      "text": "Hello, welcome to my channel.",
      "words": [
        {
          "word": "Hello",
          "start": 0.0,
          "end": 0.5,
          "confidence": 0.95
        },
        {
          "word": "welcome",
          "start": 0.8,
          "end": 1.2,
          "confidence": 0.92
        }
      ],
      "avg_confidence": 0.94,
      "no_speech_prob": 0.02
    }
  ],
  "statistics": {
    "total_segments": 18,
    "total_words": 425,
    "total_duration": 180.5,
    "avg_confidence": 0.92,
    "speech_percentage": 0.85
  }
}
```

### Idiomas e Modelos

#### `GET /languages`
Lista idiomas suportados.

**Response:**
```json
{
  "supported_languages": {
    "auto": "Detec√ß√£o Autom√°tica",
    "pt": "Portugu√™s",
    "en": "English", 
    "es": "Espa√±ol",
    "fr": "Fran√ßais",
    "de": "Deutsch",
    "it": "Italiano",
    "ja": "Êó•Êú¨Ë™û",
    "ko": "ÌïúÍµ≠Ïñ¥",
    "zh": "‰∏≠Êñá",
    "ru": "–†—É—Å—Å–∫–∏–π",
    "ar": "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©"
  },
  "translation_pairs": [
    "pt->en", "en->pt", "es->en", "fr->en", 
    "de->en", "it->en", "ja->en", "ko->en",
    "zh->en", "ru->en", "ar->en"
  ],
  "models_available": [
    "tiny", "base", "small", "medium", "large"
  ]
}
```

### Gerenciamento

#### `GET /jobs`
Lista jobs recentes de transcri√ß√£o.

#### `DELETE /jobs/{job_id}`
Remove job e arquivos associados.

### Administra√ß√£o  

#### `GET /admin/stats`
Estat√≠sticas do servi√ßo.

**Response:**
```json
{
  "jobs": {
    "total": 85,
    "completed": 80,
    "failed": 3,
    "processing": 2
  },
  "transcription": {
    "total_hours_processed": 45.8,
    "avg_processing_time": 215.5,
    "avg_confidence": 0.89,
    "languages_detected": {
      "pt": 35,
      "en": 30,
      "es": 15,
      "fr": 5
    }
  },
  "models": {
    "current_model": "base",
    "model_performance": {
      "tiny": { "speed": "5x", "accuracy": "80%" },
      "base": { "speed": "3x", "accuracy": "85%" },
      "small": { "speed": "2x", "accuracy": "90%" }
    }
  },
  "disk_usage": {
    "temp_dir_mb": 250.5,
    "transcriptions_dir_mb": 45.2,
    "models_dir_gb": 2.8
  }
}
```

#### `POST /admin/cleanup`
Limpeza de arquivos tempor√°rios.

### Health Check

#### `GET /health`
Verifica sa√∫de do servi√ßo.

**Response:**
```json
{
  "status": "healthy",
  "service": "audio-transcriber-service",
  "version": "2.0.0",
  "dependencies": {
    "whisper": "‚úÖ Modelo 'base' carregado",
    "torch": "‚úÖ CUDA dispon√≠vel",
    "redis": "‚úÖ Conectado",
    "disk_space": "‚úÖ 12.5GB livres"
  },
  "performance": {
    "model_loaded": "base",
    "gpu_available": true,
    "avg_processing_speed": "2.1x realtime",
    "concurrent_jobs": 1,
    "max_concurrent": 2
  }
}
```

## üîÑ Estados de Job

1. **queued** - Job criado, aguardando processamento
2. **loading_model** - Carregando modelo Whisper
3. **transcribing** - Transcri√ß√£o em andamento
4. **translating** - Tradu√ß√£o em andamento (se aplic√°vel)
5. **completed** - Processamento conclu√≠do
6. **failed** - Falha no processamento

## üó£Ô∏è Modelos Whisper

### Modelos Dispon√≠veis

| Modelo | Tamanho | Velocidade | Precis√£o | Uso Recomendado |
|--------|---------|------------|----------|-----------------|
| `tiny` | 39 MB | ~5x realtime | ~80% | Desenvolvimento/testes |
| `base` | 74 MB | ~3x realtime | ~85% | **Padr√£o recomendado** |
| `small` | 244 MB | ~2x realtime | ~90% | Alta qualidade |
| `medium` | 769 MB | ~1.5x realtime | ~93% | Produ√ß√£o cr√≠tica |
| `large` | 1550 MB | ~1x realtime | ~95% | M√°xima precis√£o |

### Configura√ß√£o de Modelo
```python
# Mudan√ßa de modelo (requer reinicializa√ß√£o)
WHISPER_MODEL=small

# Par√¢metros de processamento
WHISPER_TEMPERATURE=0.0        # Determin√≠stico
WHISPER_BEST_OF=5             # M√∫ltiplas tentativas
WHISPER_BEAM_SIZE=5           # Beam search
```

## üåç Suporte a Idiomas

### Detec√ß√£o Autom√°tica
- **99 idiomas** suportados pelo Whisper
- **Detec√ß√£o autom√°tica** com confian√ßa > 90%
- **Fallback**: Ingl√™s se detec√ß√£o falhar

### Idiomas Principais
- **Portugu√™s** (pt) - Excelente
- **Ingl√™s** (en) - Excelente  
- **Espanhol** (es) - Excelente
- **Franc√™s** (fr) - Muito bom
- **Alem√£o** (de) - Muito bom
- **Italiano** (it) - Bom
- **Japon√™s** (ja) - Bom
- **Chin√™s** (zh) - Bom
- **Russo** (ru) - Bom
- **√Årabe** (ar) - Regular

### Tradu√ß√£o
- **Destino**: Sempre ingl√™s (limita√ß√£o Whisper)
- **Qualidade**: Varia por idioma origem
- **Uso**: Especificar `language_out: "en"`

## üìÑ Formatos de Sa√≠da

### SRT (SubRip)
```srt
1
00:00:00,000 --> 00:00:03,200
Hello, welcome to my channel.

2
00:00:03,500 --> 00:00:08,100
Today we're going to talk about artificial intelligence.
```

### VTT (WebVTT)
```vtt
WEBVTT

00:00:00.000 --> 00:00:03.200
Hello, welcome to my channel.

00:00:03.500 --> 00:00:08.100
Today we're going to talk about artificial intelligence.
```

### JSON (Completo)
```json
{
  "segments": [
    {
      "start": 0.0,
      "end": 3.2,
      "text": "Hello, welcome to my channel.",
      "confidence": 0.94
    }
  ]
}
```

## üéØ Qualidade e Precis√£o

### M√©tricas de Confian√ßa
- **Por palavra**: 0.0 - 1.0
- **Por segmento**: M√©dia das palavras
- **Geral**: M√©dia ponderada por dura√ß√£o

### Fatores que Afetam Qualidade
- **Qualidade do √°udio**: Ru√≠do, distor√ß√£o
- **Velocidade da fala**: Muito r√°pido/lento
- **Sotaque/dialeto**: Varia√ß√µes regionais
- **M√∫ltiplos falantes**: Sobreposi√ß√£o
- **M√∫sica de fundo**: Interfere na transcri√ß√£o

### Otimiza√ß√µes
- **Normaliza√ß√£o pr√©via**: Audio Normalization service
- **Sample rate**: 16kHz otimizado
- **Formato**: WAV PCM preferido
- **Dura√ß√£o**: Segmentos 5-30 minutos ideais

## üö® Troubleshooting

### Job Stuck em "loading_model"
**Causa**: Modelo Whisper n√£o encontrado
**Solu√ß√£o**: `python -c "import whisper; whisper.load_model('base')"`

### Baixa Precis√£o na Transcri√ß√£o
**Causa**: √Åudio de baixa qualidade ou idioma n√£o suportado
**Solu√ß√£o**: Melhorar normaliza√ß√£o ou verificar idioma

### "CUDA Out of Memory"
**Causa**: Modelo muito grande para GPU dispon√≠vel
**Solu√ß√£o**: Usar modelo menor ou CPU

### Timeout no Processamento
**Causa**: Arquivo muito longo ou modelo lento
**Solu√ß√£o**: Aumentar timeout ou usar modelo mais r√°pido

### Tradu√ß√£o de Baixa Qualidade  
**Causa**: Limita√ß√µes do modelo para o par de idiomas
**Solu√ß√£o**: Usar servi√ßo de tradu√ß√£o especializado

## ‚ö° Performance

### Otimiza√ß√µes GPU
```python
# CUDA settings
TORCH_DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
WHISPER_DEVICE = "cuda"
WHISPER_FP16 = True  # Half precision para economia de VRAM
```

### Otimiza√ß√µes CPU
```python
# Threading
TORCH_THREADS = 4
OMP_NUM_THREADS = 4

# Memory management
WHISPER_CHUNK_LENGTH = 30  # Processar em chunks de 30s
```

## üìä Monitoramento

### Logs Estruturados
```
INFO - Job trans_xyz789 iniciado: pt -> en (180.5s audio)
INFO - Modelo 'base' carregado (GPU: Tesla T4)
INFO - Detec√ß√£o de idioma: pt (confian√ßa: 0.98)
INFO - Transcri√ß√£o completada: 425 palavras, confian√ßa m√©dia: 0.92
INFO - Tradu√ß√£o completada: pt -> en
INFO - Job trans_xyz789 finalizado em 330.2s
```

### M√©tricas Importantes
- Tempo de processamento vs dura√ß√£o do √°udio
- Confian√ßa m√©dia por job
- Distribui√ß√£o de idiomas detectados
- Taxa de uso GPU vs CPU
- Cache hit rate

## üìÅ Estrutura de Arquivos

```
services/audio-transcriber/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py           # API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ processor.py      # L√≥gica de transcri√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ models.py         # Modelos de dados  
‚îÇ   ‚îú‚îÄ‚îÄ whisper_client.py # Interface Whisper
‚îÇ   ‚îú‚îÄ‚îÄ redis_store.py    # Interface Redis
‚îÇ   ‚îî‚îÄ‚îÄ config.py         # Configura√ß√µes
‚îú‚îÄ‚îÄ temp/                 # Arquivos tempor√°rios
‚îú‚îÄ‚îÄ transcriptions/       # Transcri√ß√µes geradas
‚îú‚îÄ‚îÄ models/               # Modelos Whisper baixados
‚îú‚îÄ‚îÄ logs/                 # Logs do servi√ßo
‚îî‚îÄ‚îÄ requirements.txt      # Depend√™ncias
```

---

**Porta**: 8002 | **Vers√£o**: 2.0.0 | **Tech**: FastAPI + Whisper + PyTorch