# ğŸ“ Audio Transcriber - TranscriÃ§Ã£o e TraduÃ§Ã£o

O **Audio Transcriber** Ã© responsÃ¡vel por converter Ã¡udio em texto usando modelos de speech-to-text (Whisper) e realizar traduÃ§Ãµes quando necessÃ¡rio.

## ğŸ¯ FunÃ§Ã£o

- TranscriÃ§Ã£o de Ã¡udio para texto usando OpenAI Whisper
- DetecÃ§Ã£o automÃ¡tica de idioma
- TraduÃ§Ã£o entre idiomas
- GeraÃ§Ã£o de timestamps precisos
- SegmentaÃ§Ã£o inteligente do texto
- MÃºltiplos formatos de saÃ­da (SRT, VTT, TXT, JSON)

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente Principais

```bash
# Servidor
HOST=0.0.0.0
PORT=8002

# Redis
REDIS_URL=redis://localhost:6379/2

# Whisper/OpenAI
OPENAI_API_KEY=sk-...                    # Chave da OpenAI (opcional)
WHISPER_MODEL=base                       # tiny, base, small, medium, large
USE_LOCAL_WHISPER=true                   # Usar Whisper local vs API

# Processamento
MAX_FILE_SIZE_MB=100
TRANSCRIPTION_TIMEOUT_SECONDS=600
TEMP_DIR=./temp
TRANSCRIPTIONS_DIR=./transcriptions

# Cache
CACHE_TTL_HOURS=24
```

### InicializaÃ§Ã£o

```bash
cd services/audio-transcriber

# Instalar dependÃªncias
pip install -r requirements.txt

# Download do modelo Whisper (primeira execuÃ§Ã£o)
python -c "import whisper; whisper.load_model('base')"

# Iniciar serviÃ§o
python run.py
```

## ğŸ“¡ API Endpoints

### Jobs Principais

#### `POST /jobs`
Cria job de transcriÃ§Ã£o.

**Request** (multipart/form-data):
```
file: [arquivo_audio.wav]           # Arquivo de Ã¡udio normalizado
language_in: "auto"                 # Idioma de entrada ("auto", "pt", "en", etc.)
language_out: "en"                  # Idioma de saÃ­da (opcional, para traduÃ§Ã£o)
```

**Response:**
```json
{
  "id": "trans_xyz789abc123",
  "status": "queued",
  "progress": 0.0,
  "created_at": "2025-10-29T10:10:00Z",
  "original_filename": "normalized_abc123def456.wav",
  "file_size": 16234567,
  "language_in": "auto",
  "language_out": "en",
  "detected_language": null,
  "model_used": "base"
}
```

#### `GET /jobs/{job_id}`
Consulta status do job de transcriÃ§Ã£o.

**Response:**
```json
{
  "id": "trans_xyz789abc123",
  "status": "completed",
  "progress": 100.0,
  "created_at": "2025-10-29T10:10:00Z",
  "updated_at": "2025-10-29T10:15:30Z",
  "completed_at": "2025-10-29T10:15:30Z",
  "original_filename": "normalized_abc123def456.wav",
  "transcription_filename": "transcription_xyz789abc123.srt",
  "file_size": 16234567,
  "duration": 180.5,
  "processing_time": 330.2,
  "language_in": "auto",
  "language_out": "en",
  "detected_language": "pt",
  "model_used": "base",
  "word_count": 425,
  "segment_count": 18,
  "confidence_avg": 0.92,
  "audio_info": {
    "sample_rate": 16000,
    "channels": 1,
    "format": "wav",
    "duration": 180.5
  }
}
```

#### `GET /jobs/{job_id}/download`
Download do arquivo de transcriÃ§Ã£o (SRT padrÃ£o).

**Response**: Arquivo SRT com headers:
```
Content-Type: text/plain; charset=utf-8
Content-Disposition: attachment; filename="transcription_xyz789abc123.srt"
```

#### `GET /jobs/{job_id}/text`
ObtÃ©m apenas o texto da transcriÃ§Ã£o.

**Response:**
```json
{
  "text": "OlÃ¡, bem-vindos ao meu canal. Hoje vamos falar sobre inteligÃªncia artificial e como ela estÃ¡ mudando o mundo. Primeiro, vamos entender o que Ã© machine learning..."
}
```

#### `GET /jobs/{job_id}/transcription`
ObtÃ©m transcriÃ§Ã£o completa com segments e timestamps.

**Response:**
```json
{
  "job_id": "trans_xyz789abc123",
  "detected_language": "pt",
  "translated_to": "en",
  "full_text": "Hello, welcome to my channel. Today we're going to talk about artificial intelligence...",
  "segments": [
    {
      "id": 0,
      "start": 0.0,
      "end": 3.2,
      "duration": 3.2,
      "text": "Hello, welcome to my channel.",
      "words": [
        {
          "word": "Hello",
          "start": 0.0,
          "end": 0.5,
          "confidence": 0.95
        },
        {
          "word": "welcome",
          "start": 0.8,
          "end": 1.2,
          "confidence": 0.92
        }
      ],
      "avg_confidence": 0.94,
      "no_speech_prob": 0.02
    }
  ],
  "statistics": {
    "total_segments": 18,
    "total_words": 425,
    "total_duration": 180.5,
    "avg_confidence": 0.92,
    "speech_percentage": 0.85
  }
}
```

### Idiomas e Modelos

#### `GET /languages`
Lista idiomas suportados.

**Response:**
```json
{
  "supported_languages": {
    "auto": "DetecÃ§Ã£o AutomÃ¡tica",
    "pt": "PortuguÃªs",
    "en": "English", 
    "es": "EspaÃ±ol",
    "fr": "FranÃ§ais",
    "de": "Deutsch",
    "it": "Italiano",
    "ja": "æ—¥æœ¬èª",
    "ko": "í•œêµ­ì–´",
    "zh": "ä¸­æ–‡",
    "ru": "Ğ ÑƒÑÑĞºĞ¸Ğ¹",
    "ar": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
  },
  "translation_pairs": [
    "pt->en", "en->pt", "es->en", "fr->en", 
    "de->en", "it->en", "ja->en", "ko->en",
    "zh->en", "ru->en", "ar->en"
  ],
  "models_available": [
    "tiny", "base", "small", "medium", "large"
  ]
}
```

### Gerenciamento

#### `GET /jobs`
Lista jobs recentes de transcriÃ§Ã£o.

#### `DELETE /jobs/{job_id}`
Remove job e arquivos associados.

### AdministraÃ§Ã£o  

#### `GET /admin/stats`
EstatÃ­sticas do serviÃ§o.

**Response:**
```json
{
  "jobs": {
    "total": 85,
    "completed": 80,
    "failed": 3,
    "processing": 2
  },
  "transcription": {
    "total_hours_processed": 45.8,
    "avg_processing_time": 215.5,
    "avg_confidence": 0.89,
    "languages_detected": {
      "pt": 35,
      "en": 30,
      "es": 15,
      "fr": 5
    }
  },
  "models": {
    "current_model": "base",
    "model_performance": {
      "tiny": { "speed": "5x", "accuracy": "80%" },
      "base": { "speed": "3x", "accuracy": "85%" },
      "small": { "speed": "2x", "accuracy": "90%" }
    }
  },
  "disk_usage": {
    "temp_dir_mb": 250.5,
    "transcriptions_dir_mb": 45.2,
    "models_dir_gb": 2.8
  }
}
```

#### `POST /admin/cleanup`
Limpeza de arquivos temporÃ¡rios.

### Health Check

#### `GET /health`
Verifica saÃºde do serviÃ§o.

**Response:**
```json
{
  "status": "healthy",
  "service": "audio-transcriber-service",
  "version": "2.0.0",
  "dependencies": {
    "whisper": "âœ… Modelo 'base' carregado",
    "torch": "âœ… CUDA disponÃ­vel",
    "redis": "âœ… Conectado",
    "disk_space": "âœ… 12.5GB livres"
  },
  "performance": {
    "model_loaded": "base",
    "gpu_available": true,
    "avg_processing_speed": "2.1x realtime",
    "concurrent_jobs": 1,
    "max_concurrent": 2
  }
}
```

## ğŸ”„ Estados de Job

1. **queued** - Job criado, aguardando processamento
2. **loading_model** - Carregando modelo Whisper
3. **transcribing** - TranscriÃ§Ã£o em andamento
4. **translating** - TraduÃ§Ã£o em andamento (se aplicÃ¡vel)
5. **completed** - Processamento concluÃ­do
6. **failed** - Falha no processamento

## ğŸ—£ï¸ Modelos Whisper

### Modelos DisponÃ­veis

| Modelo | Tamanho | Velocidade | PrecisÃ£o | Uso Recomendado |
|--------|---------|------------|----------|-----------------|
| `tiny` | 39 MB | ~5x realtime | ~80% | Desenvolvimento/testes |
| `base` | 74 MB | ~3x realtime | ~85% | **PadrÃ£o recomendado** |
| `small` | 244 MB | ~2x realtime | ~90% | Alta qualidade |
| `medium` | 769 MB | ~1.5x realtime | ~93% | ProduÃ§Ã£o crÃ­tica |
| `large` | 1550 MB | ~1x realtime | ~95% | MÃ¡xima precisÃ£o |

### ConfiguraÃ§Ã£o de Modelo
```python
# MudanÃ§a de modelo (requer reinicializaÃ§Ã£o)
WHISPER_MODEL=small

# ParÃ¢metros de processamento
WHISPER_TEMPERATURE=0.0        # DeterminÃ­stico
WHISPER_BEST_OF=5             # MÃºltiplas tentativas
WHISPER_BEAM_SIZE=5           # Beam search
```

## ğŸŒ Suporte a Idiomas

### DetecÃ§Ã£o AutomÃ¡tica
- **99 idiomas** suportados pelo Whisper
- **DetecÃ§Ã£o automÃ¡tica** com confianÃ§a > 90%
- **Fallback**: InglÃªs se detecÃ§Ã£o falhar

### Idiomas Principais
- **PortuguÃªs** (pt) - Excelente
- **InglÃªs** (en) - Excelente  
- **Espanhol** (es) - Excelente
- **FrancÃªs** (fr) - Muito bom
- **AlemÃ£o** (de) - Muito bom
- **Italiano** (it) - Bom
- **JaponÃªs** (ja) - Bom
- **ChinÃªs** (zh) - Bom
- **Russo** (ru) - Bom
- **Ãrabe** (ar) - Regular

### TraduÃ§Ã£o
- **Destino**: Sempre inglÃªs (limitaÃ§Ã£o Whisper)
- **Qualidade**: Varia por idioma origem
- **Uso**: Especificar `language_out: "en"`

## ğŸ“„ Formatos de SaÃ­da

### SRT (SubRip)
```srt
1
00:00:00,000 --> 00:00:03,200
Hello, welcome to my channel.

2
00:00:03,500 --> 00:00:08,100
Today we're going to talk about artificial intelligence.
```

### VTT (WebVTT)
```vtt
WEBVTT

00:00:00.000 --> 00:00:03.200
Hello, welcome to my channel.

00:00:03.500 --> 00:00:08.100
Today we're going to talk about artificial intelligence.
```

### JSON (Completo)
```json
{
  "segments": [
    {
      "start": 0.0,
      "end": 3.2,
      "text": "Hello, welcome to my channel.",
      "confidence": 0.94
    }
  ]
}
```

## ğŸ¯ Qualidade e PrecisÃ£o

### MÃ©tricas de ConfianÃ§a
- **Por palavra**: 0.0 - 1.0
- **Por segmento**: MÃ©dia das palavras
- **Geral**: MÃ©dia ponderada por duraÃ§Ã£o

### Fatores que Afetam Qualidade
- **Qualidade do Ã¡udio**: RuÃ­do, distorÃ§Ã£o
- **Velocidade da fala**: Muito rÃ¡pido/lento
- **Sotaque/dialeto**: VariaÃ§Ãµes regionais
- **MÃºltiplos falantes**: SobreposiÃ§Ã£o
- **MÃºsica de fundo**: Interfere na transcriÃ§Ã£o

### OtimizaÃ§Ãµes
- **NormalizaÃ§Ã£o prÃ©via**: Audio Normalization service
- **Sample rate**: 16kHz otimizado
- **Formato**: WAV PCM preferido
- **DuraÃ§Ã£o**: Segmentos 5-30 minutos ideais

## ğŸš¨ Troubleshooting

### Job Stuck em "loading_model"
**Causa**: Modelo Whisper nÃ£o encontrado
**SoluÃ§Ã£o**: `python -c "import whisper; whisper.load_model('base')"`

### Baixa PrecisÃ£o na TranscriÃ§Ã£o
**Causa**: Ãudio de baixa qualidade ou idioma nÃ£o suportado
**SoluÃ§Ã£o**: Melhorar normalizaÃ§Ã£o ou verificar idioma

### "CUDA Out of Memory"
**Causa**: Modelo muito grande para GPU disponÃ­vel
**SoluÃ§Ã£o**: Usar modelo menor ou CPU

### Timeout no Processamento
**Causa**: Arquivo muito longo ou modelo lento
**SoluÃ§Ã£o**: Aumentar timeout ou usar modelo mais rÃ¡pido

### TraduÃ§Ã£o de Baixa Qualidade  
**Causa**: LimitaÃ§Ãµes do modelo para o par de idiomas
**SoluÃ§Ã£o**: Usar serviÃ§o de traduÃ§Ã£o especializado

## âš¡ Performance

### OtimizaÃ§Ãµes GPU
```python
# CUDA settings
TORCH_DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
WHISPER_DEVICE = "cuda"
WHISPER_FP16 = True  # Half precision para economia de VRAM
```

### OtimizaÃ§Ãµes CPU
```python
# Threading
TORCH_THREADS = 4
OMP_NUM_THREADS = 4

# Memory management
WHISPER_CHUNK_LENGTH = 30  # Processar em chunks de 30s
```

## ğŸ“Š Monitoramento

### Logs Estruturados
```
INFO - Job trans_xyz789 iniciado: pt -> en (180.5s audio)
INFO - Modelo 'base' carregado (GPU: Tesla T4)
INFO - DetecÃ§Ã£o de idioma: pt (confianÃ§a: 0.98)
INFO - TranscriÃ§Ã£o completada: 425 palavras, confianÃ§a mÃ©dia: 0.92
INFO - TraduÃ§Ã£o completada: pt -> en
INFO - Job trans_xyz789 finalizado em 330.2s
```

### MÃ©tricas Importantes
- Tempo de processamento vs duraÃ§Ã£o do Ã¡udio
- ConfianÃ§a mÃ©dia por job
- DistribuiÃ§Ã£o de idiomas detectados
- Taxa de uso GPU vs CPU
- Cache hit rate

## ğŸ“ Estrutura de Arquivos

```
services/audio-transcriber/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py           # API endpoints
â”‚   â”œâ”€â”€ processor.py      # LÃ³gica de transcriÃ§Ã£o
â”‚   â”œâ”€â”€ models.py         # Modelos de dados  
â”‚   â”œâ”€â”€ whisper_client.py # Interface Whisper
â”‚   â”œâ”€â”€ redis_store.py    # Interface Redis
â”‚   â””â”€â”€ config.py         # ConfiguraÃ§Ãµes
â”œâ”€â”€ temp/                 # Arquivos temporÃ¡rios
â”œâ”€â”€ transcriptions/       # TranscriÃ§Ãµes geradas
â”œâ”€â”€ models/               # Modelos Whisper baixados
â”œâ”€â”€ logs/                 # Logs do serviÃ§o
â””â”€â”€ requirements.txt      # DependÃªncias
```

---

**Porta**: 8002 | **VersÃ£o**: 2.0.0 | **Tech**: FastAPI + Whisper + PyTorch