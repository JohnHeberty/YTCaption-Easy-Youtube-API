# üîß Guia de Integra√ß√£o das Otimiza√ß√µes

Este guia mostra como integrar todas as otimiza√ß√µes implementadas aos endpoints existentes da API.

---

## üìã Passo a Passo de Integra√ß√£o

### 1. Atualizar Depend√™ncias (main.py)

**Arquivo**: `src/presentation/api/main.py`

Adicionar imports das novas funcionalidades:

```python
# Importar novos m√≥dulos
from src.infrastructure.whisper.model_cache import get_model_cache
from src.infrastructure.storage.file_cleanup_manager import FileCleanupManager
from src.infrastructure.cache import get_transcription_cache
from src.infrastructure.validators import AudioValidator
from src.infrastructure.utils import get_ffmpeg_optimizer

# Vari√°veis globais
model_cache = None
file_cleanup_manager = None
transcription_cache = None
audio_validator = None
ffmpeg_optimizer = None
```

### 2. Inicializar Servi√ßos no Startup

Adicionar no `lifespan` do `main.py`:

```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gerencia o ciclo de vida da aplica√ß√£o."""
    global model_cache, file_cleanup_manager, transcription_cache, audio_validator, ffmpeg_optimizer
    
    # Startup
    logger.info("=" * 60)
    logger.info(f"Starting {settings.app_name} v{settings.app_version} (OPTIMIZED)")
    
    # 1. Inicializar cache de modelos Whisper
    logger.info("Initializing Whisper model cache...")
    model_cache = get_model_cache()
    model_cache.set_unload_timeout(settings.model_cache_timeout_minutes)
    
    # 2. Inicializar cache de transcri√ß√µes
    if settings.enable_transcription_cache:
        logger.info("Initializing transcription cache...")
        transcription_cache = get_transcription_cache(
            max_size=settings.cache_max_size,
            ttl_hours=settings.cache_ttl_hours
        )
    
    # 3. Inicializar gerenciador de cleanup
    logger.info("Initializing file cleanup manager...")
    file_cleanup_manager = FileCleanupManager(
        base_temp_dir=Path(settings.temp_dir),
        default_ttl_hours=settings.max_temp_age_hours,
        cleanup_interval_minutes=settings.cleanup_interval_minutes
    )
    
    # Iniciar limpeza peri√≥dica
    if settings.enable_periodic_cleanup:
        file_cleanup_manager.start_periodic_cleanup()
    
    # 4. Inicializar validador de √°udio
    logger.info("Initializing audio validator...")
    audio_validator = AudioValidator()
    
    # 5. Inicializar otimizador FFmpeg
    logger.info("Initializing FFmpeg optimizer...")
    ffmpeg_optimizer = get_ffmpeg_optimizer()
    capabilities = ffmpeg_optimizer.get_capabilities()
    logger.info(f"FFmpeg capabilities: hw_accel={capabilities.has_hw_acceleration}")
    
    # [Resto do startup existente...]
    
    logger.info("=" * 60)
    logger.info("üöÄ Application startup complete (OPTIMIZED)!")
    logger.info("=" * 60)
    
    yield
    
    # Shutdown
    logger.info("=" * 60)
    logger.info("Shutting down application...")
    
    # 1. Parar cleanup peri√≥dico
    if file_cleanup_manager:
        await file_cleanup_manager.stop_periodic_cleanup()
        logger.info("File cleanup manager stopped")
    
    # 2. Limpar cache de modelos
    if model_cache:
        model_cache.clear_all()
        logger.info("Model cache cleared")
    
    # 3. Limpar cache de transcri√ß√µes
    if transcription_cache:
        stats = transcription_cache.get_stats()
        logger.info(f"Transcription cache stats: {stats}")
        transcription_cache.clear()
    
    # [Resto do shutdown existente...]
    
    logger.info("=" * 60)
```

---

### 3. Adicionar Fun√ß√µes de Depend√™ncia

**Arquivo**: `src/presentation/api/dependencies.py`

```python
def get_audio_validator() -> AudioValidator:
    """Retorna validador de √°udio."""
    from src.presentation.api.main import audio_validator
    if audio_validator is None:
        raise RuntimeError("Audio validator not initialized")
    return audio_validator


def get_transcription_cache_service():
    """Retorna cache de transcri√ß√µes."""
    from src.presentation.api.main import transcription_cache
    if settings.enable_transcription_cache and transcription_cache:
        return transcription_cache
    return None


def get_file_cleanup_manager_service():
    """Retorna gerenciador de cleanup."""
    from src.presentation.api.main import file_cleanup_manager
    return file_cleanup_manager
```

---

### 4. Atualizar Endpoint de Transcri√ß√£o

**Arquivo**: `src/presentation/api/routes/transcription.py`

#### 4.1 - Adicionar Valida√ß√£o Antecipada

```python
from src.presentation.api.dependencies import get_audio_validator

@router.post("/transcribe")
async def transcribe_video(
    # ... par√¢metros existentes ...
    validator: AudioValidator = Depends(get_audio_validator)
):
    """Transcreve v√≠deo com valida√ß√£o antecipada."""
    
    try:
        # 1. VALIDAR ARQUIVO ANTES DE PROCESSAR
        logger.info("Validating audio file...")
        metadata = validator.validate_file(video_file.file_path, strict=True)
        
        if not metadata.is_valid:
            logger.warning(f"Audio validation failed: {metadata.validation_errors}")
            raise HTTPException(
                status_code=400,
                detail={
                    "error": "InvalidAudioFile",
                    "message": "Audio file validation failed",
                    "validation_errors": metadata.validation_errors,
                    "file_info": {
                        "duration": metadata.duration_formatted,
                        "format": metadata.format_name,
                        "codec": metadata.codec_name,
                        "size_mb": metadata.file_size_mb
                    }
                }
            )
        
        logger.info(
            f"Audio validation passed: {metadata.duration_formatted}, "
            f"{metadata.file_size_mb:.2f}MB, {metadata.codec_name}"
        )
        
        # 2. ESTIMAR TEMPO DE PROCESSAMENTO
        min_time, max_time = validator.estimate_processing_time(
            metadata,
            model_name=model or settings.whisper_model,
            device=settings.whisper_device
        )
        
        logger.info(f"Estimated processing time: {min_time:.1f}s - {max_time:.1f}s")
        
        # 3. VERIFICAR CACHE DE TRANSCRI√á√ÉO
        cache = get_transcription_cache_service()
        
        if cache:
            file_hash = cache.compute_file_hash(video_file.file_path)
            cached_result = cache.get(
                file_hash,
                model or settings.whisper_model,
                language or "auto"
            )
            
            if cached_result:
                logger.info(f"üéØ Cache HIT! Returning cached transcription")
                return {
                    "cached": True,
                    "transcription": cached_result,
                    "processing_time": 0.0
                }
        
        # 4. PROCESSAR TRANSCRI√á√ÉO (c√≥digo existente)
        start_time = time.time()
        
        # [C√≥digo de transcri√ß√£o existente...]
        
        processing_time = time.time() - start_time
        
        # 5. CACHEAR RESULTADO
        if cache:
            cache.put(
                file_hash,
                transcription_data,
                model or settings.whisper_model,
                language or "auto",
                metadata.file_size_bytes
            )
            logger.info("Transcription cached for future requests")
        
        return {
            "cached": False,
            "transcription": transcription_data,
            "processing_time": processing_time,
            "estimated_time": {"min": min_time, "max": max_time}
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Transcription failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

---

### 5. Adicionar Endpoint de M√©tricas

**Arquivo**: `src/presentation/api/routes/system.py`

```python
@router.get("/metrics")
async def get_metrics():
    """
    Retorna m√©tricas do sistema.
    
    **Informa√ß√µes retornadas**:
    - Cache de modelos Whisper
    - Cache de transcri√ß√µes
    - Gerenciador de cleanup
    - FFmpeg capabilities
    """
    from src.presentation.api.main import (
        model_cache,
        transcription_cache,
        file_cleanup_manager,
        ffmpeg_optimizer
    )
    
    metrics = {
        "timestamp": datetime.now().isoformat(),
        "model_cache": None,
        "transcription_cache": None,
        "file_cleanup": None,
        "ffmpeg": None
    }
    
    # Cache de modelos
    if model_cache:
        metrics["model_cache"] = model_cache.get_cache_stats()
    
    # Cache de transcri√ß√µes
    if transcription_cache:
        metrics["transcription_cache"] = transcription_cache.get_stats()
    
    # Cleanup manager
    if file_cleanup_manager:
        metrics["file_cleanup"] = file_cleanup_manager.get_stats()
    
    # FFmpeg
    if ffmpeg_optimizer:
        capabilities = ffmpeg_optimizer.get_capabilities()
        metrics["ffmpeg"] = {
            "version": capabilities.version,
            "has_hw_acceleration": capabilities.has_hw_acceleration,
            "has_cuda": capabilities.has_cuda,
            "has_nvenc": capabilities.has_nvenc,
            "has_vaapi": capabilities.has_vaapi
        }
    
    return metrics


@router.post("/cache/clear")
async def clear_caches():
    """Limpa todos os caches."""
    from src.presentation.api.main import model_cache, transcription_cache
    
    results = {}
    
    # Limpar cache de modelos
    if model_cache:
        model_cache.clear_all()
        results["model_cache"] = "cleared"
    
    # Limpar cache de transcri√ß√µes
    if transcription_cache:
        transcription_cache.clear()
        results["transcription_cache"] = "cleared"
    
    logger.info("All caches cleared")
    return {"message": "Caches cleared", "results": results}


@router.post("/cleanup/run")
async def run_cleanup():
    """Executa limpeza manual de arquivos antigos."""
    from src.presentation.api.main import file_cleanup_manager
    
    if not file_cleanup_manager:
        raise HTTPException(status_code=503, detail="Cleanup manager not initialized")
    
    logger.info("Running manual cleanup...")
    stats = await file_cleanup_manager.cleanup_old_files()
    
    return {
        "message": "Cleanup completed",
        "stats": stats
    }
```

---

### 6. Atualizar Servi√ßo de Transcri√ß√£o

**Arquivo**: `src/infrastructure/whisper/transcription_service.py`

O arquivo j√° foi atualizado para usar o cache global de modelos. N√£o precisa de mais altera√ß√µes!

---

### 7. Vari√°veis de Ambiente

**Arquivo**: `.env`

Adicionar as novas configura√ß√µes:

```env
# ============================================
# OTIMIZA√á√ïES v2.0
# ============================================

# Cache de Transcri√ß√µes
ENABLE_TRANSCRIPTION_CACHE=true
CACHE_MAX_SIZE=100              # M√°ximo de transcri√ß√µes em cache
CACHE_TTL_HOURS=24              # Tempo de vida do cache em horas

# Cache de Modelos Whisper
MODEL_CACHE_TIMEOUT_MINUTES=30  # Descarregar modelos n√£o usados ap√≥s 30min

# Otimiza√ß√£o FFmpeg
ENABLE_FFMPEG_HW_ACCEL=true     # Usar acelera√ß√£o por hardware (CUDA/NVENC)

# Limpeza Autom√°tica de Arquivos
ENABLE_PERIODIC_CLEANUP=true    # Ativar limpeza peri√≥dica
CLEANUP_INTERVAL_MINUTES=30     # Intervalo de limpeza
```

---

## üß™ Testes

### Teste 1: Cache de Modelos

```bash
# Primeira requisi√ß√£o (carrega modelo)
curl -X POST http://localhost:8000/transcribe \
  -F "youtube_url=https://www.youtube.com/watch?v=VIDEO_ID" \
  -F "model=base"
# Resposta: ~10s

# Segunda requisi√ß√£o (usa cache)
curl -X POST http://localhost:8000/transcribe \
  -F "youtube_url=https://www.youtube.com/watch?v=OUTRO_VIDEO" \
  -F "model=base"
# Resposta: ~0.5s (modelo j√° carregado!)
```

### Teste 2: Cache de Transcri√ß√µes

```bash
# Primeira transcri√ß√£o
curl -X POST http://localhost:8000/transcribe \
  -F "youtube_url=https://www.youtube.com/watch?v=VIDEO_ID"
# Resposta: {"cached": false, "processing_time": 15.3}

# Segunda transcri√ß√£o do MESMO v√≠deo
curl -X POST http://localhost:8000/transcribe \
  -F "youtube_url=https://www.youtube.com/watch?v=VIDEO_ID"
# Resposta: {"cached": true, "processing_time": 0.0}
```

### Teste 3: Valida√ß√£o Antecipada

```bash
# Upload de arquivo inv√°lido
curl -X POST http://localhost:8000/transcribe \
  -F "file=@corrupted.mp4"
# Resposta: HTTP 400 {"error": "InvalidAudioFile", "validation_errors": [...]}
```

### Teste 4: M√©tricas

```bash
# Ver m√©tricas do sistema
curl http://localhost:8000/metrics

# Resposta:
{
  "model_cache": {
    "cache_size": 2,
    "total_usage_count": 45,
    "models": {...}
  },
  "transcription_cache": {
    "hit_rate_percent": 68.5,
    "cache_size": 23,
    "total_size_mb": 145.2
  },
  "file_cleanup": {
    "tracked_files": 5,
    "total_size_mb": 23.4
  }
}
```

---

## ‚úÖ Checklist de Integra√ß√£o

- [ ] Atualizar `main.py` com inicializa√ß√£o dos novos servi√ßos
- [ ] Adicionar fun√ß√µes de depend√™ncia em `dependencies.py`
- [ ] Atualizar endpoint `/transcribe` com valida√ß√£o e cache
- [ ] Adicionar endpoint `/metrics` em `system.py`
- [ ] Adicionar endpoint `/cache/clear` em `system.py`
- [ ] Adicionar endpoint `/cleanup/run` em `system.py`
- [ ] Atualizar arquivo `.env` com novas vari√°veis
- [ ] Testar cache de modelos
- [ ] Testar cache de transcri√ß√µes
- [ ] Testar valida√ß√£o antecipada
- [ ] Testar endpoint de m√©tricas
- [ ] Documentar API atualizada

---

## üöÄ Deploy

### Desenvolvimento

```bash
# Instalar depend√™ncias (se houver novas)
pip install -r requirements.txt

# Configurar vari√°veis de ambiente
cp .env.example .env
# Editar .env com configura√ß√µes de otimiza√ß√£o

# Rodar servidor
python -m src.presentation.api.main
```

### Produ√ß√£o (Docker)

```bash
# Build com otimiza√ß√µes
docker-compose build

# Rodar
docker-compose up -d

# Ver logs
docker-compose logs -f

# Ver m√©tricas
curl http://localhost:8000/metrics
```

---

## üìä Monitoramento

### Dashboards Recomendados

1. **Cache Hit Rate**: Monitorar efetividade do cache
2. **Model Load Time**: Tempo de carregamento de modelos
3. **Disk Usage**: Uso de disco por arquivos tempor√°rios
4. **Processing Time**: Tempo m√©dio de processamento

### Alertas Sugeridos

- Cache hit rate < 30% (cache pequeno demais)
- Disk usage > 80% (cleanup n√£o est√° funcionando)
- Model load time > 15s (problema de I/O)
- Processing time > 2x estimado (problema de performance)

---

## üêõ Troubleshooting

### Cache n√£o est√° funcionando

```python
# Verificar se cache est√° habilitado
curl http://localhost:8000/metrics | jq '.transcription_cache'

# Limpar cache manualmente
curl -X POST http://localhost:8000/cache/clear
```

### Arquivos tempor√°rios acumulando

```python
# Executar cleanup manual
curl -X POST http://localhost:8000/cleanup/run

# Verificar status
curl http://localhost:8000/metrics | jq '.file_cleanup'
```

### Modelo n√£o est√° sendo cacheado

```python
# Verificar cache de modelos
curl http://localhost:8000/metrics | jq '.model_cache'

# Reiniciar servidor para resetar cache
docker-compose restart
```

---

## üìö Recursos Adicionais

- [Relat√≥rio de Otimiza√ß√µes](./OPTIMIZATION-REPORT.md)
- [Documenta√ß√£o da API](./04-API-USAGE.md)
- [Guia de Deploy](./07-DEPLOYMENT.md)

---

**√öltima atualiza√ß√£o**: 21/10/2025  
**Vers√£o**: 2.0 (Optimized)
