# Engines de TranscriÃ§Ã£o Whisper

## ğŸ¯ SituaÃ§Ã£o Atual

Atualmente **apenas Faster-Whisper** estÃ¡ implementado e funcionando.

### âœ… Implementado
- **faster-whisper** (padrÃ£o): 4x mais rÃ¡pido que openai-whisper, word timestamps nativos

### âš ï¸ Planejado (nÃ£o implementado)
- **openai-whisper**: Original da OpenAI, mais lento mas compatÃ­vel
- **whisperx**: Word-level timestamps com forced alignment (mais preciso)

## ğŸ“Š ComparaÃ§Ã£o de Engines

| Feature | faster-whisper | openai-whisper | whisperx |
|---------|---------------|----------------|----------|
| **Status** | âœ… Implementado | âš ï¸ Planejado | âš ï¸ Planejado |
| **Velocidade** | 4x mais rÃ¡pido | Baseline (1x) | Similar a faster |
| **Word timestamps** | âœ… Nativos | âŒ Requer patch | âœ… Forced alignment |
| **PrecisÃ£o timestamps** | Boa | N/A | Excelente |
| **VRAM** | Baixo (~500MB) | Alto (~1.5GB) | MÃ©dio (~800MB) |
| **DependÃªncias** | CTranslate2 | PyTorch | PyTorch + Phoneme |

## ğŸš€ Como Usar

### API REST

```bash
# Usando faster-whisper (padrÃ£o)
curl -X POST "http://localhost:8002/jobs" \
  -F "file=@audio.mp3" \
  -F "language_in=auto" \
  -F "engine=faster-whisper"

# Futuro: usando whisperx (quando implementado)
curl -X POST "http://localhost:8002/jobs" \
  -F "file=@audio.mp3" \
  -F "language_in=auto" \
  -F "engine=whisperx"
```

### Swagger UI (http://localhost:8002/docs)

1. Acesse `/docs`
2. VÃ¡ em `POST /jobs`
3. No campo `engine`, selecione:
   - `faster-whisper` (padrÃ£o, recomendado)
   - `openai-whisper` (futuro)
   - `whisperx` (futuro)

## ğŸ“¦ ImplementaÃ§Ã£o Futura

### Para adicionar openai-whisper:

```bash
pip install openai-whisper
```

```python
# app/openai_whisper_manager.py
class OpenAIWhisperManager(IModelManager):
    def __init__(self):
        import whisper
        self.model = whisper.load_model("base")
    
    def transcribe(self, audio_path, language="auto"):
        result = self.model.transcribe(audio_path, language=language)
        return result
```

### Para adicionar whisperx:

```bash
pip install whisperx
```

```python
# app/whisperx_manager.py
class WhisperXManager(IModelManager):
    def __init__(self):
        import whisperx
        self.model = whisperx.load_model("base", device="cpu")
    
    def transcribe(self, audio_path, language="auto"):
        audio = whisperx.load_audio(audio_path)
        result = self.model.transcribe(audio)
        
        # Forced alignment para timestamps precisos
        model_a, metadata = whisperx.load_align_model(
            language_code=result["language"]
        )
        result = whisperx.align(
            result["segments"], 
            model_a, 
            metadata, 
            audio
        )
        return result
```

### Atualizar processor.py:

```python
def _load_model(self, engine: WhisperEngine):
    if engine == WhisperEngine.FASTER_WHISPER:
        self.model_manager = FasterWhisperModelManager()
    elif engine == WhisperEngine.OPENAI_WHISPER:
        self.model_manager = OpenAIWhisperManager()
    elif engine == WhisperEngine.WHISPERX:
        self.model_manager = WhisperXManager()
    
    self.model_manager.load_model()
```

## ğŸ¯ RecomendaÃ§Ãµes

### Use faster-whisper quando:
- âœ… Precisa de velocidade(4x mais rÃ¡pido)
- âœ… Quer economizar VRAM
- âœ… Word timestamps sÃ£o suficientes
- âœ… **ProduÃ§Ã£o padrÃ£o** (Ã© o que temos agora)

### Use whisperx quando (futuro):
- âœ… Precisa de timestamps MUITO precisos
- âœ… FarÃ¡ alinhamento labial (lip-sync)
- âœ… GerarÃ¡ legendas com timing perfeito
- âš ï¸ Pode esperar um pouco mais (~20% mais lento)

### Use openai-whisper quando (futuro):
- âœ… Precisa de compatibilidade mÃ¡xima
- âœ… Tem muito VRAM disponÃ­vel
- âš ï¸ NÃ£o tem pressa (4x mais lento)

## ğŸ“ Status dos Testes

### Faster-Whisper âœ…
- âœ… 6 testes reais passando (sem mocks)
- âœ… TranscriÃ§Ã£o validada com TEST-.ogg
- âœ… Word timestamps funcionando
- âœ… Performance medida: RTF ~1.7x no CPU

### OpenAI-Whisper âš ï¸
- âš ï¸ NÃ£o implementado
- ğŸ“‹ Testes: A fazer

### WhisperX âš ï¸
- âš ï¸ NÃ£o implementado
- ğŸ“‹ Testes: A fazer

## ğŸ”§ ConfiguraÃ§Ã£o

```bash
# .env
WHISPER_ENGINE=faster-whisper  # padrÃ£o
WHISPER_MODEL=small            # tiny, base, small, medium, large
WHISPER_DEVICE=cpu             # cpu, cuda
```

## ğŸ“š ReferÃªncias

- [Faster-Whisper](https://github.com/SYSTRAN/faster-whisper) - CTranslate2-based
- [OpenAI Whisper](https://github.com/openai/whisper) - Original
- [WhisperX](https://github.com/m-bain/whisperX) - Forced alignment
