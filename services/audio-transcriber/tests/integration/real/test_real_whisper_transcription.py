"""
Testes de integra√ß√£o REAIS com Faster-Whisper.

‚ö†Ô∏è  ATEN√á√ÉO: Estes testes N√ÉO usam mocks!
‚úÖ Carregam o modelo Faster-Whisper real
‚úÖ Transcrevem √°udio real (TEST-.ogg)
‚úÖ Validam word timestamps reais
‚úÖ Medem performance real de produ√ß√£o

Execute com: pytest -m real -v --tb=short
"""

import pytest
import time
from pathlib import Path
import sys
import os
import importlib.util
from unittest.mock import MagicMock

# Setup para importar sem Redis
mock_interfaces = MagicMock()
mock_interfaces.IModelManager = type('IModelManager', (), {})
sys.modules['app.interfaces'] = mock_interfaces
sys.modules['app.exceptions'] = MagicMock()
mock_config = MagicMock()
mock_settings = MagicMock()
mock_settings.get = lambda k, d=None: {
    'whisper_download_root': './models',
    'whisper_model': 'small',  # small √© mais r√°pido para testes
    'whisper_device': 'cpu',
    'model_load_retries': 3,
    'model_load_backoff': 2.0
}.get(k, d)
mock_config.get_settings.return_value = mock_settings
sys.modules['app.config'] = mock_config

# Importa FasterWhisperModelManager
module_path = Path(__file__).parent.parent.parent.parent / "app" / "faster_whisper_manager.py"
spec = importlib.util.spec_from_file_location("app.faster_whisper_manager", module_path)
fwm_module = importlib.util.module_from_spec(spec)
sys.modules['app.faster_whisper_manager'] = fwm_module
spec.loader.exec_module(fwm_module)

FasterWhisperModelManager = fwm_module.FasterWhisperModelManager


@pytest.fixture(scope="module")
def test_audio_file():
    """Retorna caminho do arquivo de teste real"""
    audio_path = Path(__file__).parent.parent.parent / "TEST-.ogg"
    assert audio_path.exists(), f"Arquivo de teste n√£o encontrado: {audio_path}"
    return audio_path


@pytest.fixture(scope="module")
def model_manager():
    """
    Cria e retorna FasterWhisperModelManager REAL.
    
    ‚ö†Ô∏è  SEM MOCKS! Carrega modelo real do Hugging Face.
    """
    manager = FasterWhisperModelManager()
    return manager


@pytest.mark.real
@pytest.mark.slow
class TestRealWhisperIntegration:
    """
    Testes de integra√ß√£o REAL com Faster-Whisper.
    
    ‚ö†Ô∏è  Estes testes:
    - Carregam o modelo real (~250MB download na primeira vez)
    - Fazem infer√™ncia real
    - Demoram mais tempo (modelo small ~10-30s no CPU)
    """
    
    def test_model_download_and_load(self, model_manager):
        """
        Teste 1: Carrega modelo Faster-Whisper REAL.
        
        Valida:
        - Download do modelo (se necess√°rio)
        - Carregamento em mem√≥ria
        - Device detection
        - Status after load
        """
        print("\n" + "="*70)
        print("üöÄ TESTE REAL: Carregando modelo Faster-Whisper...")
        print("="*70)
        
        start_time = time.time()
        
        # Carrega modelo REAL (sem mocks!)
        model_manager.load_model()
        
        load_time = time.time() - start_time
        
        # Valida√ß√µes
        assert model_manager.is_loaded is True, "Modelo n√£o foi carregado"
        assert model_manager.model is not None, "Modelo est√° None"
        assert model_manager.device in ["cpu", "cuda"], f"Device inv√°lido: {model_manager.device}"
        
        # Status
        status = model_manager.get_status()
        assert status["loaded"] is True
        assert status["engine"] == "faster-whisper"
        
        print(f"\n‚úÖ Modelo carregado com sucesso!")
        print(f"   - Modelo: {model_manager.model_name}")
        print(f"   - Device: {model_manager.device}")
        print(f"   - Tempo de load: {load_time:.2f}s")
        print(f"   - Engine: {status['engine']}")
        
    def test_real_transcription_with_word_timestamps(self, model_manager, test_audio_file):
        """
        Teste 2: Transcri√ß√£o REAL com word timestamps.
        
        Valida:
        - Transcri√ß√£o do arquivo TEST-.ogg real
        - Word-level timestamps gerados
        - Estrutura do resultado
        - Performance em produ√ß√£o
        """
        print("\n" + "="*70)
        print("üé§ TESTE REAL: Transcrevendo √°udio real (TEST-.ogg)...")
        print("="*70)
        print(f"   Arquivo: {test_audio_file.name} ({test_audio_file.stat().st_size / 1024:.1f} KB)")
        
        start_time = time.time()
        
        # Transcreve REAL (sem mocks!)
        result = model_manager.transcribe(test_audio_file, language="pt")
        
        transcription_time = time.time() - start_time
        
        # Valida√ß√µes b√°sicas
        assert result["success"] is True, "Transcri√ß√£o falhou"
        assert "text" in result, "Resultado n√£o tem 'text'"
        assert "segments" in result, "Resultado n√£o tem 'segments'"
        assert len(result["segments"]) > 0, "Nenhum segment gerado"
        
        # Valida word timestamps
        total_words = 0
        for segment in result["segments"]:
            assert "words" in segment, "Segment n√£o tem 'words'"
            words = segment["words"]
            total_words += len(words)
            
            # Valida cada word
            for word in words:
                assert "word" in word, "Word n√£o tem campo 'word'"
                assert "start" in word, "Word n√£o tem campo 'start'"
                assert "end" in word, "Word n√£o tem campo 'end'"
                assert "probability" in word, "Word n√£o tem campo 'probability'"
                
                # Timestamps s√£o v√°lidos
                assert word["start"] >= 0, f"Start inv√°lido: {word['start']}"
                # Faster-Whisper pode gerar start == end para palavras muito curtas
                assert word["end"] >= word["start"], f"End < start: {word}"
                assert 0 <= word["probability"] <= 1, f"Probability inv√°lida: {word['probability']}"
        
        # M√©tricas
        duration = result.get("duration", 0)
        rtf = transcription_time / duration if duration > 0 else 0  # Real-Time Factor
        
        print(f"\n‚úÖ Transcri√ß√£o conclu√≠da!")
        print(f"\nüìä RESULTADOS:")
        print(f"   - Texto: \"{result['text'][:100]}...\"" if len(result['text']) > 100 else f"   - Texto: \"{result['text']}\"")
        print(f"   - Segments: {len(result['segments'])}")
        print(f"   - Total words: {total_words}")
        print(f"   - Idioma detectado: {result.get('language', 'N/A')}")
        print(f"   - Dura√ß√£o √°udio: {duration:.2f}s")
        print(f"\n‚è±Ô∏è  PERFORMANCE:")
        print(f"   - Tempo transcri√ß√£o: {transcription_time:.2f}s")
        print(f"   - RTF (Real-Time Factor): {rtf:.2f}x")
        print(f"   - Throughput: {total_words/transcription_time:.1f} words/s")
        
        # Valida que encontrou palavras esperadas
        text_lower = result['text'].lower()
        expected_words = ["um", "dois", "tr√™s", "quatro", "1", "2", "3", "4"]
        found_words = [w for w in expected_words if w in text_lower]
        
        print(f"\nüéØ VALIDA√á√ÉO CONTE√öDO:")
        print(f"   - Texto completo: \"{result['text']}\"")
        print(f"   - Palavras esperadas: {expected_words}")
        print(f"   - Palavras encontradas: {found_words}")
        if found_words:
            print(f"   - Taxa acerto: {len(found_words)}/{len(expected_words)} ({len(found_words)*100/len(expected_words):.0f}%)")
        
        # Pelo menos 25% das palavras esperadas devem estar presentes
        assert len(found_words) >= len(expected_words) * 0.25, \
            f"Poucas palavras esperadas encontradas: {found_words}"
    
    def test_word_timestamps_accuracy(self, model_manager, test_audio_file):
        """
        Teste 3: Precis√£o dos word timestamps.
        
        Valida:
        - Timestamps s√£o sequenciais
        - N√£o h√° gaps grandes entre palavras
        - Dura√ß√£o das palavras √© razo√°vel
        """
        print("\n" + "="*70)
        print("‚è±Ô∏è  TESTE REAL: Validando precis√£o dos timestamps...")
        print("="*70)
        
        result = model_manager.transcribe(test_audio_file, language="pt")
        
        all_words = []
        for segment in result["segments"]:
            all_words.extend(segment["words"])
        
        print(f"\nüìä Analisando {len(all_words)} palavras...")
        
        # Valida sequencialidade
        for i in range(len(all_words) - 1):
            current = all_words[i]
            next_word = all_words[i + 1]
            
            # Timestamps s√£o crescentes
            assert current["end"] <= next_word["start"] + 0.5, \
                f"Timestamps n√£o sequenciais: {current} -> {next_word}"
            
            # Gap entre palavras n√£o √© absurdo (< 2s)
            gap = next_word["start"] - current["end"]
            assert gap < 2.0, f"Gap muito grande entre palavras: {gap:.2f}s"
        
        # Valida dura√ß√£o das palavras
        durations = [w["end"] - w["start"] for w in all_words]
        avg_duration = sum(durations) / len(durations)
        max_duration = max(durations)
        min_duration = min(durations)
        
        print(f"\nüìà ESTAT√çSTICAS DOS TIMESTAMPS:")
        print(f"   - Dura√ß√£o m√©dia: {avg_duration:.3f}s")
        print(f"   - Dura√ß√£o m√≠nima: {min_duration:.3f}s")
        print(f"   - Dura√ß√£o m√°xima: {max_duration:.3f}s")
        
        # Valida que dura√ß√µes s√£o razo√°veis
        assert avg_duration > 0, "Dura√ß√£o m√©dia deve ser > 0"
        assert avg_duration < 2.0, f"Dura√ß√£o m√©dia muito alta: {avg_duration}"
        assert max_duration < 5.0, f"Palavra com dura√ß√£o absurda: {max_duration}s"
        
        # Mostra algumas palavras com timestamps
        print(f"\nüîç AMOSTRA DE PALAVRAS COM TIMESTAMPS:")
        for i, word in enumerate(all_words[:5]):  # Primeiras 5 palavras
            print(f"   {i+1}. \"{word['word']}\" [{word['start']:.2f}s - {word['end']:.2f}s] (conf: {word['probability']:.2%})")
        
        print(f"\n‚úÖ Timestamps validados com sucesso!")
    
    @pytest.mark.skip(reason="Teste longo (>5min) com arquivo de 33s - execute manualmente se necess√°rio")
    def test_multiple_transcriptions_performance(self, model_manager, test_audio_file):
        """
        Teste 4: Performance de m√∫ltiplas transcri√ß√µes.
        
        ‚ö†Ô∏è  ATEN√á√ÉO: Teste MUITO LENTO (>5 min) devido ao arquivo de 33s.
        Execute manualmente: pytest -m real -k "performance" --timeout=600
        
        Valida:
        - Modelo √© reutilizado (n√£o recarrega)
        - Performance se mant√©m est√°vel
        - N√£o h√° memory leaks
        """
        print("\n" + "="*70)
        print("üîÑ TESTE REAL: Performance de m√∫ltiplas transcri√ß√µes...")
        print("="*70)
        
        num_runs = 3
        times = []
        word_counts = []
        
        for i in range(num_runs):
            print(f"\n   Run {i+1}/{num_runs}...")
            
            start = time.time()
            result = model_manager.transcribe(test_audio_file, language="pt")
            elapsed = time.time() - start
            
            times.append(elapsed)
            word_count = sum(len(seg["words"]) for seg in result["segments"])
            word_counts.append(word_count)
            
            print(f"      ‚úì {elapsed:.2f}s ({word_count} words)")
        
        avg_time = sum(times) / len(times)
        std_dev = (sum((t - avg_time)**2 for t in times) / len(times)) ** 0.5
        
        print(f"\nüìä RESULTADOS DE PERFORMANCE:")
        print(f"   - Runs: {num_runs}")
        print(f"   - Tempo m√©dio: {avg_time:.2f}s")
        print(f"   - Desvio padr√£o: {std_dev:.2f}s")
        print(f"   - Varia√ß√£o: {std_dev/avg_time*100:.1f}%")
        print(f"   - Mais r√°pido: {min(times):.2f}s")
        print(f"   - Mais lento: {max(times):.2f}s")
        print(f"   - Word count consistente: {len(set(word_counts)) == 1}")
        
        # Valida consist√™ncia
        assert len(set(word_counts)) == 1, \
            f"Word counts inconsistentes: {word_counts}"
        
        # Performance n√£o degrada muito
        assert max(times) < min(times) * 2, \
            "Performance degrada muito entre runs"
        
        print(f"\n‚úÖ Performance est√°vel confirmada!")
    
    def test_model_unload(self, model_manager):
        """
        Teste 5: Descarregamento do modelo.
        
        Valida:
        - Modelo √© descarregado corretamente
        - Mem√≥ria √© liberada
        - Status ap√≥s unload
        """
        print("\n" + "="*70)
        print("üî• TESTE REAL: Descarregando modelo...")
        print("="*70)
        
        # Status antes
        status_before = model_manager.get_status()
        assert status_before["loaded"] is True
        
        # Unload
        result = model_manager.unload_model()
        
        # Valida√ß√µes
        assert result["success"] is True, "Unload falhou"
        assert model_manager.model is None, "Modelo ainda est√° na mem√≥ria"
        assert model_manager.is_loaded is False, "Flag is_loaded ainda True"
        
        # Status depois
        status_after = model_manager.get_status()
        assert status_after["loaded"] is False
        
        print(f"\n‚úÖ Modelo descarregado!")
        print(f"   - Mem√≥ria RAM liberada: ~{result['memory_freed']['ram_mb']}MB")
        print(f"   - Status: {status_after}")


@pytest.mark.real
@pytest.mark.slow
class TestRealProductionScenario:
    """
    Testes simulando cen√°rio real de produ√ß√£o.
    """
    
    def test_cold_start_to_transcription(self, test_audio_file):
        """
        Teste 6: Cold start completo (como em produ√ß√£o).
        
        Simula:
        - Aplica√ß√£o inicia
        - Modelo n√£o est√° em cache
        - Primeira transcri√ß√£o
        """
        print("\n" + "="*70)
        print("üÜï TESTE REAL: Cen√°rio de cold start (produ√ß√£o)...")
        print("="*70)
        
        # Cria manager novo (simula cold start)
        manager = FasterWhisperModelManager()
        
        print("\n1Ô∏è‚É£  Aplica√ß√£o iniciando (modelo n√£o carregado)...")
        status = manager.get_status()
        assert status["loaded"] is False
        print(f"   ‚úì Status inicial: {status}")
        
        print("\n2Ô∏è‚É£  Primeira requisi√ß√£o de transcri√ß√£o...")
        start = time.time()
        
        # Transcreve (deve carregar modelo automaticamente)
        result = manager.transcribe(test_audio_file, language="pt")
        
        total_time = time.time() - start
        
        print(f"   ‚úì Transcri√ß√£o conclu√≠da!")
        print(f"\n‚è±Ô∏è  TEMPO TOTAL (COLD START + TRANSCRI√á√ÉO): {total_time:.2f}s")
        
        # Valida resultado
        assert result["success"] is True
        assert len(result["segments"]) > 0
        
        # Segunda transcri√ß√£o (modelo j√° carregado)
        print("\n3Ô∏è‚É£  Segunda requisi√ß√£o (modelo quente)...")
        start2 = time.time()
        result2 = manager.transcribe(test_audio_file, language="pt")
        warm_time = time.time() - start2
        
        print(f"   ‚úì Transcri√ß√£o conclu√≠da!")
        print(f"\n‚è±Ô∏è  TEMPO (MODELO QUENTE): {warm_time:.2f}s")
        print(f"\nüìä COMPARA√á√ÉO:")
        print(f"   - Cold start: {total_time:.2f}s")
        print(f"   - Warm: {warm_time:.2f}s")
        print(f"   - Speedup: {total_time/warm_time:.1f}x mais r√°pido")
        
        # Cleanup
        manager.unload_model()
        
        print(f"\n‚úÖ Cen√°rio de produ√ß√£o validado!")


# ============================================================================
# Teste de Sanidade R√°pido (para CI/CD)
# ============================================================================

@pytest.mark.real
class TestRealQuickSanity:
    """
    Teste r√°pido de sanidade com modelo real.
    √ötil para CI/CD quando n√£o h√° tempo para testes completos.
    """
    
    def test_quick_sanity_check(self, test_audio_file):
        """
        Teste 7: Sanity check r√°pido com modelo real.
        
        Execu√ß√£o: ~10-30s
        Valida apenas o essencial.
        """
        print("\n" + "="*70)
        print("‚ö° TESTE REAL R√ÅPIDO: Sanity check...")
        print("="*70)
        
        manager = FasterWhisperModelManager()
        
        # Load + Transcribe
        result = manager.transcribe(test_audio_file, language="pt")
        
        # Valida√ß√µes m√≠nimas
        assert result["success"] is True
        assert len(result["text"]) > 0
        assert len(result["segments"]) > 0
        
        total_words = sum(len(seg["words"]) for seg in result["segments"])
        assert total_words > 0
        
        # Cleanup
        manager.unload_model()
        
        print(f"\n‚úÖ Sanity check OK!")
        print(f"   - Texto: \"{result['text'][:50]}...\"")
        print(f"   - Words: {total_words}")
