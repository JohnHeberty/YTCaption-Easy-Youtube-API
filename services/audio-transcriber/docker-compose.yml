services:

  audio-transcriber-service:
    build: .
    container_name: audio-transcriber-api
    runtime: nvidia
    ports:
      - "${PORT:-8002}:8002"
    volumes:
      - ./app:/app/app
      - ./uploads:/app/uploads
      - ./transcriptions:/app/transcriptions
      - ./models:/app/models
      - ./temp:/app/temp
      - ./logs:/app/logs
      - /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1:/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1:ro
      - /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/lib/x86_64-linux-gnu/libcuda.so.1:ro
    env_file:
      - .env
    environment:
      - PYTHONPATH=/app
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - WHISPER_DEVICE=cuda
      - WHISPER_FALLBACK_CPU=true
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    labels:
      - "com.example.service=audio-transcriber"
      - "com.example.version=2.0.0"

  celery-worker:
    build: .
    container_name: audio-transcriber-celery
    runtime: nvidia
    command: python -m celery -A app.celery_config worker --loglevel=info --concurrency=1 --pool=solo --queues=audio_transcriber_queue
    volumes:
      - ./app:/app/app
      - ./uploads:/app/uploads
      - ./transcriptions:/app/transcriptions
      - ./models:/app/models
      - ./temp:/app/temp
      - ./logs:/app/logs
      - /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1:/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1:ro
      - /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/lib/x86_64-linux-gnu/libcuda.so.1:ro
    env_file:
      - .env
    environment:
      - PYTHONPATH=/app
      - C_FORCE_ROOT=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - WHISPER_DEVICE=cuda
      - WHISPER_FALLBACK_CPU=true
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    depends_on:
      audio-transcriber-service:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "python -m celery -A app.celery_config inspect ping || exit 1"]
      interval: 30s
      timeout: 30s
      retries: 5
      start_period: 60s
    labels:
      - "com.example.service=audio-transcriber-worker"
      - "com.example.version=2.0.0"
