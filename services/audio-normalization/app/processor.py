import os
import asyncio
import tempfile
import numpy as np
import logging
from datetime import datetime
from pathlib import Path
from pydub import AudioSegment
from pydub.effects import normalize, high_pass_filter
import noisereduce as nr
import soundfile as sf
import librosa
from .models import Job, JobStatus
from .exceptions import AudioNormalizationException

logger = logging.getLogger(__name__)

# Para isolamento vocal com openunmix
try:
    import torch
    import openunmix
    OPENUNMIX_AVAILABLE = True
    logger.info("OpenUnmix dispon√≠vel para isolamento vocal")
except ImportError:
    OPENUNMIX_AVAILABLE = False
    logger.warning("OpenUnmix n√£o dispon√≠vel. Isolamento vocal ser√° desabilitado")


class AudioProcessor:
    def __init__(self):
        self.job_store = None  # Will be injected
        self._openunmix_model = None
    
    def _load_openunmix_model(self):
        """Carrega modelo openunmix para isolamento vocal - API CORRIGIDA e ROBUSTA"""
        if not OPENUNMIX_AVAILABLE:
            raise AudioNormalizationException("OpenUnmix n√£o est√° dispon√≠vel - instale com: pip install openunmix-pytorch")
            
        if self._openunmix_model is None:
            try:
                logger.info("üéµ Carregando modelo OpenUnmix...")
                
                # ESTRAT√âGIA 1: API oficial do OpenUnmix (openunmix-pytorch)
                try:
                    import openunmix
                    
                    # Modelo UMX (Universal Music eXtractor)
                    # Carrega modelo pr√©-treinado em CPU para evitar OOM
                    self._openunmix_model = openunmix.umx.load_pretrained(
                        target='vocals',  # Apenas vocais
                        device='cpu',  # For√ßa CPU para controle de mem√≥ria
                        pretrained=True
                    )
                    
                    self._openunmix_model.eval()  # Modo de infer√™ncia
                    logger.info("‚úÖ Modelo OpenUnmix carregado com sucesso (API oficial)")
                    
                except AttributeError:
                    # API alternativa para vers√µes antigas
                    logger.info("‚ö†Ô∏è API oficial n√£o dispon√≠vel, tentando API alternativa...")
                    
                    from openunmix import predict
                    # Usa fun√ß√£o de predi√ß√£o diretamente
                    self._openunmix_model = predict
                    logger.info("‚úÖ OpenUnmix carregado via API de predi√ß√£o")
                    
            except Exception as e:
                logger.error(f"‚ùå Erro ao carregar modelo OpenUnmix: {e}")
                raise AudioNormalizationException(
                    f"Falha ao carregar OpenUnmix. Erro: {str(e)}. "
                    f"Certifique-se de que 'openunmix-pytorch' est√° instalado."
                )
                    
        return self._openunmix_model
    
    async def process_audio_job(self, job: Job):
        """
        Processa um job de √°udio com opera√ß√µes condicionais.
        IMPORTANTE: Aceita QUALQUER formato de entrada e SEMPRE salva como .webm
        """
        try:
            logger.info(f"Iniciando processamento do job: {job.id}")
            
            # Atualiza status para processando
            job.status = JobStatus.PROCESSING
            job.progress = 2.0
            if self.job_store:
                self.job_store.update_job(job)
            
            # VALIDA√á√ÉO COM FFPROBE (a verdadeira valida√ß√£o)
            try:
                from .security import validate_audio_content_with_ffprobe
                logger.info(f"Validando arquivo com ffprobe: {job.input_file}")
                file_info = validate_audio_content_with_ffprobe(job.input_file)
                logger.info(f"Arquivo v√°lido - √Åudio: {file_info['has_audio']}, V√≠deo: {file_info['has_video']}")
            except Exception as e:
                logger.error(f"Valida√ß√£o ffprobe falhou: {e}")
                raise AudioNormalizationException(str(e))
            
            job.progress = 5.0
            if self.job_store:
                self.job_store.update_job(job)
            
            # Carrega arquivo - com extra√ß√£o autom√°tica de √°udio se for v√≠deo
            try:
                logger.info(f"Carregando arquivo: {job.input_file}")
                
                # Se cont√©m v√≠deo, extrai apenas o √°udio automaticamente
                if file_info['has_video']:
                    logger.info("Arquivo cont√©m v√≠deo - extraindo stream de √°udio automaticamente")
                    # pydub automaticamente extrai √°udio usando ffmpeg
                    audio = AudioSegment.from_file(job.input_file, parameters=["-vn"])
                else:
                    # Arquivo s√≥ de √°udio
                    audio = AudioSegment.from_file(job.input_file)
                
                logger.info(f"√Åudio carregado com sucesso. Formato: {Path(job.input_file).suffix}")
                
            except Exception as e:
                logger.error(f"Erro ao carregar arquivo: {e}")
                raise AudioNormalizationException(f"N√£o foi poss√≠vel carregar o arquivo: {str(e)}")
            
            job.progress = 10.0
            if self.job_store:
                self.job_store.update_job(job)
            
            # Verifica se alguma opera√ß√£o foi solicitada
            any_operation = (job.remove_noise or job.convert_to_mono or 
                           job.apply_highpass_filter or job.set_sample_rate_16k or 
                           job.isolate_vocals)
            
            if not any_operation:
                logger.info("Nenhuma opera√ß√£o solicitada - salvando arquivo sem modifica√ß√µes")
                job.progress = 50.0
                if self.job_store:
                    self.job_store.update_job(job)
            else:
                logger.info(f"Aplicando opera√ß√µes: {job.processing_operations}")
                
                try:
                    # Aplicar opera√ß√µes condicionalmente
                    processed_audio = await self._apply_processing_operations(audio, job)
                    audio = processed_audio
                except Exception as e:
                    logger.error(f"Erro durante processamento de √°udio: {e}")
                    raise AudioNormalizationException(f"Falha no processamento: {str(e)}")
            
            # CR√çTICO: Salva arquivo processado SEMPRE como .webm
            output_dir = Path("./processed")
            try:
                output_dir.mkdir(exist_ok=True, parents=True)
            except Exception as e:
                logger.error(f"Erro ao criar diret√≥rio de sa√≠da: {e}")
                raise AudioNormalizationException(f"N√£o foi poss√≠vel criar diret√≥rio: {str(e)}")
            
            # Nome do arquivo baseado nas opera√ß√µes
            operations_suffix = f"_{job.processing_operations}" if job.processing_operations != "none" else ""
            output_path = output_dir / f"{job.id}{operations_suffix}.webm"
            
            try:
                logger.info(f"Salvando arquivo processado como WebM: {output_path}")
                # SEMPRE exporta como .webm com codec opus
                audio.export(
                    str(output_path), 
                    format="webm",
                    codec="libopus",
                    parameters=["-strict", "-2"]
                )
                logger.info(f"Arquivo WebM salvo com sucesso. Tamanho: {output_path.stat().st_size} bytes")
            except Exception as e:
                logger.error(f"Erro ao salvar arquivo WebM: {e}")
                raise AudioNormalizationException(f"Falha ao salvar arquivo de sa√≠da: {str(e)}")
            
            # Finaliza job
            job.output_file = str(output_path)
            job.status = JobStatus.COMPLETED
            job.progress = 100.0
            job.file_size_output = output_path.stat().st_size
            job.completed_at = datetime.now()
            
            if self.job_store:
                self.job_store.update_job(job)
            
            logger.info(f"Job {job.id} processado com sucesso. Output: {output_path.name}")
            
        except AudioNormalizationException:
            # Re-raise exce√ß√µes espec√≠ficas
            raise
        except Exception as e:
            # Captura qualquer erro inesperado
            error_msg = f"Erro inesperado no processamento: {str(e)}"
            logger.error(f"Job {job.id} falhou: {error_msg}", exc_info=True)
            
            job.status = JobStatus.FAILED
            job.error_message = error_msg
            
            if self.job_store:
                self.job_store.update_job(job)
            
            raise AudioNormalizationException(error_msg)
    
    async def _apply_processing_operations(self, audio: AudioSegment, job: Job) -> AudioSegment:
        """Aplica opera√ß√µes de processamento condicionalmente com tratamento robusto de erros"""
        operations_count = sum([
            job.remove_noise, job.convert_to_mono, job.apply_highpass_filter,
            job.set_sample_rate_16k, job.isolate_vocals
        ])
        
        if operations_count == 0:
            return audio
            
        progress_step = 80.0 / operations_count
        current_progress = 10.0
        
        # 1. Isolamento vocal (primeiro, pois pode afetar outras opera√ß√µes)
        if job.isolate_vocals:
            try:
                logger.info("Aplicando isolamento vocal...")
                audio = await self._isolate_vocals(audio)
                current_progress += progress_step
                job.progress = current_progress
                if self.job_store:
                    self.job_store.update_job(job)
            except Exception as e:
                logger.error(f"Erro no isolamento vocal: {e}")
                raise AudioNormalizationException(f"Falha no isolamento vocal: {str(e)}")
        
        # 2. Remo√ß√£o de ru√≠do
        if job.remove_noise:
            try:
                logger.info("Removendo ru√≠do...")
                audio = await self._remove_noise(audio)
                current_progress += progress_step
                job.progress = current_progress
                if self.job_store:
                    self.job_store.update_job(job)
            except Exception as e:
                logger.error(f"Erro na remo√ß√£o de ru√≠do: {e}")
                raise AudioNormalizationException(f"Falha na remo√ß√£o de ru√≠do: {str(e)}")
        
        # 3. Converter para mono
        if job.convert_to_mono:
            try:
                logger.info("Convertendo para mono...")
                audio = audio.set_channels(1)
                current_progress += progress_step
                job.progress = current_progress
                if self.job_store:
                    self.job_store.update_job(job)
            except Exception as e:
                logger.error(f"Erro ao converter para mono: {e}")
                raise AudioNormalizationException(f"Falha na convers√£o para mono: {str(e)}")
        
        # 4. Aplicar filtro high-pass
        if job.apply_highpass_filter:
            try:
                logger.info("Aplicando filtro high-pass...")
                audio = await self._apply_highpass_filter(audio)
                current_progress += progress_step
                job.progress = current_progress
                if self.job_store:
                    self.job_store.update_job(job)
            except Exception as e:
                logger.error(f"Erro no filtro high-pass: {e}")
                raise AudioNormalizationException(f"Falha no filtro high-pass: {str(e)}")
        
        # 5. Reduzir sample rate para 16kHz
        if job.set_sample_rate_16k:
            try:
                logger.info("Reduzindo sample rate para 16kHz...")
                audio = audio.set_frame_rate(16000)
                current_progress += progress_step
                job.progress = current_progress
                if self.job_store:
                    self.job_store.update_job(job)
            except Exception as e:
                logger.error(f"Erro ao ajustar sample rate: {e}")
                raise AudioNormalizationException(f"Falha ao ajustar sample rate: {str(e)}")
        
        return audio
    
    async def _isolate_vocals(self, audio: AudioSegment) -> AudioSegment:
        """Isola vocais usando OpenUnmix com PROTE√á√ÉO TOTAL contra erros e OOM"""
        if not OPENUNMIX_AVAILABLE:
            logger.error("‚ùå OpenUnmix n√£o dispon√≠vel")
            raise AudioNormalizationException("OpenUnmix n√£o est√° instalado. Use: pip install openunmix-pytorch")
        
        try:
            logger.info(f"üé§ Iniciando isolamento vocal - dura√ß√£o: {len(audio)}ms, canais: {audio.channels}")
            
            # PROTE√á√ÉO 1: Limita dura√ß√£o para evitar OOM (OpenUnmix √© pesado)
            max_duration_ms = 180000  # 3 minutos m√°ximo para vocal isolation
            original_duration = len(audio)
            if original_duration > max_duration_ms:
                logger.warning(f"‚ö†Ô∏è √Åudio muito longo ({original_duration}ms), cortando para {max_duration_ms}ms")
                audio = audio[:max_duration_ms]
            
            # PROTE√á√ÉO 2: Prepara √°udio no formato correto
            original_sample_rate = audio.frame_rate
            target_sample_rate = 44100  # OpenUnmix funciona melhor com 44.1kHz
            
            if audio.frame_rate != target_sample_rate:
                logger.info(f"üîÑ Ajustando sample rate de {audio.frame_rate} para {target_sample_rate}")
                audio = audio.set_frame_rate(target_sample_rate)
            
            # PROTE√á√ÉO 3: Garante que √© est√©reo (OpenUnmix precisa de est√©reo)
            original_channels = audio.channels
            if audio.channels == 1:
                logger.info("üîÑ Convertendo mono para est√©reo (OpenUnmix requer est√©reo)")
                audio = audio.set_channels(2)
            
            # PROTE√á√ÉO 4: Converte para numpy array
            try:
                samples = np.array(audio.get_array_of_samples())
                
                # Reshape para est√©reo (samples x 2)
                if audio.channels == 2:
                    samples = samples.reshape((-1, 2))
                
                # Converte para float32 e normaliza para [-1, 1]
                samples_float = samples.astype(np.float32) / 32768.0
                
                logger.info(f"üìä Array preparado: shape={samples_float.shape}, dtype={samples_float.dtype}")
                
            except Exception as array_err:
                logger.error(f"üí• Erro ao preparar array: {array_err}")
                raise AudioNormalizationException(f"Failed to prepare audio for vocal isolation: {str(array_err)}")
            
            # PROTE√á√ÉO 5: Carrega modelo
            try:
                model = self._load_openunmix_model()
            except Exception as model_err:
                logger.error(f"üí• Erro ao carregar modelo: {model_err}")
                raise AudioNormalizationException(f"Failed to load OpenUnmix model: {str(model_err)}")
            
            # PROTE√á√ÉO 6: Aplica isolamento vocal
            try:
                logger.info("üéØ Aplicando separa√ß√£o de fontes com OpenUnmix...")
                
                # Converte para tensor PyTorch (channels x samples)
                audio_tensor = torch.from_numpy(samples_float.T).unsqueeze(0)
                logger.info(f"üìä Tensor criado: shape={audio_tensor.shape}")
                
                # Infer√™ncia sem gradientes (economia de mem√≥ria)
                with torch.no_grad():
                    # Aplica modelo
                    if callable(model):
                        # Se √© fun√ß√£o predict
                        vocals_tensor = model(audio_tensor, rate=target_sample_rate)
                        if isinstance(vocals_tensor, dict):
                            vocals_tensor = vocals_tensor.get('vocals', audio_tensor)
                    else:
                        # Se √© modelo
                        vocals_tensor = model(audio_tensor)
                    
                    logger.info(f"üìä Tensor de sa√≠da: shape={vocals_tensor.shape}")
                    
                    # Extrai apenas vocais e converte para numpy
                    vocals_np = vocals_tensor.squeeze(0).cpu().numpy()
                
                logger.info("‚úÖ Separa√ß√£o conclu√≠da")
                
            except Exception as openunmix_err:
                logger.error(f"üí• OpenUnmix falhou: {openunmix_err}", exc_info=True)
                raise AudioNormalizationException(f"Vocal isolation failed: {str(openunmix_err)}")
            
            # PROTE√á√ÉO 7: Converte resultado de volta para AudioSegment
            try:
                # Transp√µe de volta (samples x channels)
                vocals_np = vocals_np.T
                
                # Clip para [-1, 1]
                vocals_np = np.clip(vocals_np, -1.0, 1.0)
                
                # Converte para int16
                vocals_int16 = (vocals_np * 32767).astype(np.int16)
                
                # Flatten se for est√©reo
                if vocals_int16.shape[1] == 2:
                    vocals_bytes = vocals_int16.flatten().tobytes()
                    channels = 2
                else:
                    vocals_bytes = vocals_int16.tobytes()
                    channels = 1
                
                # Cria AudioSegment
                processed_audio = AudioSegment(
                    vocals_bytes,
                    frame_rate=target_sample_rate,
                    sample_width=2,
                    channels=channels
                )
                
                logger.info(f"‚úÖ AudioSegment criado: {len(processed_audio)}ms, {channels} canais")
                
            except Exception as convert_err:
                logger.error(f"üí• Erro ao converter resultado: {convert_err}")
                raise AudioNormalizationException(f"Failed to convert isolated vocals: {str(convert_err)}")
            
            # RESTAURA√á√ÉO: Tenta restaurar sample rate original
            try:
                if processed_audio.frame_rate != original_sample_rate:
                    processed_audio = processed_audio.set_frame_rate(original_sample_rate)
                    logger.info(f"üîÑ Sample rate restaurado para {original_sample_rate}Hz")
                
                # Mant√©m est√©reo ou converte para mono conforme original
                if original_channels == 1 and processed_audio.channels == 2:
                    # OPCIONAL: Converte de volta para mono se original era mono
                    # processed_audio = processed_audio.set_channels(1)
                    # logger.info("üîÑ Convertido de volta para mono")
                    pass  # Mant√©m est√©reo para melhor qualidade dos vocais
                    
            except Exception as restore_err:
                logger.warning(f"‚ö†Ô∏è Falha ao restaurar caracter√≠sticas: {restore_err}")
            
            logger.info("‚úÖ Isolamento vocal conclu√≠do com sucesso")
            return processed_audio
            
        except MemoryError as mem_err:
            logger.error(f"üíæ OUT OF MEMORY no isolamento vocal: {mem_err}")
            raise AudioNormalizationException(
                f"Out of memory during vocal isolation. Audio too large for ML model. "
                f"Try reducing duration or use a smaller audio file."
            )
        except AudioNormalizationException:
            raise
        except Exception as e:
            logger.error(f"üí• Erro cr√≠tico inesperado no isolamento vocal: {e}", exc_info=True)
            raise AudioNormalizationException(f"Critical error in vocal isolation: {str(e)}")
    
    async def _remove_noise(self, audio: AudioSegment) -> AudioSegment:
        """Remove ru√≠do usando noisereduce com PROTE√á√ÉO TOTAL contra erros de formato e mem√≥ria"""
        try:
            logger.info(f"üîá Iniciando remo√ß√£o de ru√≠do - dura√ß√£o: {len(audio)}ms, canais: {audio.channels}, sample_rate: {audio.frame_rate}")
            
            # PROTE√á√ÉO 1: Limita dura√ß√£o para evitar OOM
            max_duration_ms = 300000  # 5 minutos m√°ximo
            original_duration = len(audio)
            if original_duration > max_duration_ms:
                logger.warning(f"‚ö†Ô∏è √Åudio muito longo ({original_duration}ms), cortando para {max_duration_ms}ms")
                audio = audio[:max_duration_ms]
            
            # PROTE√á√ÉO 2: Converte para mono para reduzir uso de mem√≥ria
            original_channels = audio.channels
            if audio.channels > 1:
                logger.info("üîÑ Convertendo para mono temporariamente para economizar mem√≥ria")
                audio_mono = audio.set_channels(1)
            else:
                audio_mono = audio
            
            # PROTE√á√ÉO 3: Reduz sample rate se muito alto
            target_sample_rate = 22050  # 22kHz √© suficiente para noise reduction
            original_sample_rate = audio_mono.frame_rate
            if audio_mono.frame_rate > target_sample_rate:
                logger.info(f"üîÑ Reduzindo sample rate de {audio_mono.frame_rate} para {target_sample_rate}")
                audio_mono = audio_mono.set_frame_rate(target_sample_rate)
            
            # PROTE√á√ÉO 4: Converte para numpy com tipo correto
            try:
                # Obt√©m samples como array
                samples = np.array(audio_mono.get_array_of_samples())
                logger.info(f"üìä Array shape inicial: {samples.shape}, dtype: {samples.dtype}")
                
                # Converte para float32 e normaliza para [-1, 1]
                # CR√çTICO: noisereduce espera float32 ou float64 com valores em [-1, 1]
                if samples.dtype == np.int16:
                    samples_float = samples.astype(np.float32) / 32768.0
                elif samples.dtype == np.int32:
                    samples_float = samples.astype(np.float32) / 2147483648.0
                else:
                    # J√° √© float, normaliza se necess√°rio
                    samples_float = samples.astype(np.float32)
                    max_val = np.max(np.abs(samples_float))
                    if max_val > 1.0:
                        samples_float = samples_float / max_val
                
                logger.info(f"üìä Array ap√≥s normaliza√ß√£o: shape={samples_float.shape}, dtype={samples_float.dtype}, range=[{samples_float.min():.3f}, {samples_float.max():.3f}]")
                
                # PROTE√á√ÉO 5: Verifica se tem valores v√°lidos
                if np.isnan(samples_float).any() or np.isinf(samples_float).any():
                    logger.error("‚ùå Array cont√©m NaN ou Inf ap√≥s normaliza√ß√£o")
                    raise ValueError("Audio array contains invalid values (NaN or Inf)")
                
            except Exception as array_err:
                logger.error(f"üí• Erro ao preparar array para noise reduction: {array_err}")
                raise AudioNormalizationException(f"Failed to prepare audio array: {str(array_err)}")
            
            logger.info(f"üéØ Aplicando noisereduce em {len(samples_float)} samples @ {audio_mono.frame_rate}Hz")
            
            # PROTE√á√ÉO 6: Aplica redu√ß√£o de ru√≠do com par√¢metros conservadores e try/except
            try:
                reduced_noise = nr.reduce_noise(
                    y=samples_float,
                    sr=audio_mono.frame_rate,
                    stationary=True,  # Mais eficiente em mem√≥ria
                    prop_decrease=0.8,  # Redu√ß√£o agressiva mas controlada
                    freq_mask_smooth_hz=500,  # Suaviza√ß√£o de frequ√™ncia
                    time_mask_smooth_ms=50,  # Suaviza√ß√£o temporal
                    n_std_thresh_stationary=1.5,  # Threshold para ru√≠do estacion√°rio
                    n_jobs=1  # For√ßa single-thread para controlar mem√≥ria
                )
                
                logger.info(f"‚úÖ noisereduce conclu√≠do. Output shape: {reduced_noise.shape}, dtype: {reduced_noise.dtype}")
                
            except Exception as nr_err:
                logger.error(f"üí• noisereduce falhou: {nr_err}", exc_info=True)
                raise AudioNormalizationException(f"Noise reduction algorithm failed: {str(nr_err)}")
            
            # PROTE√á√ÉO 7: Valida output e converte de volta para int16
            try:
                # Verifica se output √© v√°lido
                if np.isnan(reduced_noise).any() or np.isinf(reduced_noise).any():
                    logger.error("‚ùå noisereduce retornou NaN ou Inf")
                    raise ValueError("Noise reduction produced invalid values")
                
                # Clip para garantir que est√° em [-1, 1]
                reduced_noise = np.clip(reduced_noise, -1.0, 1.0)
                
                # Converte para int16
                reduced_noise_int16 = (reduced_noise * 32767).astype(np.int16)
                
                logger.info(f"üìä Array final: shape={reduced_noise_int16.shape}, dtype={reduced_noise_int16.dtype}")
                
            except Exception as convert_err:
                logger.error(f"üí• Erro ao converter resultado: {convert_err}")
                raise AudioNormalizationException(f"Failed to convert processed audio: {str(convert_err)}")
            
            # PROTE√á√ÉO 8: Cria AudioSegment processado
            try:
                processed_audio = AudioSegment(
                    reduced_noise_int16.tobytes(),
                    frame_rate=audio_mono.frame_rate,
                    sample_width=2,  # int16 = 2 bytes
                    channels=1  # Sempre retorna mono ap√≥s noise reduction
                )
                
                logger.info(f"‚úÖ AudioSegment criado: {len(processed_audio)}ms")
                
            except Exception as segment_err:
                logger.error(f"üí• Erro ao criar AudioSegment: {segment_err}")
                raise AudioNormalizationException(f"Failed to create audio segment: {str(segment_err)}")
            
            # RESTAURA√á√ÉO: Tenta restaurar caracter√≠sticas originais
            try:
                # Restaura sample rate original se foi alterado
                if processed_audio.frame_rate != original_sample_rate:
                    processed_audio = processed_audio.set_frame_rate(original_sample_rate)
                    logger.info(f"üîÑ Sample rate restaurado para {original_sample_rate}Hz")
                
                # Restaura canais se original era est√©reo
                if original_channels > 1:
                    processed_audio = processed_audio.set_channels(original_channels)
                    logger.info(f"üîÑ Canais restaurados para {original_channels}")
                    
            except Exception as restore_err:
                logger.warning(f"‚ö†Ô∏è Falha ao restaurar caracter√≠sticas originais: {restore_err}")
                # Continua com √°udio processado mesmo se restaura√ß√£o falhar
            
            logger.info("‚úÖ Remo√ß√£o de ru√≠do conclu√≠da com sucesso")
            return processed_audio
            
        except MemoryError as mem_err:
            logger.error(f"üíæ MEMORY ERROR na remo√ß√£o de ru√≠do: {mem_err}")
            raise AudioNormalizationException(f"Out of memory during noise reduction. Audio too large: {str(mem_err)}")
        except AudioNormalizationException:
            raise
        except Exception as e:
            logger.error(f"üí• Erro cr√≠tico inesperado na remo√ß√£o de ru√≠do: {e}", exc_info=True)
            raise AudioNormalizationException(f"Critical error in noise removal: {str(e)}")
    
    async def _apply_highpass_filter(self, audio: AudioSegment) -> AudioSegment:
        """Aplica filtro high-pass com tratamento robusto de erros e m√∫ltiplas estrat√©gias"""
        try:
            cutoff_freq = 80  # Frequ√™ncia de corte: 80Hz
            logger.info(f"üéõÔ∏è Aplicando filtro high-pass com cutoff={cutoff_freq}Hz")
            
            # ESTRAT√âGIA 1: Tenta usar pydub high_pass_filter
            try:
                filtered_audio = high_pass_filter(audio, cutoff_freq)
                logger.info("‚úÖ Filtro high-pass aplicado via pydub")
                return filtered_audio
            except Exception as pydub_err:
                logger.warning(f"‚ö†Ô∏è pydub high_pass_filter falhou: {pydub_err}")
                
                # ESTRAT√âGIA 2: Usa ffmpeg diretamente via export/import
                try:
                    logger.info("üîÑ Tentando filtro high-pass via ffmpeg direto")
                    
                    # Cria arquivo tempor√°rio
                    import tempfile
                    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_in:
                        temp_input_path = temp_in.name
                    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_out:
                        temp_output_path = temp_out.name
                    
                    try:
                        # Exporta √°udio original
                        audio.export(temp_input_path, format="wav")
                        
                        # Aplica filtro via ffmpeg
                        import subprocess
                        ffmpeg_cmd = [
                            "ffmpeg", "-y", "-i", temp_input_path,
                            "-af", f"highpass=f={cutoff_freq}",
                            temp_output_path
                        ]
                        
                        result = subprocess.run(
                            ffmpeg_cmd,
                            capture_output=True,
                            text=True,
                            timeout=60
                        )
                        
                        if result.returncode != 0:
                            raise Exception(f"ffmpeg failed: {result.stderr}")
                        
                        # Carrega √°udio filtrado
                        filtered_audio = AudioSegment.from_wav(temp_output_path)
                        logger.info("‚úÖ Filtro high-pass aplicado via ffmpeg direto")
                        return filtered_audio
                        
                    finally:
                        # Limpa arquivos tempor√°rios
                        import os
                        try:
                            if os.path.exists(temp_input_path):
                                os.unlink(temp_input_path)
                            if os.path.exists(temp_output_path):
                                os.unlink(temp_output_path)
                        except Exception:
                            pass
                            
                except Exception as ffmpeg_err:
                    logger.warning(f"‚ö†Ô∏è ffmpeg direto tamb√©m falhou: {ffmpeg_err}")
                    
                    # ESTRAT√âGIA 3: Implementa filtro manualmente com scipy
                    try:
                        logger.info("üîÑ Tentando filtro high-pass via scipy")
                        from scipy import signal
                        
                        # Converte para numpy
                        samples = np.array(audio.get_array_of_samples())
                        sample_rate = audio.frame_rate
                        
                        # Verifica se √© stereo
                        if audio.channels == 2:
                            samples = samples.reshape((-1, 2))
                            is_stereo = True
                        else:
                            is_stereo = False
                        
                        # Normaliza para float
                        samples_float = samples.astype(np.float32) / (2**15)
                        
                        # Cria filtro Butterworth high-pass
                        nyquist = sample_rate / 2
                        normalized_cutoff = cutoff_freq / nyquist
                        b, a = signal.butter(5, normalized_cutoff, btype='high')
                        
                        # Aplica filtro
                        if is_stereo:
                            filtered_left = signal.filtfilt(b, a, samples_float[:, 0])
                            filtered_right = signal.filtfilt(b, a, samples_float[:, 1])
                            filtered_samples = np.column_stack((filtered_left, filtered_right))
                        else:
                            filtered_samples = signal.filtfilt(b, a, samples_float)
                        
                        # Converte de volta para int16
                        filtered_samples = np.clip(filtered_samples * (2**15), -32768, 32767).astype(np.int16)
                        
                        # Cria AudioSegment
                        filtered_audio = AudioSegment(
                            filtered_samples.tobytes(),
                            frame_rate=sample_rate,
                            sample_width=2,
                            channels=audio.channels
                        )
                        
                        logger.info("‚úÖ Filtro high-pass aplicado via scipy")
                        return filtered_audio
                        
                    except Exception as scipy_err:
                        logger.error(f"üí• Todas as estrat√©gias de high-pass falharam. √öltimo erro (scipy): {scipy_err}")
                        raise AudioNormalizationException(
                            f"High-pass filter failed with all strategies. "
                            f"pydub: {str(pydub_err)[:50]}, "
                            f"ffmpeg: {str(ffmpeg_err)[:50]}, "
                            f"scipy: {str(scipy_err)[:50]}"
                        )
                        
        except AudioNormalizationException:
            raise
        except Exception as e:
            logger.error(f"üí• Erro cr√≠tico inesperado no filtro high-pass: {e}", exc_info=True)
            raise AudioNormalizationException(f"Critical error in high-pass filter: {str(e)}")