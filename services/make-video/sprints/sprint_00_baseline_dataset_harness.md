# Sprint 00: Baseline + Dataset + Evaluation Harness

> **Status**: üî¥ **CRITICAL - DEVE SER IMPLEMENTADA ANTES DA SPRINT 01**  
> **Prioridade**: P0 (Ultra Grave)  
> **Dura√ß√£o Estimada**: 1-2 semanas  
> **Depend√™ncias**: Nenhuma (√© a base de tudo)

---

## üéØ Objetivo T√©cnico

**Estabelecer infraestrutura de avalia√ß√£o ANTES de qualquer desenvolvimento:**

1. **Dataset imut√°vel e estratificado** com ground truth confi√°vel
2. **Baseline mensur√°vel** (sistema atual documentado + m√©tricas)
3. **Harness de avalia√ß√£o automatizado** (CI/CD gates para "zero regress√£o")

**Por que Sprint 00 √© cr√≠tica?**

Sem dataset + baseline + harness **desde o in√≠cio**, voc√™:
- ‚ùå N√£o consegue provar "sem regress√£o" sprint a sprint
- ‚ùå Treina/calibra modelos (Sprints 06-07) em "areia movedi√ßa"
- ‚ùå Corre risco de **data leakage** e **overfit** silencioso
- ‚ùå N√£o pode validar estimativas de impacto (+5%, +8%, etc.)

**Com Sprint 00 implementada:**
- ‚úÖ Cada sprint prova ganho vs baseline
- ‚úÖ Gates automatizados impedem regress√µes
- ‚úÖ Dataset sustenta treino/calibra√ß√£o de forma confi√°vel
- ‚úÖ Decis√µes t√©cnicas baseadas em evid√™ncia

---

## üìÅ Estrutura de Diret√≥rios do Projeto

**Dataset de Valida√ß√£o Atual**:

```
services/make-video/storage/validation/
‚îú‚îÄ‚îÄ sample_OK/               # V√≠deos COM legenda embutida (positivos)
‚îÇ   ‚îú‚îÄ‚îÄ video_001.mp4
‚îÇ   ‚îú‚îÄ‚îÄ video_002.mp4
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ sample_NOT_OK/           # V√≠deos SEM legenda embutida (negativos)
‚îÇ   ‚îú‚îÄ‚îÄ video_101.mp4
‚îÇ   ‚îú‚îÄ‚îÄ video_102.mp4
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ h264_converted/          # V√≠deos convertidos para H264 (processamento)
‚îî‚îÄ‚îÄ quick_test/              # Subset r√°pido para testes locais
```

**Estrutura de Dataset Recomendada para Sprint 00**:

```
services/make-video/storage/validation/
‚îú‚îÄ‚îÄ holdout_test_set/        # 200 v√≠deos (NUNCA usar para treino!)
‚îÇ   ‚îú‚îÄ‚îÄ with_subs/           # 100 v√≠deos COM legenda
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video_001.mp4
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ without_subs/        # 100 v√≠deos SEM legenda
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video_101.mp4
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ ground_truth.json    # Anota√ß√µes gold standard
‚îú‚îÄ‚îÄ development_set/         # 100 v√≠deos (tuning/valida√ß√£o)
‚îÇ   ‚îú‚îÄ‚îÄ with_subs/
‚îÇ   ‚îú‚îÄ‚îÄ without_subs/
‚îÇ   ‚îî‚îÄ‚îÄ ground_truth.json
‚îú‚îÄ‚îÄ smoke_test_set/          # 20 v√≠deos (CI/CD r√°pido)
‚îÇ   ‚îú‚îÄ‚îÄ videos/
‚îÇ   ‚îî‚îÄ‚îÄ golden_predictions.json
‚îî‚îÄ‚îÄ baseline_results/        # Resultados do baseline
    ‚îú‚îÄ‚îÄ baseline_metrics.json
    ‚îú‚îÄ‚îÄ breakdown_by_slice.json
    ‚îî‚îÄ‚îÄ failed_videos.log
```

> **‚ö†Ô∏è NOTA**: Atualmente o projeto tem `sample_OK/` e `sample_NOT_OK/`. Esta sprint prop√µe reestrutura√ß√£o para separar holdout/dev/smoke sets e evitar contamina√ß√£o.

---

## üìä Componentes da Sprint 00

### 1Ô∏è‚É£ Dataset Imut√°vel (Holdout Test Set)

**Objetivo**: Conjunto de teste que **NUNCA** ser√° usado para treino/tuning.

**Especifica√ß√£o**:

```yaml
Holdout Test Set:
  size: 200 v√≠deos
  composition:
    com_legenda: 100 v√≠deos
    sem_legenda: 100 v√≠deos
  
  estratifica√ß√£o:
    resolucao:
      1080p: 100 v√≠deos (50%)
      720p: 50 v√≠deos (25%)
      4K: 30 v√≠deos (15%)
      outros: 20 v√≠deos (10% - vertical, 480p, etc.)
    
    complexidade_fundo:
      simples: 80 v√≠deos (fundo preto/gradiente)
      medio: 80 v√≠deos (fundo com padr√µes)
      complexo: 40 v√≠deos (fundo com texto/logos)
    
    posicao_legenda:
      bottom: 80 v√≠deos (80% - padr√£o)
      top: 10 v√≠deos (10% - edge case cr√≠tico)
      centro: 10 v√≠deos (10% - edge case)
    
    duracao_aparicao:
      curta: 20 v√≠deos (<2s por legenda)
      normal: 140 v√≠deos (2-5s)
      longa: 40 v√≠deos (>5s)
    
    estilo_legenda:
      branco_sombra: 60 v√≠deos (padr√£o)
      colorido: 20 v√≠deos
      outlined: 20 v√≠deos
    
    qualidade_video:
      alta: 100 v√≠deos (>5 Mbps)
      media: 60 v√≠deos (2-5 Mbps)
      baixa: 40 v√≠deos (<2 Mbps - artifacts)

Smoke Test Set:
  size: 20 v√≠deos (subset do holdout)
  purpose: Testes r√°pidos em CI/PR (execu√ß√£o <2min)
  composition:
    - 5 casos "f√°ceis" (1080p, bottom, fundo simples)
    - 5 casos "m√©dios" (720p, bottom, fundo m√©dio)
    - 5 casos "hard" (4K, top, fundo complexo)
    - 5 casos "edge" (vertical, curta dura√ß√£o, baixa qualidade)

Development Set (para tuning/valida√ß√£o durante sprints):
  size: 100 v√≠deos (SEPARADO do holdout!)
  purpose: Tuning de hiperpar√¢metros, threshold, ROI, etc.
  composition: Mesma estratifica√ß√£o do holdout
```

**Ground Truth Format**:

```json
{
  "video_id": "abc123xyz",
  "video_path": "services/make-video/storage/validation/holdout_test_set/with_subs/abc123xyz.mp4",
  "resolution": {"width": 1920, "height": 1080},
  "duration_seconds": 180,
  "ground_truth": {
    "has_embedded_subtitles": true,
    "subtitle_regions": [
      {
        "timestamp_start": 5.2,
        "timestamp_end": 8.7,
        "text": "Example subtitle text",
        "bbox": {"x": 640, "y": 950, "width": 640, "height": 60},
        "position": "bottom",
        "confidence_annotation": 1.0
      }
    ]
  },
  "metadata": {
    "background_complexity": "medium",
    "compression_quality": "high",
    "annotator_id": "annotator_01",
    "annotation_date": "2026-02-13",
    "validation_status": "double_checked",
    "source_folder": "sample_OK"  # Migrado de sample_OK/ existente
  }
}
```

**Guidelines de Rotulagem**:

1. **Legenda embutida** (hardcoded): texto que faz parte do frame (n√£o SRT/ASS)
2. **Posi√ß√£o**: bottom (‚â•70% height), top (‚â§30% height), centro (30-70%)
3. **Dupla verifica√ß√£o**: 2 anotadores independentes, resolver conflitos
4. **Casos amb√≠guos**: texto de HUD/grafismos/logos N√ÉO √© legenda
5. **Qualidade m√≠nima**: legenda deve ser leg√≠vel por humano (‚â•80% dos caracteres)

---

### 2Ô∏è‚É£ Baseline Documentado

**Objetivo**: Medir sistema ATUAL (antes de qualquer sprint) como ponto de partida.

**Implementa√ß√£o**:

```python
"""
baseline/evaluate_baseline.py

Script para avaliar sistema ATUAL no holdout test set.
"""

import json
import logging
from pathlib import Path
from typing import Dict, List
from app.video_processing.video_validator import SubtitleValidator
from app.ocr.paddle_ocr import PaddleOCRDetector

logger = logging.getLogger(__name__)


class BaselineEvaluator:
    """
    Avalia sistema ATUAL (pre-Sprint 01) no holdout test set.
    """
    
    def __init__(self, test_set_path: str, results_dir: str):
        self.test_set_path = Path(test_set_path)
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # Initialize CURRENT system (hardcoded 1080p, full frame, etc.)
        self.ocr_detector = PaddleOCRDetector()
        self.validator = SubtitleValidator(self.ocr_detector)
    
    def evaluate(self) -> Dict:
        """
        Avalia baseline no holdout test set.
        
        Returns:
            Resultados completos com m√©tricas + breakdown por slice
        """
        # Load ground truth
        ground_truth = self._load_ground_truth()
        
        # Run predictions
        predictions = {}
        errors = []
        
        for video_id, gt in ground_truth.items():
            try:
                video_path = gt['video_path']
                prediction = self.validator.has_embedded_subtitles(video_path)
                predictions[video_id] = prediction
            except Exception as e:
                logger.error(f"Baseline failed on {video_id}: {e}")
                errors.append({'video_id': video_id, 'error': str(e)})
                predictions[video_id] = None  # Count as error
        
        # Calculate metrics
        metrics = self._calculate_metrics(ground_truth, predictions)
        
        # Breakdown by slices
        slices = self._breakdown_by_slices(ground_truth, predictions)
        
        # Save results
        results = {
            'baseline_version': 'pre-sprint-01',
            'evaluation_date': '2026-02-13',
            'test_set_size': len(ground_truth),
            'errors': errors,
            'overall_metrics': metrics,
            'slices': slices,
        }
        
        self._save_results(results)
        
        return results
    
    def _calculate_metrics(
        self,
        ground_truth: Dict,
        predictions: Dict
    ) -> Dict:
        """
        Calcula Precision, Recall, F1, FPR, Accuracy.
        """
        tp = fp = tn = fn = 0
        
        for video_id, gt in ground_truth.items():
            gt_label = gt['ground_truth']['has_embedded_subtitles']
            pred = predictions.get(video_id)
            
            if pred is None:
                # Error = False Negative (conservative)
                if gt_label:
                    fn += 1
                else:
                    tn += 1
                continue
            
            if gt_label and pred:
                tp += 1
            elif not gt_label and not pred:
                tn += 1
            elif not gt_label and pred:
                fp += 1
            elif gt_label and not pred:
                fn += 1
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0
        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0
        accuracy = (tp + tn) / (tp + tn + fp + fn)
        
        return {
            'tp': tp,
            'fp': fp,
            'tn': tn,
            'fn': fn,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'fpr': fpr,
            'accuracy': accuracy,
            'error_rate': len([p for p in predictions.values() if p is None]) / len(predictions)
        }
    
    def _breakdown_by_slices(
        self,
        ground_truth: Dict,
        predictions: Dict
    ) -> Dict:
        """
        M√©tricas por slice (resolu√ß√£o, posi√ß√£o, complexidade).
        """
        slices = {
            'by_resolution': {},
            'by_position': {},
            'by_background': {},
            'by_duration': {},
        }
        
        # Group by slices
        for video_id, gt in ground_truth.items():
            # Resolution
            res = f"{gt['resolution']['width']}x{gt['resolution']['height']}"
            if res not in slices['by_resolution']:
                slices['by_resolution'][res] = {'gt': [], 'pred': []}
            slices['by_resolution'][res]['gt'].append(gt['ground_truth']['has_embedded_subtitles'])
            slices['by_resolution'][res]['pred'].append(predictions.get(video_id))
            
            # Position (if has subtitles)
            if gt['ground_truth']['has_embedded_subtitles'] and gt['ground_truth']['subtitle_regions']:
                pos = gt['ground_truth']['subtitle_regions'][0]['position']
                if pos not in slices['by_position']:
                    slices['by_position'][pos] = {'gt': [], 'pred': []}
                slices['by_position'][pos]['gt'].append(True)
                slices['by_position'][pos]['pred'].append(predictions.get(video_id))
            
            # Background complexity
            bg = gt['metadata']['background_complexity']
            if bg not in slices['by_background']:
                slices['by_background'][bg] = {'gt': [], 'pred': []}
            slices['by_background'][bg]['gt'].append(gt['ground_truth']['has_embedded_subtitles'])
            slices['by_background'][bg]['pred'].append(predictions.get(video_id))
        
        # Calculate metrics per slice
        for slice_type, slice_data in slices.items():
            for slice_name, data in slice_data.items():
                metrics = self._calculate_metrics_from_lists(data['gt'], data['pred'])
                slices[slice_type][slice_name] = metrics
        
        return slices
    
    def _calculate_metrics_from_lists(self, gt_list: List, pred_list: List) -> Dict:
        """Helper para calcular m√©tricas de listas."""
        tp = fp = tn = fn = 0
        
        for gt, pred in zip(gt_list, pred_list):
            if pred is None:
                if gt:
                    fn += 1
                else:
                    tn += 1
                continue
            
            if gt and pred:
                tp += 1
            elif not gt and not pred:
                tn += 1
            elif not gt and pred:
                fp += 1
            elif gt and not pred:
                fn += 1
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0
        
        return {
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'samples': len(gt_list)
        }
    
    def _load_ground_truth(self) -> Dict:
        """Carrega ground truth do test set."""
        # Load from JSON files
        gt_file = self.test_set_path / "ground_truth.json"
        with open(gt_file) as f:
            return json.load(f)
    
    def _save_results(self, results: Dict):
        """Salva resultados em JSON."""
        output_file = self.results_dir / "baseline_results.json"
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        logger.info(f"Baseline results saved: {output_file}")
```

**Baseline Report Example**:

```
BASELINE EVALUATION (Pre-Sprint 01)
====================================

Overall Metrics:
  Precision: 0.745
  Recall: 0.718
  F1: 0.731
  FPR: 0.080 (8.0%)
  Accuracy: 0.835
  Error Rate: 0.068 (6.8% crashes/exceptions)

Breakdown by Resolution:
  1080p (100 videos):
    Precision: 0.820, Recall: 0.800, F1: 0.810
  720p (50 videos):
    Precision: 0.650, Recall: 0.580, F1: 0.613 ‚ö†Ô∏è BAIXO!
  4K (30 videos):
    Precision: 0.600, Recall: 0.520, F1: 0.557 ‚ö†Ô∏è MUITO BAIXO!
  Others (20 videos):
    Precision: 0.700, Recall: 0.650, F1: 0.674

Breakdown by Subtitle Position:
  Bottom (80 videos):
    Precision: 0.810, Recall: 0.780, F1: 0.795
  Top (10 videos):
    Precision: 0.500, Recall: 0.400, F1: 0.444 ‚ùå CR√çTICO!
  Center (10 videos):
    Precision: 0.667, Recall: 0.600, F1: 0.632

Breakdown by Background Complexity:
  Simple (80 videos):
    Precision: 0.850, Recall: 0.820, F1: 0.835
  Medium (80 videos):
    Precision: 0.740, Recall: 0.710, F1: 0.725
  Complex (40 videos):
    Precision: 0.600, Recall: 0.580, F1: 0.590 ‚ö†Ô∏è BAIXO!
```

**Baseline estabelece targets para as sprints:**
- Sprint 01 deve melhorar 720p/4K (reduzir crashes)
- Sprint 02 deve melhorar top subtitles (ROI com fallback!)
- Sprint 03 deve melhorar complex background

---

### 3Ô∏è‚É£ Evaluation Harness (CI/CD Gates)

**Objetivo**: Gate automatizado que roda a cada PR/sprint e impede regress√µes.

**Implementa√ß√£o**:

```python
"""
tests/evaluation/test_no_regression.py

Harness de avalia√ß√£o com gates autom√°ticos.
"""

import pytest
import json
from pathlib import Path
from baseline.evaluate_baseline import BaselineEvaluator


class TestNoRegression:
    """
    Gates de regress√£o - FALHAM se m√©tricas piorarem.
    """
    
    @pytest.fixture(scope='class')
    def baseline_metrics(self):
        """Carrega m√©tricas do baseline."""
        baseline_file = Path('results/baseline_results.json')
        with open(baseline_file) as f:
            return json.load(f)['overall_metrics']
    
    @pytest.fixture(scope='class')
    def current_metrics(self):
        """Avalia sistema ATUAL no smoke test set (20 v√≠deos)."""
        evaluator = BaselineEvaluator(
            test_set_path='data/smoke_test',
            results_dir='results/current'
        )
        results = evaluator.evaluate()
        return results['overall_metrics']
    
    def test_precision_no_regression(self, baseline_metrics, current_metrics):
        """Gate: Precis√£o n√£o pode regredir mais de 1%."""
        baseline_prec = baseline_metrics['precision']
        current_prec = current_metrics['precision']
        
        regression = baseline_prec - current_prec
        
        assert regression <= 0.01, (
            f"PRECISION REGRESSION: "
            f"baseline={baseline_prec:.4f}, current={current_prec:.4f}, "
            f"delta={regression:.4f} (max allowed: 0.01)"
        )
    
    def test_recall_no_regression(self, baseline_metrics, current_metrics):
        """Gate: Recall n√£o pode regredir mais de 2%."""
        baseline_rec = baseline_metrics['recall']
        current_rec = current_metrics['recall']
        
        regression = baseline_rec - current_rec
        
        assert regression <= 0.02, (
            f"RECALL REGRESSION: "
            f"baseline={baseline_rec:.4f}, current={current_rec:.4f}, "
            f"delta={regression:.4f} (max allowed: 0.02)"
        )
    
    def test_fpr_no_regression(self, baseline_metrics, current_metrics):
        """Gate: FPR n√£o pode aumentar mais de 0.5%."""
        baseline_fpr = baseline_metrics['fpr']
        current_fpr = current_metrics['fpr']
        
        increase = current_fpr - baseline_fpr
        
        assert increase <= 0.005, (
            f"FPR REGRESSION: "
            f"baseline={baseline_fpr:.4f}, current={current_fpr:.4f}, "
            f"delta={increase:.4f} (max allowed: 0.005)"
        )
    
    def test_error_rate_improved_or_stable(self, baseline_metrics, current_metrics):
        """Gate: Error rate (crashes) n√£o pode aumentar."""
        baseline_err = baseline_metrics['error_rate']
        current_err = current_metrics['error_rate']
        
        increase = current_err - baseline_err
        
        assert increase <= 0.0, (
            f"ERROR RATE REGRESSION: "
            f"baseline={baseline_err:.4f}, current={current_err:.4f}, "
            f"delta={increase:.4f} (must not increase)"
        )
    
    def test_smoke_set_intact(self, current_metrics):
        """Gate: Smoke set (20 v√≠deos fixos) deve manter predictions."""
        # Load smoke set "golden predictions" (from baseline)
        golden_file = Path('services/make-video/storage/validation/smoke_test_set/golden_predictions.json')
        with open(golden_file) as f:
            golden = json.load(f)
        
        # Run current system on smoke set
        from app.video_processing.video_validator import SubtitleValidator
        from app.ocr.paddle_ocr import PaddleOCRDetector
        
        validator = SubtitleValidator(PaddleOCRDetector())
        
        smoke_test_dir = Path('services/make-video/storage/validation/smoke_test_set/videos')
        regressions = []
        for video_id, expected_pred in golden.items():
            video_path = smoke_test_dir / f"{video_id}.mp4"
            current_pred = validator.has_embedded_subtitles(str(video_path))
            
            if current_pred != expected_pred:
                regressions.append({
                    'video_id': video_id,
                    'expected': expected_pred,
                    'got': current_pred
                })
        
        assert len(regressions) <= 1, (
            f"SMOKE SET REGRESSION: {len(regressions)} videos changed predictions "
            f"(max allowed: 1). Details: {regressions}"
        )
```

**CI/CD Integration (.github/workflows/regression_check.yml)**:

```yaml
name: Regression Check

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

jobs:
  regression-test:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest
      
      - name: Download test dataset
        run: |
          # Download smoke test set (20 videos)
          aws s3 sync s3://ytcaption-test-data/smoke_test data/smoke_test
      
      - name: Run regression tests
        run: |
          pytest tests/evaluation/test_no_regression.py -v --tb=short
      
      - name: Fail if regressions detected
        if: failure()
        run: |
          echo "‚ùå REGRESSION DETECTED - PR BLOCKED"
          exit 1
```

---

## üìã Crit√©rio de Aceite Sprint 00

```
‚úÖ CR√çTICO (MUST HAVE)
  ‚ñ° Holdout test set criado: 200 v√≠deos estratificados
  ‚ñ° Smoke test set criado: 20 v√≠deos (subset do holdout)
  ‚ñ° Development set criado: 100 v√≠deos (separado do holdout)
  ‚ñ° Ground truth anotado por 2 anotadores independentes
  ‚ñ° Guidelines de rotulagem documentadas
  ‚ñ° Baseline avaliado no holdout: m√©tricas salvas em baseline_results.json
  ‚ñ° Breakdown por slices documentado (resolu√ß√£o, posi√ß√£o, background)
  ‚ñ° Harness de avalia√ß√£o implementado: test_no_regression.py
  ‚ñ° CI/CD gates configurados: regression_check.yml
  ‚ñ° Smoke set validado: ‚â§1 regress√£o permitida

‚úÖ IMPORTANTE (SHOULD HAVE)
  ‚ñ° Dataset versionado (Git LFS ou DVC)
  ‚ñ° Documenta√ß√£o de coleta/amostragem de v√≠deos
  ‚ñ° Scripts de valida√ß√£o de ground truth (dupla checagem)
  ‚ñ° Dashboard de m√©tricas (Grafana/MLflow)
  ‚ñ° Slices adicionais: dura√ß√£o, qualidade, estilo

‚úÖ NICE TO HAVE (COULD HAVE)
  ‚ñ° Anota√ß√£o semi-autom√°tica (OCR + review manual)
  ‚ñ° Inter-annotator agreement (Kappa score)
  ‚ñ° Test set expandido (500 v√≠deos)
```

### Defini√ß√£o de "Done" Sprint 00

1. ‚úÖ Holdout test set (200 v√≠deos) pronto e versionado
2. ‚úÖ Baseline medido: Precision/Recall/FPR/Error Rate
3. ‚úÖ Breakdown por slices mostra gargalos (720p/4K/top subs)
4. ‚úÖ Harness CI/CD bloqueando PRs com regress√£o
5. ‚úÖ Smoke set (20 v√≠deos) rodando em <2min
6. ‚úÖ Time alinhado: baseline √© "source of truth" para as sprints

---

## üöÄ Impacto da Sprint 00

| Aspecto | Antes (sem Sprint 00) | Depois (com Sprint 00) |
|---------|----------------------|------------------------|
| **Treino Sprint 06** | Dataset indefinido, risco de leakage | Dataset limpo, split disjunto, sem leakage ‚úÖ |
| **Calibra√ß√£o Sprint 07** | Sem holdout para calibrar | Holdout dedicado, isotonic seguro ‚úÖ |
| **Zero Regress√£o** | Sem como provar | Gates automatizados por sprint ‚úÖ |
| **Decis√µes t√©cnicas** | Baseadas em "achismo" | Baseadas em breakdown por slice ‚úÖ |
| **Risco de overfit** | ALTO (sem holdout) | BAIXO (holdout imut√°vel) ‚úÖ |
| **Tempo de valida√ß√£o** | Manual, demorado | Automatizado, <2min (smoke set) ‚úÖ |

**ROI da Sprint 00**:
- Investimento: 1-2 semanas (anota√ß√£o + scripts)
- Retorno: **Evita 4-6 semanas de retrabalho** (treino em dataset ruim, regress√µes n√£o detectadas, overfit em produ√ß√£o)

---

## üìù Checklist de Implementa√ß√£o

```
Sprint 00 Checklist - Status: üü° IN PROGRESS (2025-02-13)

  Infrastructure & Environment:
    ‚úÖ Setup Python environment (3.11.2 + venv)
    ‚úÖ Install PaddleOCR 3.4.0 (CPU version)
    ‚úÖ Install testing framework (pytest 7.4.3 + pytest-cov)
    ‚úÖ Install dependencies (prometheus-client, fastapi, opencv, etc.)
    ‚ö†Ô∏è Fix PaddleOCR MKL arithmetic error (BLOCKER - needs resolution)

  Dataset Structure:
    ‚úÖ Create validation directory structure
    ‚úÖ Create sample_OK/ directory (7 videos)
    ‚úÖ Create sample_NOT_OK/ directory (39 videos)
    ‚úÖ Create ground_truth.json for sample_OK (7 videos)
    ‚úÖ Create ground_truth.json for sample_NOT_OK (39 videos)
    ‚úÖ Create holdout_test_set/ directory (ready for population)
    ‚úÖ Create dev_set/ directory (ready for population)
    ‚úÖ Create smoke_set/ directory (ready for population)
    ‚ö†Ô∏è Dataset imbalanced (15.2% positive class - needs more positive samples)
    ‚òê Collect 320 videos total (200 holdout + 100 dev + 20 smoke)
    ‚òê Stratify by resolution/position/complexity
    ‚òê Annotate ground truth (2 independent annotators)
    ‚òê Resolve annotation conflicts
    ‚òê Validate annotation quality (spot check 10%)
    ‚òê Version dataset (Git LFS / DVC)

  Baseline Measurement:
    ‚úÖ Create scripts/measure_baseline.py (260 lines - full implementation)
    ‚úÖ Create scripts/measure_baseline_simple.py (189 lines - fallback)
    ‚úÖ Generate baseline_results.json (placeholder - OCR pending)
    ‚ö†Ô∏è OCR measurement BLOCKED by PaddleOCR initialization error
    ‚òê Fix PaddleOCR or implement pytesseract fallback
    ‚òê Run actual baseline measurement on videos
    ‚òê Document breakdown by slices (resolution/position/complexity)

  Regression Test Harness:
    ‚úÖ Create tests/test_sprint00_harness.py (regression gates)
    ‚úÖ Implement baseline_exists test (PASSING)
    ‚úÖ Implement baseline_sanity test (PENDING - needs real metrics)
    ‚úÖ Implement no_regression gates (F1, Recall, FPR)
    ‚úÖ Implement goal_tracking tests (informational)
    ‚úÖ Implement smoke_videos_process test (SKIPPED - needs smoke_set videos)
    ‚úÖ Create storage/validation/README.md (dataset documentation)
    ‚òê Configure CI/CD: .github/workflows/regression_check.yml
    ‚òê Validate gates: simulate deliberate regression (should block)

  Documentation & Finalization:
    ‚úÖ Update sprint_00 checklist (this document)
    ‚òê Document baseline as "source of truth"
    ‚òê Prepare presentation for team (alignment)
    ‚òê Approve Sprint 00 as "complete"
    ‚òê Rename to OK_sprint_00_baseline_dataset_harness.md
    ‚òê Unblock Sprint 01 (baseline established)

  BLOCKERS (P0 - Must Resolve):
    üî¥ PaddleOCR MKL arithmetic error (SIGFPE) - prevents OCR measurement
       Solutions:
         A. Fix PaddleOCR installation (different version/backend)
         B. Implement pytesseract fallback temporarily
         C. Use cloud OCR API (Google Vision, AWS Rekognition)
    
    üü° Dataset imbalance (15.2% positive class)
       Solution: Add 20+ more videos WITH subtitles to sample_OK
```

---

## üéØ Pr√≥ximos Passos

1. ‚úÖ **Aprovar Sprint 00 como cr√≠tica** (bloqueia Sprints 01-10)
2. ‚è≥ Alocar recursos: 1-2 pessoas full-time por 1-2 semanas
3. ‚è≥ Coletar e anotar dataset (200 + 100 + 20 v√≠deos)
4. ‚è≥ Implementar baseline evaluator + harness
5. ‚è≥ Configurar CI/CD gates
6. ‚úÖ **Aprovar baseline como "source of truth"**
7. ‚û°Ô∏è **Liberar Sprint 01** (com baseline estabelecido)

---

## üìå Nota Cr√≠tica

> **SEM SPRINT 00, O ROADMAP SPRINTS 01-10 √â ARRISCADO A PONTO DE SER INVI√ÅVEL.**
>
> Esta sprint resolve o problema #1 identificado no documento FIX_OCR.md:
> - ‚úÖ Dataset + ground truth + harness ANTES do desenvolvimento
> - ‚úÖ Sustenta treino/calibra√ß√£o (Sprints 06-07)
> - ‚úÖ Gates automatizados para "zero regress√£o"
> - ‚úÖ Decis√µes baseadas em evid√™ncia (breakdown por slice)
>
> **Recomenda√ß√£o: Implementar Sprint 00 IMEDIATAMENTE antes de qualquer outra sprint.**

---

## üîÑ Migra√ß√£o de Dados Existentes

**Situa√ß√£o Atual**: O projeto j√° possui datasets em:
- `services/make-video/storage/validation/sample_OK/` - v√≠deos COM legenda embutida
- `services/make-video/storage/validation/sample_NOT_OK/` - v√≠deos SEM legenda embutida

**Plano de Migra√ß√£o para Estrutura Sprint 00**:

```bash
# Script de migra√ß√£o (migrate_dataset.sh)

#!/bin/bash
set -e

VALIDATION_ROOT="services/make-video/storage/validation"
SOURCE_OK="$VALIDATION_ROOT/sample_OK"
SOURCE_NOT_OK="$VALIDATION_ROOT/sample_NOT_OK"

# Criar nova estrutura
mkdir -p "$VALIDATION_ROOT/holdout_test_set/with_subs"
mkdir -p "$VALIDATION_ROOT/holdout_test_set/without_subs"
mkdir -p "$VALIDATION_ROOT/development_set/with_subs"
mkdir -p "$VALIDATION_ROOT/development_set/without_subs"
mkdir -p "$VALIDATION_ROOT/smoke_test_set/videos"
mkdir -p "$VALIDATION_ROOT/baseline_results"

# Contar v√≠deos dispon√≠veis
NUM_OK=$(ls -1 "$SOURCE_OK"/*.mp4 2>/dev/null | wc -l)
NUM_NOT_OK=$(ls -1 "$SOURCE_NOT_OK"/*.mp4 2>/dev/null | wc -l)

echo "V√≠deos dispon√≠veis:"
echo "  - COM legenda (sample_OK): $NUM_OK"
echo "  - SEM legenda (sample_NOT_OK): $NUM_NOT_OK"

# Estrat√©gia de split (70% holdout, 25% dev, 5% smoke)
# Para 100 v√≠deos OK: 70 holdout, 25 dev, 5 smoke
# Para 100 v√≠deos NOT_OK: 70 holdout, 25 dev, 5 smoke

# Assumindo sample_OK tem suficientes v√≠deos, fazer split aleat√≥rio
cd "$SOURCE_OK"
ls -1 *.mp4 | shuf > /tmp/ok_shuffled.txt

# Split sample_OK
head -n 70 /tmp/ok_shuffled.txt | while read video; do
    cp "$video" "$VALIDATION_ROOT/holdout_test_set/with_subs/"
done

tail -n +71 /tmp/ok_shuffled.txt | head -n 25 | while read video; do
    cp "$video" "$VALIDATION_ROOT/development_set/with_subs/"
done

tail -n 5 /tmp/ok_shuffled.txt | while read video; do
    cp "$video" "$VALIDATION_ROOT/smoke_test_set/videos/"
done

# Split sample_NOT_OK (similar)
cd "$SOURCE_NOT_OK"
ls -1 *.mp4 | shuf > /tmp/not_ok_shuffled.txt

head -n 70 /tmp/not_ok_shuffled.txt | while read video; do
    cp "$video" "$VALIDATION_ROOT/holdout_test_set/without_subs/"
done

tail -n +71 /tmp/not_ok_shuffled.txt | head -n 25 | while read video; do
    cp "$video" "$VALIDATION_ROOT/development_set/without_subs/"
done

tail -n 5 /tmp/not_ok_shuffled.txt | while read video; do
    cp "$video" "$VALIDATION_ROOT/smoke_test_set/videos/"
done

echo "‚úÖ Migra√ß√£o conclu√≠da!"
echo "Estrutura criada em: $VALIDATION_ROOT"
```

**Pr√≥ximos Passos Ap√≥s Migra√ß√£o**:

1. **Anotar ground truth**: Criar `ground_truth.json` para holdout/dev sets
2. **Validar qualidade**: Spot check manual de 10% dos v√≠deos
3. **Rodar baseline**: Executar `baseline/evaluate_baseline.py`
4. **Gerar golden predictions**: Para smoke test set (CI/CD)
5. **Versionar datasets**: Usar Git LFS ou DVC

**Exemplo de Ground Truth Inicial**:

```python
# scripts/generate_initial_ground_truth.py

import json
from pathlib import Path

def generate_ground_truth(videos_dir: Path, has_subs: bool) -> dict:
    """
    Gera ground truth inicial (placeholder) para valida√ß√£o manual posterior.
    """
    ground_truth = {}
    
    for video_path in videos_dir.glob("*.mp4"):
        video_id = video_path.stem
        ground_truth[video_id] = {
            "video_id": video_id,
            "video_path": str(video_path),
            "ground_truth": {
                "has_embedded_subtitles": has_subs,
                "subtitle_regions": [],  # Anotar manualmente
                "needs_annotation": True
            },
            "metadata": {
                "source_folder": "sample_OK" if has_subs else "sample_NOT_OK",
                "annotation_status": "pending"
            }
        }
    
    return ground_truth

# Gerar para holdout
holdout_ok = Path("services/make-video/storage/validation/holdout_test_set/with_subs")
holdout_not_ok = Path("services/make-video/storage/validation/holdout_test_set/without_subs")

gt_ok = generate_ground_truth(holdout_ok, has_subs=True)
gt_not_ok = generate_ground_truth(holdout_not_ok, has_subs=False)

combined_gt = {**gt_ok, **gt_not_ok}

output_path = Path("services/make-video/storage/validation/holdout_test_set/ground_truth.json")
with open(output_path, 'w') as f:
    json.dump(combined_gt, f, indent=2)

print(f"‚úÖ Ground truth inicial salvo em: {output_path}")
print(f"   Total de v√≠deos: {len(combined_gt)}")
print(f"   ‚ö†Ô∏è  ATEN√á√ÉO: Revisar manualmente e preencher 'subtitle_regions'")
```

> **‚ö†Ô∏è IMPORTANTE**: Os v√≠deos em `sample_OK/` e `sample_NOT_OK/` existentes s√£o um **√≥timo ponto de partida**, mas precisam de:
> 1. Anota√ß√£o detalhada (bbox, timestamps, posi√ß√£o)
> 2. Estratifica√ß√£o por resolu√ß√£o/complexidade
> 3. Valida√ß√£o por 2 anotadores independentes
> 4. Coleta de v√≠deos adicionais se necess√°rio (meta: 200 holdout + 100 dev)


