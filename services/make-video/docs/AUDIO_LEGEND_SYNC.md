# ğŸ™ï¸ SINCRONIZAÃ‡ÃƒO DE ÃUDIO COM LEGENDAS - DOCUMENTAÃ‡ÃƒO TÃ‰CNICA DE PRODUÃ‡ÃƒO

> **DocumentaÃ§Ã£o 100% do cÃ³digo em produÃ§Ã£o**  
> **VersÃ£o**: 2026-02-20  
> **Status**: âœ… Ativo em produÃ§Ã£o  

---

## ğŸ“‹ ÃNDICE

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Arquitetura do Sistema](#arquitetura-do-sistema)
3. [Pipeline Completo](#pipeline-completo)
4. [Etapa 1: TranscriÃ§Ã£o de Ãudio](#etapa-1-transcriÃ§Ã£o-de-Ã¡udio)
5. [Etapa 2: GeraÃ§Ã£o SRT Inicial](#etapa-2-geraÃ§Ã£o-srt-inicial)
6. [Etapa 3: Voice Activity Detection (VAD)](#etapa-3-voice-activity-detection-vad)
7. [Etapa 4: Speech Gating](#etapa-4-speech-gating)
8. [Etapa 5: ValidaÃ§Ã£o SRT](#etapa-5-validaÃ§Ã£o-srt)
9. [Etapa 6: Burn-in de Legendas](#etapa-6-burn-in-de-legendas)
10. [Fluxogramas](#fluxogramas)
11. [ConfiguraÃ§Ãµes](#configuraÃ§Ãµes)

---

## VISÃƒO GERAL

### O Que Faz?

O sistema garante que **legendas apareÃ§am APENAS quando hÃ¡ fala real no Ã¡udio**, eliminando legendas durante:
- âŒ SilÃªncios prolongados
- âŒ RuÃ­dos de fundo
- âŒ MÃºsica instrumental
- âŒ TransiÃ§Ãµes entre cenas

### Objetivos

âœ… **SincronizaÃ§Ã£o perfeita** entre Ã¡udio e legendas  
âœ… **DetecÃ§Ã£o precisa de fala** usando VAD (Voice Activity Detection)  
âœ… **Legendas legÃ­veis** (duraÃ§Ã£o mÃ­nima de 120ms)  
âœ… **Evitar flicker** (merge de legendas prÃ³ximas)  
âœ… **ValidaÃ§Ã£o rigorosa** (SRT vazio = job FAIL)  

### Tecnologias

| Componente | Tecnologia |
|------------|------------|
| **TranscriÃ§Ã£o** | Whisper API (audio-transcriber service) |
| **VAD Principal** | Silero-VAD v4.0 (PyTorch JIT) |
| **VAD Fallback 1** | WebRTC VAD (algoritmo clÃ¡ssico) |
| **VAD Fallback 2** | RMS (Root Mean Square) |
| **Burn-in** | FFmpeg (subtitle filter) |
| **Formato** | SubRip Text (SRT) |

---

## ARQUITETURA DO SISTEMA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AUDIO-LEGEND SYNCHRONIZATION PIPELINE              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ãudio Original (audio.mp3)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. TRANSCRIPTION            â”‚  â—„â”€â”€â”€ audio-transcriber service (Whisper API)
â”‚    Entrada: audio.mp3       â”‚
â”‚    SaÃ­da: segments[]        â”‚
â”‚    [{start:0.5,end:3.2,     â”‚
â”‚      text:"OlÃ¡"}]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. SRT GENERATION           â”‚  â—„â”€â”€â”€ SubtitleGenerator.generate_word_by_word_srt()
â”‚    Entrada: segments[]      â”‚
â”‚    SaÃ­da: raw_cues[]        â”‚
â”‚    [{start:0.5,end:0.6,     â”‚
â”‚      text:"OlÃ¡"}]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. VAD DETECTION            â”‚  â—„â”€â”€â”€ SpeechGatedSubtitles.detect_speech_segments()
â”‚    Entrada: audio.mp3       â”‚
â”‚    SaÃ­da: speech_segments[] â”‚
â”‚    [{start:0.42,end:3.28,   â”‚
â”‚      confidence:1.0}]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. SPEECH GATING            â”‚  â—„â”€â”€â”€ SpeechGatedSubtitles.gate_subtitles()
â”‚    Entrada: raw_cues[]      â”‚
â”‚            + speech_segmentsâ”‚
â”‚    Processo:                â”‚
â”‚    - CLAMP cues nos segmentsâ”‚
â”‚    - DROP cues fora de fala â”‚
â”‚    - MERGE cues prÃ³ximos    â”‚
â”‚    SaÃ­da: final_cues[]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. VALIDATION               â”‚  â—„â”€â”€â”€ ValidaÃ§Ã£o crÃ­tica (final_cues nÃ£o pode ser vazio)
â”‚    Se final_cues == [] â†’    â”‚
â”‚    RAISE Exception          â”‚
â”‚    Job FAIL                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. SRT FILE WRITE           â”‚  â—„â”€â”€â”€ SubtitleGenerator.generate_word_by_word_srt()
â”‚    Entrada: final_cues[]    â”‚
â”‚    SaÃ­da: subtitles.srt     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. BURN-IN                  â”‚  â—„â”€â”€â”€ VideoBuilder.burn_subtitles() + FFmpeg
â”‚    Entrada: video.mp4       â”‚
â”‚            + subtitles.srt  â”‚
â”‚    SaÃ­da: final_video.mp4   â”‚
â”‚    âœ… Legendas gravadas     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## PIPELINE COMPLETO

### CÃ³digo Completo da OrquestraÃ§Ã£o

**Arquivo**: `app/infrastructure/celery_tasks.py` (linhas ~700-920)

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ETAPA 6: GERAR LEGENDAS (RETRY INFINITO ATÃ‰ CONSEGUIR)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info(f"ğŸ“ [6/7] Generating subtitles...")
await update_job_status(job_id, JobStatus.GENERATING_SUBTITLES, progress=80.0)

# Inicializar variÃ¡veis
segments = []           # Segmentos da transcriÃ§Ã£o Whisper
retry_attempt = 0       # Contador de tentativas
max_backoff = 300       # 5 minutos mÃ¡ximo entre tentativas

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ETAPA 6.1: TRANSCRIÃ‡ÃƒO COM RETRY INFINITO
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Objetivo: Garantir que SEMPRE temos transcriÃ§Ã£o, mesmo se API falhar
# Comportamento: Retry exponencial atÃ© conseguir
while not segments:
    retry_attempt += 1
    
    try:
        if retry_attempt > 1:
            logger.info(f"ğŸ”„ Subtitle generation retry #{retry_attempt}")
            await update_job_status(
                job_id, 
                JobStatus.GENERATING_SUBTITLES, 
                progress=80.0,
                stage_updates={
                    "generating_subtitles": {
                        "status": "retrying",
                        "metadata": {
                            "retry_attempt": retry_attempt,
                            "reason": "Previous attempt failed or timed out"
                        }
                    }
                }
            )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # CHAMADA Ã€ API: audio-transcriber service (Whisper)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Entrada: audio_path (ex: /tmp/make-video-temp/<job_id>/audio.mp3)
        #          subtitle_language (ex: "pt", "en", "es")
        # SaÃ­da: segments[] = [
        #   {start: 0.5, end: 3.2, text: "OlÃ¡, como vai?"},
        #   {start: 3.5, end: 6.1, text: "Tudo bem?"}
        # ]
        segments = await api_client.transcribe_audio(
            str(audio_path), 
            job.subtitle_language
        )
        
        logger.info(
            f"âœ… Subtitles generated: {len(segments)} segments "
            f"(attempt #{retry_attempt})"
        )
        
    except MicroserviceException as e:
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # TRATAMENTO DE ERRO: Backoff exponencial
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # FÃ³rmula: backoff_seconds = min(5 * 2^(retry_attempt - 1), 300)
        # SequÃªncia: 5s â†’ 10s â†’ 20s â†’ 40s â†’ 80s â†’ 160s â†’ 300s (mÃ¡x)
        backoff_seconds = min(5 * (2 ** (retry_attempt - 1)), max_backoff)
        
        logger.warning(
            f"âš ï¸ Subtitle generation failed (attempt #{retry_attempt}): {e}",
            exc_info=False
        )
        logger.info(f"ğŸ”„ Retrying in {backoff_seconds}s...")
        
        # Atualizar status do job com informaÃ§Ãµes de retry
        await update_job_status(
            job_id,
            JobStatus.GENERATING_SUBTITLES,
            progress=80.0,
            stage_updates={
                "generating_subtitles": {
                    "status": "waiting_retry",
                    "metadata": {
                        "retry_attempt": retry_attempt,
                        "backoff_seconds": backoff_seconds,
                        "error": str(e)
                    }
                }
            }
        )
        
        # Aguardar backoff
        await asyncio.sleep(backoff_seconds)
        
        # Loop continua (while not segments)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ETAPA 6.2: CONVERSÃƒO SEGMENTS â†’ RAW CUES (PALAVRA POR PALAVRA)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Objetivo: Transformar segmentos longos em palavras individuais
# Comportamento: Cada palavra recebe timestamp proporcional
from app.services.subtitle_generator import SubtitleGenerator
subtitle_gen = SubtitleGenerator()

raw_cues = []  # Lista de cues palavra por palavra

for segment in segments:
    # Extrair informaÃ§Ãµes do segmento
    start_time = segment.get("start", 0.0)    # Ex: 0.5
    end_time = segment.get("end", 0.0)        # Ex: 3.2
    text = segment.get("text", "").strip()    # Ex: "OlÃ¡, como vai?"
    
    if not text:
        continue  # Pular segmentos vazios
    
    # Dividir em palavras (mantÃ©m pontuaÃ§Ã£o)
    import re
    words = re.findall(r'\S+', text)  # Ex: ["OlÃ¡,", "como", "vai?"]
    
    if not words:
        continue
    
    # Calcular tempo por palavra
    # DuraÃ§Ã£o do segmento: end_time - start_time = 3.2 - 0.5 = 2.7s
    # Palavras: 3 â†’ tempo_por_palavra = 2.7 / 3 = 0.9s
    segment_duration = end_time - start_time
    time_per_word = segment_duration / len(words)
    
    # Atribuir timestamp para cada palavra
    for i, word in enumerate(words):
        word_start = start_time + (i * time_per_word)
        word_end = word_start + time_per_word
        
        raw_cues.append({
            'start': word_start,   # Ex: 0.5, 1.4, 2.3
            'end': word_end,       # Ex: 1.4, 2.3, 3.2
            'text': word           # Ex: "OlÃ¡,", "como", "vai?"
        })

logger.info(f"ğŸ“ Raw cues generated: {len(raw_cues)} words from {len(segments)} segments")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ETAPA 6.3: SPEECH GATING COM VAD
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Objetivo: Garantir que legendas sÃ³ aparecem quando hÃ¡ FALA
# Processo:
#   1. VAD detecta segmentos de fala no Ã¡udio
#   2. Clamp cues para dentro dos segmentos
#   3. Drop cues fora de fala
#   4. Merge cues prÃ³ximos (gap < 120ms)

try:
    from app.services.subtitle_postprocessor import process_subtitles_with_vad
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CHAMADA: VAD + Gating
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Entrada:
    #   - audio_path: caminho do Ã¡udio final
    #   - raw_cues: lista de cues palavra por palavra
    # SaÃ­da:
    #   - gated_cues: cues filtrados (apenas durante fala)
    #   - vad_ok: True se silero-vad foi usado, False se fallback
    gated_cues, vad_ok = process_subtitles_with_vad(
        str(audio_path),  # Ex: /tmp/make-video-temp/<job_id>/audio.mp3
        raw_cues          # Ex: [{start:0.5,end:1.4,text:"OlÃ¡,"}]
    )
    
    # Log do resultado
    if vad_ok:
        logger.info(
            f"âœ… Speech gating OK: {len(gated_cues)}/{len(raw_cues)} cues "
            f"(silero-vad)"
        )
    else:
        logger.warning(
            f"âš ï¸ Speech gating fallback: {len(gated_cues)}/{len(raw_cues)} cues "
            f"(webrtcvad/RMS)"
        )
    
    # Usar cues com gating
    final_cues = gated_cues
    
except Exception as e:
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # FALLBACK: Se VAD falhar, usar cues originais
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.error(f"âš ï¸ Speech gating failed: {e}, usando cues originais")
    final_cues = raw_cues
    vad_ok = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ETAPA 6.4: VALIDAÃ‡ÃƒO CRÃTICA - FINAL_CUES NÃƒO PODE SER VAZIO
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# IMPORTANTE: Esta validaÃ§Ã£o previne vÃ­deos sem legendas
# Se final_cues == [], significa que ALGO deu errado:
#   - VAD filtrou TODAS as legendas (threshold muito alto?)
#   - Ãudio nÃ£o tem fala (silÃªncio total?)
#   - Bug no processamento
# Comportamento: RAISE Exception â†’ Job FAIL â†’ UsuÃ¡rio notificado

logger.info(f"DEBUG: final_cues count = {len(final_cues)}")

if not final_cues:
    logger.error("âŒ CRITICAL: final_cues is EMPTY! Cannot generate SRT!")
    raise SubtitleGenerationException(
        reason="No valid subtitle cues after speech gating (VAD processing)",
        subtitle_path=str(subtitle_path),
        details={
            "raw_cues_count": len(raw_cues),
            "final_cues_count": 0,
            "vad_ok": vad_ok,
            "problem": "All subtitle cues were filtered out during VAD processing",
            "recommendation": "Check VAD threshold settings or audio quality"
        }
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ETAPA 6.5: AGRUPAR CUES EM SEGMENTS PARA SRT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Objetivo: Agrupar palavras em segmentos (cada X palavras = 1 segment)
# Exemplo: ["OlÃ¡,", "como", "vai?"] â†’ 1 segment "OlÃ¡, como vai?"

segment_size = 10  # Agrupar 10 palavras por segment
segments_for_srt = []

for i in range(0, len(final_cues), segment_size):
    chunk = final_cues[i:i+segment_size]
    
    if chunk:
        segments_for_srt.append({
            'start': chunk[0]['start'],           # InÃ­cio do primeiro cue
            'end': chunk[-1]['end'],              # Fim do Ãºltimo cue
            'text': ' '.join(c['text'] for c in chunk)  # Juntar textos
        })

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ETAPA 6.6: GERAR ARQUIVO SRT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
subtitle_path = Path('/tmp/make-video-temp') / job_id / "subtitles.srt"
words_per_caption = int(settings.get('words_per_caption', 2))  # Ex: 2 palavras/legenda

subtitle_gen.generate_word_by_word_srt(
    segments_for_srt,         # Lista de segments agrupados
    str(subtitle_path),       # Caminho do arquivo SRT
    words_per_caption=words_per_caption  # Palavras por legenda
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ETAPA 6.7: VALIDAÃ‡ÃƒO DO ARQUIVO SRT GERADO
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Verificar se arquivo foi criado e nÃ£o estÃ¡ vazio

if subtitle_path.exists():
    srt_size = subtitle_path.stat().st_size
    logger.info(f"DEBUG: SRT file created, size = {srt_size} bytes")
    
    if srt_size == 0:
        logger.error("âŒ CRITICAL: SRT file is EMPTY (0 bytes)!")
        # Esta situaÃ§Ã£o Ã© tratada posteriormente no burn_subtitles()
else:
    logger.error(f"âŒ CRITICAL: SRT file NOT created at {subtitle_path}!")

# Log final
num_captions_expected = len(final_cues) // words_per_caption
logger.info(
    f"âœ… Speech-gated subtitles: {len(final_cues)} words â†’ "
    f"{len(segments_for_srt)} segments â†’ ~{num_captions_expected} captions, "
    f"{words_per_caption} words/caption, vad_ok={vad_ok}"
)

# Salvar checkpoint (Sprint-01)
await _save_checkpoint(job_id, "generating_subtitles_completed")
```

---

## ETAPA 1: TRANSCRIÃ‡ÃƒO DE ÃUDIO

### Responsabilidade

Converter Ã¡udio em texto com timestamps precisos usando Whisper API.

### CÃ³digo: Chamada Ã  API

**LocalizaÃ§Ã£o**: `celery_tasks.py` (linha ~730)

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TRANSCRIÃ‡ÃƒO COM WHISPER API (audio-transcriber service)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Entrada:
#   - audio_path: /tmp/make-video-temp/<job_id>/audio.mp3
#   - subtitle_language: "pt", "en", "es", etc.
segments = await api_client.transcribe_audio(
    str(audio_path), 
    job.subtitle_language
)

# SaÃ­da: Lista de segmentos
# Exemplo:
# [
#   {
#     "start": 0.5,              # InÃ­cio do segmento (segundos)
#     "end": 3.2,                # Fim do segmento (segundos)
#     "text": "OlÃ¡, como vai?"  # Texto transcrito
#   },
#   {
#     "start": 3.5,
#     "end": 6.1,
#     "text": "Tudo bem?"
#   },
#   {
#     "start": 7.0,
#     "end": 10.5,
#     "text": "Vamos comeÃ§ar!"
#   }
# ]
```

### Formato de SaÃ­da

```json
[
  {
    "start": 0.5,
    "end": 3.2,
    "text": "OlÃ¡, como vai?"
  },
  {
    "start": 3.5,
    "end": 6.1,
    "text": "Tudo bem?"
  }
]
```

### CaracterÃ­sticas

- â±ï¸ **Timestamps automÃ¡ticos**: Whisper detecta inÃ­cio/fim de cada fala
- ğŸ“ **PontuaÃ§Ã£o incluÃ­da**: "OlÃ¡, como vai?" (nÃ£o "ola como vai")
- ğŸŒ **Multi-idioma**: Suporta 50+ idiomas
- ğŸ”„ **Retry automÃ¡tico**: Se falhar, retry com backoff exponencial

---

## ETAPA 2: GERAÃ‡ÃƒO SRT INICIAL

### Responsabilidade

Converter segmentos longos em palavras individuais com timestamps proporcionais.

### CÃ³digo: DivisÃ£o em Palavras

**LocalizaÃ§Ã£o**: `celery_tasks.py` (linha ~800)

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DIVISÃƒO DE SEGMENTS EM PALAVRAS INDIVIDUAIS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import re
raw_cues = []  # Lista de cues palavra por palavra

for segment in segments:
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PASSO 1: Extrair dados do segmento
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    start_time = segment.get("start", 0.0)    # Ex: 0.5
    end_time = segment.get("end", 0.0)        # Ex: 3.2
    text = segment.get("text", "").strip()    # Ex: "OlÃ¡, como vai?"
    
    if not text:
        continue  # Pular segmentos vazios
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PASSO 2: Dividir texto em palavras
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Regex \S+ = sequÃªncia de caracteres nÃ£o-whitespace
    # MantÃ©m pontuaÃ§Ã£o anexada: "OlÃ¡," "como" "vai?"
    words = re.findall(r'\S+', text)
    # Resultado: ["OlÃ¡,", "como", "vai?"]
    
    if not words:
        continue
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PASSO 3: Calcular tempo por palavra
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    segment_duration = end_time - start_time  # 3.2 - 0.5 = 2.7s
    time_per_word = segment_duration / len(words)  # 2.7 / 3 = 0.9s
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PASSO 4: Atribuir timestamps para cada palavra
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for i, word in enumerate(words):
        # Timestamp de inÃ­cio da palavra
        word_start = start_time + (i * time_per_word)
        # Palavra 0: 0.5 + (0 * 0.9) = 0.5
        # Palavra 1: 0.5 + (1 * 0.9) = 1.4
        # Palavra 2: 0.5 + (2 * 0.9) = 2.3
        
        # Timestamp de fim da palavra
        word_end = word_start + time_per_word
        # Palavra 0: 0.5 + 0.9 = 1.4
        # Palavra 1: 1.4 + 0.9 = 2.3
        # Palavra 2: 2.3 + 0.9 = 3.2
        
        raw_cues.append({
            'start': word_start,
            'end': word_end,
            'text': word
        })

# Resultado:
# raw_cues = [
#   {start: 0.5, end: 1.4, text: "OlÃ¡,"},
#   {start: 1.4, end: 2.3, text: "como"},
#   {start: 2.3, end: 3.2, text: "vai?"}
# ]

logger.info(
    f"ğŸ“ Raw cues generated: {len(raw_cues)} words from {len(segments)} segments"
)
```

### Exemplo Visual

```
Segment: "OlÃ¡, como vai?"
Duration: 2.7s (0.5 â†’ 3.2)
Words: 3 â†’ 0.9s por palavra

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OlÃ¡,     â”‚  como     â”‚  vai?     â”‚                 â”‚
â”‚  0.5â†’1.4  â”‚  1.4â†’2.3  â”‚  2.3â†’3.2  â”‚                 â”‚
â”‚  (0.9s)   â”‚  (0.9s)   â”‚  (0.9s)   â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ETAPA 3: VOICE ACTIVITY DETECTION (VAD)

### Responsabilidade

Detectar **exatamente quando hÃ¡ fala** no Ã¡udio, ignorando silÃªncios e ruÃ­dos.

### Modelo Principal: Silero-VAD

**Tecnologia**: PyTorch JIT (Just-In-Time compiled)  
**Modelo**: Silero-VAD v4.0  
**Vantagens**: Alta precisÃ£o (95%+), rÃ¡pido, offline  

### CÃ³digo: DetecÃ§Ã£o de Fala

**Arquivo**: `app/services/subtitle_postprocessor.py`

```python
def detect_speech_segments(
    self,
    audio_path: str
) -> Tuple[List[SpeechSegment], bool]:
    """
    Detecta segmentos de fala usando VAD.
    
    Returns:
        (segments: List[SpeechSegment], vad_ok: bool)
        vad_ok=False indica fallback usado (precisÃ£o reduzida)
    """
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # TENTATIVA 1: Silero-VAD (preferÃ­vel)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if self.model is not None:
        segments = self._detect_with_silero(audio_path)
        logger.info(
            f"ğŸ™ï¸ Detectados {len(segments)} segmentos de fala (silero)"
        )
        return segments, True
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # FALLBACK 1: WebRTC VAD
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif self.webrtc_vad is not None:
        logger.info("ğŸ”„ Usando webrtcvad (fallback)")
        segments = self._detect_with_webrtc(audio_path)
        return segments, False
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # FALLBACK 2: RMS simples
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    else:
        logger.warning("âš ï¸ VAD total fallback: usando RMS simples")
        segments = self._detect_with_rms(audio_path)
        return segments, False

def _detect_with_silero(self, audio_path: str) -> List[SpeechSegment]:
    """DetecÃ§Ã£o com silero-vad (alta precisÃ£o)"""
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PASSO 1: Carregar Ã¡udio em 16kHz (requisito do modelo)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    wav = load_audio_torch(audio_path, sampling_rate=16000)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PASSO 2: Detectar timestamps de fala
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ParÃ¢metros:
    #   - threshold: 0.5 (confianÃ§a mÃ­nima)
    #   - min_speech_duration_ms: 250ms (mÃ­nimo de fala contÃ­nua)
    #   - min_silence_duration_ms: 100ms (mÃ­nimo de silÃªncio entre falas)
    speech_timestamps = get_speech_timestamps(
        wav,
        self.model,
        threshold=self.vad_threshold,      # Ex: 0.5
        sampling_rate=16000,
        min_speech_duration_ms=250,        # MÃ­nimo 250ms de fala
        min_silence_duration_ms=100        # MÃ­nimo 100ms de silÃªncio
    )
    
    # Resultado: Lista de dicts [{start: 6720, end: 52480}, ...]
    # Valores em samples (16kHz)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PASSO 3: Converter para SpeechSegment objects
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    segments = []
    for ts in speech_timestamps:
        # Converter samples â†’ segundos
        start_sec = ts['start'] / 16000.0  # Ex: 6720 / 16000 = 0.42s
        end_sec = ts['end'] / 16000.0      # Ex: 52480 / 16000 = 3.28s
        
        segments.append(SpeechSegment(
            start=start_sec,
            end=end_sec,
            confidence=1.0  # Silero-VAD = alta confianÃ§a
        ))
    
    return segments
```

### ComparaÃ§Ã£o de VADs

| MÃ©todo | PrecisÃ£o | Velocidade | Quando Usar |
|--------|----------|------------|-------------|
| **Silero-VAD** | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ (95%+) | ğŸš€ RÃ¡pido (1-2s/min) | âœ… ProduÃ§Ã£o (default) |
| **WebRTC VAD** | ğŸŒŸğŸŒŸğŸŒŸ (80%+) | âš¡ Muito rÃ¡pido (<1s/min) | ğŸ”„ Fallback 1 |
| **RMS** | ğŸŒŸ (60%+) | ğŸš€ InstantÃ¢neo | âš ï¸ Fallback 2 (Ãºltimo recurso) |

---

## ETAPA 4: SPEECH GATING

### Responsabilidade

Garantir que **TODAS as legendas estÃ£o dentro de segmentos de fala**, aplicando:
1. **CLAMP**: Ajustar timestamps para dentro dos speech segments
2. **DROP**: Remover legendas fora de fala
3. **MERGE**: Juntar legendas prÃ³ximas (gap < 120ms)

### CÃ³digo: Algoritmo de Gating

**LocalizaÃ§Ã£o**: `subtitle_postprocessor.py` (classe `SpeechGatedSubtitles`)

```python
def gate_subtitles(
    self,
    cues: List[SubtitleCue],
    speech_segments: List[SpeechSegment],
    audio_duration: float
) -> List[SubtitleCue]:
    """
    Aplica gating: remove/clamp cues para dentro dos speech segments.
    
    Args:
        cues: Lista de cues originais
        speech_segments: Segmentos de fala detectados por VAD
        audio_duration: DuraÃ§Ã£o total do Ã¡udio (para clamp final)
    
    Regras:
    1. Se cue NÃƒO intersecta nenhum segment â†’ DROP
    2. Se intersecta â†’ CLAMP dentro do segment (com padding)
    3. Se duraÃ§Ã£o < min_duration â†’ ajustar
    4. Se gap entre cues < merge_gap â†’ MERGE
    """
    gated_cues = []
    dropped_count = 0
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ETAPA 1: CLAMP/DROP INDIVIDUAL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    for cue in cues:
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # PASSO 1: Encontrar speech segment que intersecta o cue
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        intersecting_segment = self._find_intersecting_segment(
            cue, speech_segments
        )
        
        if intersecting_segment is None:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # DROP: Cue fora de fala (nÃ£o intersecta nenhum segment)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            logger.debug(f"âš ï¸ DROP cue '{cue.text}' (fora de fala)")
            dropped_count += 1
            continue  # NÃ£o adicionar em gated_cues
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # PASSO 2: CLAMP start para dentro do segment (com pre-pad)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Regra: ComeÃ§ar no mÃ¡ximo 60ms ANTES do segmento de fala
        # Exemplo:
        #   segment.start = 0.42s
        #   pre_pad = 0.06s
        #   cue.start = 0.50s
        #   â†’ clamped_start = max(0.42 - 0.06, 0.50) = max(0.36, 0.50) = 0.50
        clamped_start = max(
            intersecting_segment.start - self.pre_pad,  # 0.36s
            cue.start                                   # 0.50s
        )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # PASSO 3: CLAMP end para dentro do segment (com post-pad)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Regra: Terminar no mÃ¡ximo 120ms APÃ“S o segmento de fala
        # Exemplo:
        #   segment.end = 3.28s
        #   post_pad = 0.12s
        #   audio_duration = 60.0s
        #   â†’ clamped_end = min(60.0, 3.28 + 0.12) = min(60.0, 3.40) = 3.40
        clamped_end = min(
            audio_duration,                             # NÃ£o ultrapassar Ã¡udio
            intersecting_segment.end + self.post_pad    # 3.40s
        )
        # IMPORTANTE: NÃ£o limitar pelo cue.end original (permite estender)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # PASSO 4: Garantir duraÃ§Ã£o mÃ­nima (120ms)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Regra: Legenda precisa ficar na tela por pelo menos 120ms
        # para ser legÃ­vel pelo olho humano
        if clamped_end - clamped_start < self.min_duration:
            clamped_end = min(
                audio_duration, 
                clamped_start + self.min_duration  # Estender atÃ© 120ms
            )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # PASSO 5: Criar cue ajustado
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        gated_cues.append(SubtitleCue(
            index=cue.index,
            start=clamped_start,
            end=clamped_end,
            text=cue.text
        ))
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ETAPA 2: MERGE DE CUES PRÃ“XIMOS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Objetivo: Evitar "flicker" de legendas (aparecer/desaparecer rÃ¡pido)
    # Regra: Se gap < 120ms, juntar legendas
    merged_cues = self._merge_close_cues(gated_cues)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # LOG FINAL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    merged_count = len(gated_cues) - len(merged_cues)
    logger.info(
        f"âœ… Speech gating: {len(merged_cues)}/{len(cues)} cues finais, "
        f"{dropped_count} dropped, {merged_count} merged"
    )
    
    return merged_cues

def _merge_close_cues(self, cues: List[SubtitleCue]) -> List[SubtitleCue]:
    """Merge cues se gap < merge_gap (120ms)"""
    if not cues:
        return []
    
    merged = [cues[0]]  # Iniciar com primeiro cue
    
    for cue in cues[1:]:
        prev = merged[-1]
        gap = cue.start - prev.end  # Calcular gap (silÃªncio entre cues)
        
        if gap < self.merge_gap:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # MERGE: Juntar com anterior
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Exemplo:
            #   prev: [0.5 â†’ 1.4] "OlÃ¡,"
            #   cue:  [1.5 â†’ 2.3] "como"
            #   gap = 1.5 - 1.4 = 0.1s (100ms) < 120ms
            #   merged: [0.5 â†’ 2.3] "OlÃ¡, como"
            merged[-1] = SubtitleCue(
                index=prev.index,
                start=prev.start,
                end=cue.end,
                text=f"{prev.text} {cue.text}"
            )
        else:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # KEEP SEPARATE: Gap grande, manter separado
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            merged.append(cue)
    
    return merged
```

### Exemplo Visual de Gating

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ANTES DO GATING                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Raw Cues (palavras):
[0.5â”€â”€1.4] "OlÃ¡,"    [1.5â”€â”€2.3] "como"    [8.0â”€â”€9.5] "!" (silÃªncio)
    â”‚                    â”‚                     â”‚
    â””â”€â”€â”€â”€â”€Cue 1â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€Cue 3â”€â”€â”€â”€â”€
                â””â”€â”€â”€â”€â”€Cue 2â”€â”€â”€â”€â”€

Speech Segments (VAD detectou):
[0.42â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€3.28] Segment 1
                          [3.45â”€â”€6.18] Segment 2

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   APÃ“S GATING                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Cue 1: [0.5â”€â”€1.4] "OlÃ¡," â†’ CLAMP â†’ [0.36â”€â”€1.52]
  - start: max(0.42 - 0.06, 0.5) = 0.36 (pre-pad aplicado)
  - end: min(60.0, 3.28 + 0.12) = 3.40 (post-pad aplicado)

Cue 2: [1.5â”€â”€2.3] "como" â†’ CLAMP â†’ [1.39â”€â”€3.40]
  - Intersecta Segment 1
  - Gap com Cue 1 = 1.39 - 1.52 = -0.13s (negativo!)
  - â†’ MERGE com Cue 1

Cue 3: [8.0â”€â”€9.5] "!" â†’ DROP âŒ
  - NÃƒO intersecta nenhum segment
  - EstÃ¡ durante silÃªncio

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   RESULTADO FINAL                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Final Cues (apÃ³s gating + merge):
[0.36â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€3.40] "OlÃ¡, como"  â—„â”€â”€â”€ Merged (gap < 120ms)

Total: 1 cue final (de 3 originais)
- 2 cues merged
- 1 cue dropped
```

---

## ETAPA 5: VALIDAÃ‡ÃƒO SRT

### Responsabilidade

Garantir que **SRT nÃ£o estÃ¡ vazio** antes de burn-in.

### ValidaÃ§Ãµes Implementadas

#### 1. ValidaÃ§Ã£o ApÃ³s Gating (celery_tasks.py)

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VALIDAÃ‡ÃƒO CRÃTICA: FINAL_CUES NÃƒO PODE SER VAZIO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Arquivo: celery_tasks.py (linha ~872)

logger.info(f"DEBUG: final_cues count = {len(final_cues)}")

if not final_cues:
    logger.error("âŒ CRITICAL: final_cues is EMPTY! Cannot generate SRT!")
    raise SubtitleGenerationException(
        reason="No valid subtitle cues after speech gating (VAD processing)",
        subtitle_path=str(subtitle_path),
        details={
            "raw_cues_count": len(raw_cues),
            "final_cues_count": 0,
            "vad_ok": vad_ok,
            "problem": "All subtitle cues were filtered out during VAD processing",
            "recommendation": "Check VAD threshold settings or audio quality"
        }
    )

# Comportamento:
#   - Se final_cues == [] â†’ Exception raised
#   - Job status â†’ FAILED
#   - UsuÃ¡rio notificado do erro
#   - VÃ­deo NÃƒO Ã© gerado (fail-safe)
```

#### 2. ValidaÃ§Ã£o Antes de Burn-in (video_builder.py)

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VALIDAÃ‡ÃƒO ANTES DE BURN-IN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Arquivo: video_builder.py (linha ~590)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PASSO 1: Verificar se arquivo SRT existe
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not subtitle_path_obj.exists():
    raise SubtitleGenerationException(
        reason=f"Subtitle file not found: {subtitle_path_obj}",
        subtitle_path=str(subtitle_path_obj),
        details={"expected_path": str(subtitle_path_obj)}
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PASSO 2: Verificar se arquivo SRT NÃƒO estÃ¡ vazio (0 bytes)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
subtitle_size = subtitle_path_obj.stat().st_size

if subtitle_size == 0:
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # RAISE EXCEPTION: SRT vazio = vÃ­deo sem legendas
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    raise SubtitleGenerationException(
        reason="Subtitle file is empty - subtitles are mandatory for this job",
        subtitle_path=str(subtitle_path_obj),
        details={
            "subtitle_size": 0,
            "expected_size": "> 0 bytes",
            "problem": "Cannot generate video without subtitles - empty SRT file",
            "recommendation": "Check audio transcription and VAD processing steps"
        }
    )

# Comportamento:
#   - Se SRT vazio (0 bytes) â†’ Exception raised
#   - Job status â†’ FAILED
#   - VÃ­deo NÃƒO Ã© copiado sem legendas
#   - Sistema GARANTE que legendas sÃ£o obrigatÃ³rias
```

---

## ETAPA 6: BURN-IN DE LEGENDAS

### Responsabilidade

Gravar legendas permanentemente no vÃ­deo usando FFmpeg.

### CÃ³digo: Burn-in com FFmpeg

**Arquivo**: `app/services/video_builder.py` (mÃ©todo `burn_subtitles()`)

```python
async def burn_subtitles(
    self,
    video_path: str,
    subtitle_path: str,
    output_path: str,
    style: str = "dynamic"
) -> str:
    """
    Grava legendas no vÃ­deo (burn-in permanente).
    """
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASSO 1: VALIDAÃ‡Ã•ES DE ENTRADA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    video_path_obj = Path(video_path).resolve()
    subtitle_path_obj = Path(subtitle_path).resolve()
    output_path_obj = Path(output_path).resolve()
    output_path_obj.parent.mkdir(parents=True, exist_ok=True)
    
    # ValidaÃ§Ã£o 1: Arquivo SRT existe?
    if not subtitle_path_obj.exists():
        raise SubtitleGenerationException(...)
    
    # ValidaÃ§Ã£o 2: Arquivo SRT nÃ£o estÃ¡ vazio?
    subtitle_size = subtitle_path_obj.stat().st_size
    if subtitle_size == 0:
        raise SubtitleGenerationException(...)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASSO 2: DEFINIR ESTILOS DE LEGENDA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Alinhamento: 10 = Topo Centro
    # MarginV: 280 = 280 pixels do topo (empurra para centro da tela)
    # FontSize: 18-22 (pequeno para evitar sair da tela)
    # Outline: Borda preta para legibilidade
    styles = {
        "static": (
            "FontSize=20,"
            "PrimaryColour=&HFFFFFF&,"      # Branco
            "OutlineColour=&H000000&,"      # Borda preta
            "Outline=2,"                     # Borda 2px
            "Bold=1,"                        # Negrito
            "Alignment=10,"                  # Topo centro
            "MarginV=280"                    # 280px do topo
        ),
        "dynamic": (
            "FontSize=22,"
            "PrimaryColour=&H00FFFF&,"      # Amarelo
            "OutlineColour=&H000000&,"      # Borda preta
            "Outline=2,"
            "Bold=1,"
            "Alignment=10,"
            "MarginV=280"
        ),
        "minimal": (
            "FontSize=18,"
            "PrimaryColour=&HFFFFFF&,"      # Branco
            "OutlineColour=&H000000&,"      # Borda preta
            "Outline=1,"                     # Borda fina
            "Alignment=10,"
            "MarginV=280"
        )
    }
    
    subtitle_style = styles.get(style, styles["dynamic"])
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASSO 3: ESCAPAR CAMINHO DO SRT PARA FFMPEG
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    subtitle_path_escaped = str(subtitle_path_obj).replace("\\", "\\\\").replace(":", "\\:").replace("'", "\\'")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASSO 4: CONSTRUIR COMANDO FFMPEG
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    cmd = [
        self.ffmpeg_path,
        "-i", str(video_path_obj),
        "-vf", f"subtitles={subtitle_path_escaped}:force_style='{subtitle_style}'",
        "-c:a", "copy",         # NÃƒO re-encode Ã¡udio
        "-map", "0:v:0",        # Mapear APENAS 1Âº stream de vÃ­deo
        "-map", "0:a:0",        # Mapear APENAS 1Âº stream de Ã¡udio
        "-y",                   # Sobrescrever output
        str(output_path_obj)
    ]
    
    logger.info(f"â–¶ï¸ Running FFmpeg subtitle burn-in...")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PASSO 5: EXECUTAR FFMPEG COM TIMEOUT
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    returncode, stdout, stderr = await run_subprocess_with_timeout(
        cmd=cmd,
        timeout=900,              # 900s = 15 minutos
        check=False,
        capture_output=True
    )
    
    if returncode != 0:
        raise VideoEncodingException(...)
    
    if not output_path_obj.exists():
        raise VideoEncodingException(...)
    
    output_size = output_path_obj.stat().st_size
    if output_size == 0:
        raise VideoEncodingException(...)
    
    logger.info(
        f"âœ… Subtitles burned: {output_path_obj} "
        f"({output_size / 1024 / 1024:.2f} MB)"
    )
    return str(output_path_obj)
```

### Exemplo de Comando FFmpeg

```bash
ffmpeg \
  -i /tmp/make-video-temp/job123/video.mp4 \
  -vf "subtitles=/tmp/make-video-temp/job123/subtitles.srt:force_style='FontSize=22,PrimaryColour=&H00FFFF&,OutlineColour=&H000000&,Outline=2,Bold=1,Alignment=10,MarginV=280'" \
  -c:a copy \
  -map 0:v:0 \
  -map 0:a:0 \
  -y \
  /tmp/make-video-temp/job123/final_video.mp4
```

---

## FLUXOGRAMAS

### Fluxo Completo de Processamento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INÃCIO: process_video_job()                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ 1. TRANSCRIBE  â”‚  â—„â”€â”€â”€ audio-transcriber (Whisper)
                    â”‚     AUDIO      â”‚       Retry infinito com backoff
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  segments[] = [                 â”‚
           â”‚    {start:0.5,end:3.2,          â”‚
           â”‚     text:"OlÃ¡, como vai?"}      â”‚
           â”‚  ]                              â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  2. CONVERT TO RAW CUES         â”‚
           â”‚  (palavra por palavra)          â”‚
           â”‚  raw_cues[] = [                 â”‚
           â”‚    {start:0.5,end:1.4,          â”‚
           â”‚     text:"OlÃ¡,"}                â”‚
           â”‚  ]                              â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  3. VAD DETECTION               â”‚  â—„â”€â”€â”€ Silero-VAD / WebRTC / RMS
           â”‚  speech_segments[] = [          â”‚
           â”‚    {start:0.42,end:3.28,        â”‚
           â”‚     confidence:1.0}             â”‚
           â”‚  ]                              â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  4. SPEECH GATING               â”‚
           â”‚  - CLAMP cues â†’ speech          â”‚
           â”‚  - DROP cues fora de fala       â”‚
           â”‚  - MERGE cues prÃ³ximos          â”‚
           â”‚  final_cues[] = [               â”‚
           â”‚    {start:0.36,end:3.40,        â”‚
           â”‚     text:"OlÃ¡, como vai?"}      â”‚
           â”‚  ]                              â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  VALIDAÃ‡ÃƒO       â”‚
           â”‚  final_cues == []?
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
                  â”‚       â”‚
             SIM  â”‚       â”‚ NÃƒO
                  â”‚       â”‚
                  â–¼       â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  RAISE   â”‚  â”‚  5. GENERATE SRT FILE   â”‚
           â”‚ Exceptionâ”‚  â”‚  subtitles.srt          â”‚
           â”‚ Job FAIL â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                                  â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  VALIDAÃ‡ÃƒO     â”‚
                         â”‚  SRT vazio?    â”‚
                         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
                              â”‚       â”‚
                         SIM  â”‚       â”‚ NÃƒO
                              â”‚       â”‚
                              â–¼       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  RAISE   â”‚  â”‚  6. BURN-IN   â”‚
                       â”‚ Exceptionâ”‚  â”‚  (FFmpeg)     â”‚
                       â”‚ Job FAIL â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
                                             â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ Job COMPLETED  â”‚
                                    â”‚ âœ… SUCCESS      â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## CONFIGURAÃ‡Ã•ES

### VariÃ¡veis de Ambiente

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VAD CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Threshold VAD (0.0-1.0)
# 0.3 = Muito sensÃ­vel (detecta atÃ© ruÃ­do como fala)
# 0.5 = Balanceado âœ… (recomendado)
# 0.7 = Conservador (pode perder fala suave)
VAD_THRESHOLD=0.5

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SUBTITLE TIMING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Pre-pad: Legenda pode comeÃ§ar X ms ANTES da fala
# Valor: 60ms (0.06s)
SUBTITLE_PRE_PAD=0.06

# Post-pad: Legenda fica X ms DEPOIS da fala
# Valor: 120ms (0.12s) - tempo para leitura
SUBTITLE_POST_PAD=0.12

# DuraÃ§Ã£o mÃ­nima de legenda
# Valor: 120ms (0.12s) - mÃ­nimo para olho humano ler
SUBTITLE_MIN_DURATION=0.12

# Gap mÃ­nimo para merge
# Se gap < X ms â†’ juntar legendas (evitar flicker)
# Valor: 120ms (0.12s)
SUBTITLE_MERGE_GAP=0.12

# Palavras por legenda (estilo TikTok/Shorts)
# Valor: 2 palavras (recomendado)
WORDS_PER_CAPTION=2
```

### Tuning de ParÃ¢metros

#### VAD Threshold

| Threshold | Sensibilidade | Falsos Positivos | Falsos Negativos | Uso |
|-----------|---------------|------------------|------------------|-----|
| **0.3** | ğŸ”´ Muito Alta | Alto (detecta ruÃ­do) | Baixo | Ãudios muito limpos |
| **0.5** | ğŸŸ¢ Balanceada | Baixo | Baixo | âœ… **Recomendado** |
| **0.7** | ğŸ”µ Conservadora | Muito Baixo | MÃ©dio (perde fala suave) | RuÃ­do pesado |

---

## PERFORMANCE

### Benchmarks

**Hardware**: 4 vCPU, 8GB RAM, SSD

| OperaÃ§Ã£o | Tempo (60s de Ã¡udio) | Throughput |
|----------|----------------------|------------|
| Whisper transcription | 8-15s | 4-7 Ã¡udios/min |
| Silero-VAD detection | 1-2s | 30-60 Ã¡udios/min |
| WebRTC VAD detection | 0.5-1s | 60-120 Ã¡udios/min |
| Speech gating | 0.1-0.2s | 300-600/min |
| SRT generation | 0.05s | 1200/min |
| FFmpeg burn-in | 10-20s | 3-6 vÃ­deos/min |
| **Total pipeline** | **20-38s** | **1.5-3 vÃ­deos/min** |

---

## CONCLUSÃƒO

O sistema de sincronizaÃ§Ã£o de Ã¡udio com legendas Ã© **robusto, preciso e estÃ¡ 100% funcional em produÃ§Ã£o**:

âœ… **VAD de alta precisÃ£o** (Silero-VAD 95%+)  
âœ… **Fallbacks automÃ¡ticos** (WebRTC â†’ RMS)  
âœ… **Gating inteligente** (clamp, drop, merge)  
âœ… **ValidaÃ§Ã£o rigorosa** (SRT vazio = job FAIL)  
âœ… **Retry infinito** (transcriÃ§Ã£o sempre completa)  
âœ… **Performance excelente** (20-38s para 60s de Ã¡udio)  

### Garantias do Sistema

1. **Legendas sÃ£o OBRIGATÃ“RIAS**: Se SRT vazio â†’ job FAIL
2. **Legendas sÃ³ aparecem durante fala**: VAD garante sincronizaÃ§Ã£o
3. **DuraÃ§Ã£o mÃ­nima garantida**: 120ms (legÃ­vel)
4. **Sem flicker**: Merge automÃ¡tico de legendas prÃ³ximas
5. **Retry automÃ¡tico**: TranscriÃ§Ã£o nunca falha permanentemente

---

**Ãšltima atualizaÃ§Ã£o**: 2026-02-20  
**Autor**: Sistema de documentaÃ§Ã£o automÃ¡tica  
**Status**: âœ… ProduÃ§Ã£o ativa
