# OPTIMIZE - Oportunidades de Otimiza√ß√£o

> **√öltima atualiza√ß√£o:** Auto-gerado  
> **Escopo:** services/make-video  
> **Exclus√µes:** Zabbix, Grafana (conforme solicitado)

---

## üìä Resumo Executivo

| Categoria | Impacto | Esfor√ßo | Prioridade |
|-----------|---------|---------|------------|
| OCR/EasyOCR | Alto | M√©dio | P0 |
| Mem√≥ria/CPU | Alto | Baixo | P0 |
| Calibra√ß√£o | Alto | Baixo | P1 |
| Pipeline TRSD | M√©dio | Alto | P2 |
| Paraleliza√ß√£o | M√©dio | M√©dio | P2 |
| Cache/Storage | Baixo | Baixo | P3 |

---

## P0 - Cr√≠tico

### 1. EasyOCR GPU Acceleration

**Arquivo:** `app/ocr_detector.py`, `app/video_validator.py`

**Situa√ß√£o atual:**
```python
self.ocr_reader = easyocr.Reader(['pt', 'en'], gpu=False, verbose=False)
```

**Problema:** OCR est√° rodando apenas em CPU, perdendo acelera√ß√£o significativa.

**Otimiza√ß√£o proposta:**
```python
import torch

def create_ocr_reader():
    gpu_available = torch.cuda.is_available()
    return easyocr.Reader(
        ['pt', 'en'], 
        gpu=gpu_available,  # Usar GPU quando dispon√≠vel
        verbose=False
    )
```

**Impacto esperado:** 3-5x mais r√°pido com GPU NVIDIA

---

### 2. Limit de Frames por V√≠deo

**Arquivo:** `app/video_validator.py`

**Situa√ß√£o atual:**
```python
def __init__(self, min_confidence: float = 0.40, frames_per_second: int = 6, max_frames: int = 240):
```

**Problema:** 240 frames m√°ximos pode causar OOM em v√≠deos longos.

**Otimiza√ß√£o implementada (verificar):**
```python
# Em calibrate_trsd_optuna.py j√° limitamos a 10 frames
# Considerar reduzir tamb√©m em produ√ß√£o
max_frames: int = 30  # Suficiente para detectar legendas
```

**Impacto:** Redu√ß√£o de 8x no uso de mem√≥ria em v√≠deos longos

---

### 3. Threshold de Confian√ßa Calibrado

**Arquivo:** `app/config.py`, `.env`

**Situa√ß√£o atual:**
```python
ocr_confidence_threshold = 0.40  # Valor padr√£o
```

**Otimiza√ß√£o:**
Ap√≥s executar calibra√ß√£o Optuna, atualizar para valor otimizado:
```bash
# Verificar resultado da calibra√ß√£o
cat storage/calibration/optuna_incremental_results.json

# Atualizar .env com melhor threshold
OCR_CONFIDENCE_THRESHOLD=0.XX  # Usar best_threshold do Optuna
```

**Impacto:** Melhora significativa na acur√°cia (precis√£o vs recall)

---

## P1 - Alta Prioridade

### 4. Singleton Pattern para EasyOCR Reader

**Arquivo:** `app/ocr_detector.py`

**Situa√ß√£o atual:** J√° implementado em `calibrate_trsd_optuna.py`

**Verificar implementa√ß√£o em produ√ß√£o:**
```python
# ‚úÖ BOM - Singleton
_global_detector = None

def get_detector():
    global _global_detector
    if _global_detector is None:
        _global_detector = OCRDetector()
    return _global_detector

# ‚ùå RUIM - Inst√¢ncia por chamada
detector = OCRDetector()  # Cada chamada carrega modelo na mem√≥ria!
```

**A√ß√£o:** Verificar se `celery_tasks.py` usa singleton ou cria m√∫ltiplas inst√¢ncias.

---

### 5. Garbage Collection Agressivo

**Arquivo:** `calibrate_trsd_optuna.py` (j√° implementado)

**Padr√£o recomendado para produ√ß√£o:**
```python
import gc

def process_video(video_path):
    result = detector.detect(video_path)
    
    # Liberar mem√≥ria ap√≥s cada v√≠deo
    if hasattr(gc, 'collect'):
        gc.collect()
    
    return result
```

**Arquivos para aplicar:**
- `app/celery_tasks.py` - Ap√≥s cada job
- `app/video_validator.py` - Ap√≥s validar cada v√≠deo

---

### 6. Convers√£o AV1‚ÜíH.264 em Produ√ß√£o

**Arquivo:** `app/video_validator.py`

**Problema:** V√≠deos AV1 s√£o extremamente lentos para processar com EasyOCR.

**Pipeline atual (calibra√ß√£o):**
```python
def ensure_h264_videos(video_paths, temp_dir):
    # Detecta codec e converte se necess√°rio
    codec = get_video_codec(video_path)
    if codec in ['av1', 'av01']:
        convert_to_h264(video_path, temp_path)
```

**A√ß√£o:** Considerar adicionar mesma l√≥gica em `video_validator.py` quando detectar AV1.

---

## P2 - M√©dia Prioridade

### 7. Processamento Paralelo de Frames

**Arquivo:** `app/video_validator.py`

**Situa√ß√£o atual:** Frames s√£o processados sequencialmente.

**Otimiza√ß√£o proposta:**
```python
from concurrent.futures import ThreadPoolExecutor, as_completed

def detect_subtitles_parallel(self, video_path: str, max_workers: int = 4):
    timestamps = self._get_sample_timestamps(duration)
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {
            executor.submit(self._analyze_frame, video_path, ts): ts 
            for ts in timestamps
        }
        
        results = []
        for future in as_completed(futures):
            results.append(future.result())
    
    return self._aggregate_results(results)
```

**Impacto:** ~3x mais r√°pido em m√°quinas multi-core

**Cuidado:** EasyOCR n√£o √© thread-safe por padr√£o, usar lock se necess√°rio.

---

### 8. Cache de Resultados de Valida√ß√£o

**Arquivo:** `app/video_validator.py`

**Proposta:**
```python
import hashlib
from functools import lru_cache

def _get_video_hash(self, video_path: str) -> str:
    """Hash do arquivo para cache"""
    with open(video_path, 'rb') as f:
        return hashlib.md5(f.read(1024*1024)).hexdigest()  # Primeiros 1MB

@lru_cache(maxsize=1000)
def has_subtitles_cached(self, video_hash: str) -> Tuple[bool, float]:
    """Retorna resultado em cache se dispon√≠vel"""
    pass
```

**Impacto:** Evita reprocessar v√≠deos j√° validados

---

### 9. Dicion√°rio de Palavras Expandido

**Arquivo:** `app/ocr_detector.py`

**Situa√ß√£o atual:**
```python
COMMON_WORDS_PT = {'que', 'para', 'com', ...}  # ~60 palavras
COMMON_WORDS_EN = {'the', 'and', 'you', ...}  # ~60 palavras
```

**Otimiza√ß√£o:**
```python
# Carregar dicion√°rio externo mais completo
def load_dictionary(lang: str) -> set:
    dict_path = Path(f'data/dictionaries/{lang}.txt')
    if dict_path.exists():
        return set(dict_path.read_text().splitlines())
    return DEFAULT_WORDS[lang]

COMMON_WORDS_PT = load_dictionary('pt')  # 1000+ palavras
COMMON_WORDS_EN = load_dictionary('en')  # 1000+ palavras
```

**Impacto:** Melhor recall na detec√ß√£o de legendas v√°lidas

---

### 10. Batch Processing com Celery

**Arquivo:** `app/celery_tasks.py`

**Situa√ß√£o atual:** Um job processa um v√≠deo por vez.

**Otimiza√ß√£o:**
```python
@celery_app.task
def process_video_batch(video_ids: List[str]):
    """Agrupa m√∫ltiplos v√≠deos em um batch para otimizar uso de recursos"""
    detector = get_detector()  # Singleton
    
    results = []
    for video_id in video_ids:
        result = process_single_video(detector, video_id)
        results.append(result)
    
    return results
```

**Impacto:** Reduz overhead de inicializa√ß√£o do EasyOCR

---

## P3 - Baixa Prioridade

### 11. Compress√£o de Artefatos de Debug

**Arquivo:** `app/telemetry.py`

**Proposta:**
```python
import gzip

def save_artifact(self, data: bytes, filename: str):
    with gzip.open(f'{filename}.gz', 'wb') as f:
        f.write(data)
```

**Impacto:** ~80% menos espa√ßo em disco para debug

---

### 12. Logs Estruturados com JSON

**Arquivo:** `app/file_logger.py`

**Situa√ß√£o atual:** Logs em formato texto.

**Otimiza√ß√£o:**
```python
import json

def log_structured(self, level: str, message: str, **kwargs):
    log_entry = {
        'timestamp': datetime.utcnow().isoformat(),
        'level': level,
        'message': message,
        **kwargs
    }
    self._write_log(json.dumps(log_entry))
```

**Impacto:** Facilita an√°lise e alertas automatizados

---

### 13. Healthcheck mais Robusto

**Arquivo:** `docker-compose.yml`

**Situa√ß√£o atual:**
```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
```

**Otimiza√ß√£o:**
```yaml
healthcheck:
  test: ["CMD", "python", "-c", "import requests; r=requests.get('http://localhost:8002/health'); exit(0 if r.json().get('status')=='healthy' else 1)"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 60s  # Tempo para carregar EasyOCR
```

---

## üî¨ M√©tricas de Calibra√ß√£o Atual

```bash
# Verificar status atual
cat storage/calibration/optuna_incremental_results.json
```

| M√©trica | Valor Atual | Alvo |
|---------|-------------|------|
| Trials | 3 | 100 |
| Best Accuracy | 19.44% | 90%+ |
| Best Threshold | 0.55 | TBD |

**Pr√≥ximos passos:**
1. Executar calibra√ß√£o completa (100 trials)
2. Aplicar best_threshold em produ√ß√£o
3. Re-testar com dataset de valida√ß√£o

---

## üìã Checklist de Implementa√ß√£o

- [ ] Habilitar GPU no EasyOCR quando dispon√≠vel
- [ ] Reduzir max_frames para 30 em produ√ß√£o
- [ ] Aplicar threshold otimizado do Optuna
- [ ] Verificar singleton em celery_tasks.py
- [ ] Adicionar GC ap√≥s cada job
- [ ] Considerar convers√£o AV1‚ÜíH.264 em produ√ß√£o
- [ ] Expandir dicion√°rios PT/EN
- [ ] Implementar cache de valida√ß√£o
- [ ] Adicionar start_period no healthcheck

---

## üìö Refer√™ncias

- [EasyOCR GPU Support](https://github.com/JaidedAI/EasyOCR#gpu-support)
- [Optuna TPE Sampler](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html)
- [Celery Best Practices](https://docs.celeryproject.org/en/stable/userguide/tasks.html#tips-and-best-practices)
