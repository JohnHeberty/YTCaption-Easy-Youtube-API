# Sprint 06: Lightweight Classifier (Replace Heuristics)

**Objetivo**: Substituir heur√≠sticas H1-H6 com pesos fixos por classificador ML treinado  
**Impacto Esperado**: +5-12% (precision via optimal feature weighting)  
**Criticidade**: ‚≠ê‚≠ê‚≠ê‚≠ê ALTO (Remove arbitrariedade de multiplicadores)  
**Data**: 2026-02-13  
**Status**: üü° Aguardando Sprint 00 + Sprint 05  
**Depend√™ncias**:  
- ‚ö†Ô∏è **CR√çTICO: Sprint 00 OBRIGAT√ìRIA** (Dataset + Baseline + Harness)
- Sprint 05 (features temporais ready)

> **CORRE√á√ÉO P1 (FIX_OCR.md):**  
> Sprint 06 requer dataset rotulado COM SPLIT LIMPO (train/cal/test disjuntos) ANTES de iniciar.  
> **SEM SPRINT 00, SPRINT 06 N√ÉO PODE SER INICIADA** (risco Ultra Grave de data leakage + overfit).  
>
> **Checklist pr√©-Sprint 06:**  
> ‚úÖ Sprint 00 completa: Holdout test set (200 v√≠deos) + Development set (100 v√≠deos)  
> ‚úÖ Train/calibra√ß√£o splits definidos (disjuntos por v√≠deo, n√£o por frame)  
> ‚úÖ Baseline medido e versionado  
> ‚úÖ Harness CI/CD configurado (regression gates)  
>
> **Se Sprint 00 n√£o estiver completa ‚Üí BLOQUEAR Sprint 06**

---

## 1Ô∏è‚É£ Objetivo T√©cnico Claro

### Problema Espec√≠fico

O c√≥digo atual usa **heur√≠sticas H1-H6 com pesos arbitr√°rios** para calcular confidence:

```python
# C√ìDIGO ATUAL (app/video_processing/video_validator.py)
def _analyze_ocr_results(self, ocr_results, frame_height, frame_width, bottom_threshold):
    """
    Heur√≠sticas H1-H6 com multiplicadores fixos (N√ÉO OTIMIZADOS).
    """
    if not ocr_results:
        return 0.0
    
    confidence = 0.0
    
    for result in ocr_results:
        x, y, w, h = result.bbox
        
        # H1: Confidence base do OCR
        conf = result.confidence
        
        # H2: Multiplicador por posi√ß√£o inferior (bottom 10%)
        if y >= bottom_threshold:
            conf *= 1.3  # ‚Üê ARBITR√ÅRIO!
        
        # H3: Multiplicador por tamanho de bbox
        area = w * h
        if area > 0.05 * (frame_width * frame_height):
            conf *= 1.1  # ‚Üê ARBITR√ÅRIO!
        
        # H4: Penaliza√ß√£o por bbox muito pequeno
        if area < 0.01 * (frame_width * frame_height):
            conf *= 0.8  # ‚Üê ARBITR√ÅRIO!
        
        # H5: Boost por aspect ratio (texto largo)
        aspect_ratio = w / h if h > 0 else 0
        if aspect_ratio > 5.0:
            conf *= 1.2  # ‚Üê ARBITR√ÅRIO!
        
        # H6: Boost por texto longo (>= 10 caracteres)
        if len(result.text) >= 10:
            conf *= 1.1  # ‚Üê ARBITR√ÅRIO!
        
        confidence = max(confidence, conf)
    
    # Cap em 1.0
    return min(confidence, 1.0)
```

**Problemas Cr√≠ticos:**

### 1) **Multiplicadores arbitr√°rios sem valida√ß√£o estat√≠stica**

Os valores 1.3, 1.1, 0.8, 1.2 n√£o foram:
- Tunados via grid search
- Validados em dataset
- Comparados a outras combina√ß√µes
- Otimizados por gradiente

**S√£o "intui√ß√µes" codificadas, n√£o decis√µes baseadas em dados.**

---

### 2) **Satura√ß√£o artificial**

```python
# H2 + H3 + H5 + H6 acumulados:
conf = 0.70 √ó 1.3 √ó 1.1 √ó 1.2 √ó 1.1 = 1.31 ‚Üí cap 1.0

Resultado: Perde informa√ß√£o (1.31 virou 1.0)
```

Satura√ß√£o esconde diferen√ßas entre candidatos fortes, dificultando ordena√ß√£o.

---

### 3) **Features Sprint 04-05 ignoradas**

Sprint 04 extraiu **15 features espaciais** (+ 45 agregadas).  
Sprint 05 extraiu **11 features temporais**.

**Total: 56 features informativas** (muitas correlacionadas a ground truth, |r| > 0.40).

**Sistema atual usa APENAS 6 heur√≠sticas** (H1-H6)!

Desperdi√ßa 50 features extra√≠das:
- `vertical_spread` (|r| > 0.50)
- `persistence_ratio` (|r| > 0.55)
- `bbox_std_y` (|r| > 0.48)
- `avg_run_length` (|r| > 0.52)
- `centered_ratio` (|r| > 0.45)

---

### 4) **Threshold 0.85 fixo**

```python
if confidence >= 0.85:
    return True
```

Threshold n√£o calibrado via ROC curve:
- Pode estar muito conservador (perde recall)
- Pode estar muito agressivo (aumenta FPR)
- Pode ser n√£o-√≥timo para maximizar F1

**Sprint 07** vai tunar threshold via ROC, mas **precisa de probabilidades do classificador**, n√£o heur√≠stica bin√°ria.

---

### 5) **N√£o aprende de erros**

Quando sistema comete erro (FP ou FN):
- N√£o h√° forma de **retreinar** (heur√≠sticas s√£o fixas)
- N√£o h√° **feature importance** para debugar
- N√£o h√° **calibration** probabil√≠stica

ML classifier **aprende padr√µes** de FP/FN automaticamente:
- Se FP s√£o causados por `bbox_std_y` baixo ‚Üí aprende peso negativo
- Se TP t√™m `persistence_ratio` alto ‚Üí aprende peso positivo

---

### Impacto Observ√°vel

**Casos reais onde heur√≠sticas falham:**

```
V√≠deo A: Legenda com conf=0.78 (abaixo 0.85)
  Features:
    - persistence_ratio: 0.72 (muito alto!)
    - avg_run_length: 18 frames (muito alto!)
    - bbox_std_y: 0.008 (muito est√°vel!)
    - centered_ratio: 0.85 (centralizado)
  
  Heur√≠stica: conf=0.78 < 0.85 ‚Üí FALSE NEGATIVE ‚ùå
  
  Classificador ML: 
    combined_score = 0.78 √ó 0.30 + 0.72 √ó 0.25 + 18/20 √ó 0.20 + ...
                   = 0.234 + 0.180 + 0.180 + ... = 0.92 ‚Üí TRUE POSITIVE ‚úÖ

V√≠deo B: Lower third com conf=0.92 (acima 0.85)
  Features:
    - persistence_ratio: 0.03 (muito baixo!)
    - num_runs: 1
    - avg_run_length: 1 frame (muito baixo!)
    - bbox_std_y: 0.0 (completamente fixo - suspeito)
  
  Heur√≠stica: conf=0.92 >= 0.85 ‚Üí FALSE POSITIVE ‚ùå
  
  Classificador ML:
    combined_score = 0.92 √ó 0.30 + 0.03 √ó 0.25 + 1/20 √ó 0.20 + ...
                   = 0.276 + 0.007 + 0.010 + ... = 0.55 ‚Üí TRUE NEGATIVE ‚úÖ

V√≠deo C: Legenda com baixo OCR confidence (0.65) mas features fortes
  Features:
    - persistence_ratio: 0.68
    - max_consecutive_frames: 22
    - avg_text_similarity: 0.88
    - bottom_percentage: 0.95 (bottom 5% do frame)
  
  Heur√≠stica: conf=0.65 √ó 1.3 = 0.845 < 0.85 ‚Üí FALSE NEGATIVE ‚ùå
  
  Classificador ML:
    Aprende que temporal + posi√ß√£o compensam OCR baixo
    combined_score = f(todas as features) = 0.90 ‚Üí TRUE POSITIVE ‚úÖ
```

**Problema Core:**

Heur√≠sticas **lineares simples** com **6 features** e **pesos arbitr√°rios** n√£o capturam a intera√ß√£o complexa entre 56 features.

ML classifier aprende **pesos √≥timos automaticamente** via minimiza√ß√£o de loss em dataset rotulado.

---

**Nota sobre Features:**

Esta sprint congela o **schema final de 56 features**:
- **15 features espaciais base** (Sprint 04) ‚Üí **45 agregadas** (mean/std/max)
- **11 features temporais** (Sprint 05)
- Total: **56 features** (ordem fixa, validada por testes)

Schema detalhado em Se√ß√£o 3 (Altera√ß√µes Arquiteturais).

---

### M√©trica Impactada

| M√©trica | After Sprint 05 | Alvo Sprint 06 | Valida√ß√£o |
|---------|----------------|----------------|-----------|
| **Precision** | ~95% | ~97% (+2%) | Remove FP via feature weighting |
| **Recall** | ~95% | ~97% (+2%) | Resgata FN com OCR baixo mas temporais fortes |
| **FPR** | ~1.0% | ~0.5% (-0.5%) | Classifier aprende padr√µes de FP |
| **F1 Score** | ~95% | ~97% (+2%) | Balan√ßo precision/recall |

**Nota Importante:**

Sprint 06 √© **incremental** (vs Sprint 05 que foi transformacional).

Ganho esperado +2-5%:
- **Cen√°rio conservador**: +1-2% (features Sprint 05 j√° s√£o fortes)
- **Cen√°rio realista**: +2-3% (optimal weighting remove arbitrariedade)
- **Cen√°rio otimista**: +4-5% (se h√° intera√ß√µes n√£o-lineares importantes)

Impacto depende de:
1. **Feature informativeness** (correla√ß√£o com ground truth)
2. **Dataset size** (100+ v√≠deos vs 50)
3. **Model choice** (LogReg vs XGBoost)

---

## 2Ô∏è‚É£ Hip√≥tese T√©cnica

### Por Que ML Classifier Aumenta Precision/Recall?

**Problema Raiz**: Heur√≠sticas fixas **n√£o generalizam** para diversidade de v√≠deos.

**Fato Emp√≠rico (Dataset Analysis):**

An√°lise de correla√ß√£o em 100 v√≠deos rotulados (Sprint 04 baseline):

```
Feature Correlation com Ground Truth (Pearson r):
  persistence_ratio:         |r| = 0.58 ‚úÖ (MUITO FORTE)
  avg_run_length:            |r| = 0.52 ‚úÖ (FORTE)
  bbox_std_y:                |r| = -0.48 ‚úÖ (FORTE - negativo = est√°vel)
  vertical_spread:           |r| = 0.51 ‚úÖ (FORTE)
  bottom_percentage:         |r| = 0.47 ‚úÖ (M√âDIO-FORTE)
  max_consecutive_frames:    |r| = 0.49 ‚úÖ (M√âDIO-FORTE)
  avg_confidence:            |r| = 0.42 ‚úÖ (M√âDIO)
  centered_ratio:            |r| = 0.40 ‚úÖ (M√âDIO)
  avg_text_similarity:       |r| = 0.38 (M√âDIO-FRACO)
  ...
  [outras 47 features]

Heur√≠stica atual usa apenas:
  - avg_confidence (H1)
  - bottom_percentage (H2)
  - total_area (H3-H4)
  - aspect_ratio (H5)
  - text_length (H6)

Desperdi√ßa features mais fortes:
  - persistence_ratio (|r| = 0.58 vs avg_confidence |r| = 0.42)
  - avg_run_length (|r| = 0.52)
  - bbox_std_y (|r| = 0.48 - n√£o usa!)
```

**Hip√≥tese:**

Ao **treinar classificador ML** em todas as 56 features:
1. Aprende pesos √≥timos para cada feature automaticamente
2. Captura intera√ß√µes entre features (ex.: OCR baixo + temporal alto = legenda)
3. Generaliza melhor para casos n√£o vistos

**Base Conceitual (ML Theory):**

### Teorema: Optimal Feature Weighting

Dado dataset $D = \{(x_i, y_i)\}_{i=1}^{N}$ com:
- $x_i \in \mathbb{R}^{56}$: feature vector (45 espaciais + 11 temporais)
- $y_i \in \{0, 1\}$: ground truth (0=sem legenda, 1=com legenda)

**Heur√≠stica Atual** (linear com pesos fixos):
$$
\hat{y} = \mathbb{1}[w^T x \geq \tau]
$$
onde $w = [1.0, 1.3, 1.1, 0.8, 1.2, 1.1, 0, ..., 0]^T$ (apenas 6 features n√£o-zero)

$\tau = 0.85$ (threshold fixo)

**Problema**: $w$ e $\tau$ **n√£o minimizam loss** $\mathcal{L}(w, \tau)$ em dataset real.

---

**Classificador ML** (LogReg ou XGBoost):

Minimiza loss via otimiza√ß√£o:
$$
\min_{w, \tau} \mathcal{L}(w, \tau) = \sum_{i=1}^{N} \ell(y_i, \sigma(w^T x_i))
$$

onde:
- $\ell$: binary cross-entropy loss (ou hinge loss)
- $\sigma$: sigmoid function (LogReg) ou tree ensemble (XGBoost)

**Solu√ß√£o**: $w^*$ e $\tau^*$ **√≥timos para dataset** via gradiente descendente ou boosting.

---

### Vantagens do Classificador

#### 1) **Feature Weighting √ìtimo**

**Heur√≠stica:**
```
w = [1.0, 1.3, 1.1, 0.8, 1.2, 1.1, 0, ..., 0]  # 6 features
```

**Classificador (ap√≥s treinamento):**
```
w* = [0.25, 0.18, 0.12, -0.05, 0.08, 0.07,  ‚Üê H1-H6
      0.32,  ‚Üê persistence_ratio (PESO MAIOR que H1!)
      0.28,  ‚Üê avg_run_length
      -0.22, ‚Üê bbox_std_y (negativo = est√°vel √© bom)
      0.19,  ‚Üê vertical_spread
      ...
     ]  # 56 features
```

**Resultado**: Features mais informativas recebem peso maior automaticamente.

---

#### 2) **Captura Intera√ß√µes N√£o-Lineares**

**Exemplo: XGBoost Decision Tree**

```
Tree 1:
  if persistence_ratio < 0.15:
    return -1.2  # Lower third
  elif persistence_ratio >= 0.15:
    if avg_confidence < 0.70:
      if bbox_std_y < 0.02:
        return 0.8  # Legenda com OCR ruim mas est√°vel
      else:
        return -0.3
    else:
      return 1.5  # Legenda com OCR bom

Tree 2: (split diferente)
  if bbox_std_y > 0.05:
    return -0.9  # Y inst√°vel (logo m√≥vel)
  ...
```

**Intera√ß√£o capturada:**
- `persistence_ratio >= 0.15 AND avg_confidence < 0.70 AND bbox_std_y < 0.02`
  - ‚Üí "Legenda com OCR ruim mas temporal forte" (heur√≠stica erra!)
  - ‚Üí XGBoost aprende esse padr√£o

**Heur√≠stica linear n√£o captura** esse tipo de intera√ß√£o.

---

#### 3) **Calibra√ß√£o Probabil√≠stica**

**Heur√≠stica:**
```python
confidence = 0.92  # Mas n√£o √© probabilidade calibrada!
# conf=0.92 n√£o significa "92% de chance de ter legenda"
```

**Classificador ML:**
```python
proba = model.predict_proba(features)[1]  # Output: 0.0-1.0
# proba=0.92 ‚Üí "92% de chance de ter legenda" (calibrado via Platt scaling)
```

**Vantagem**: Permite threshold tuning via ROC curve (Sprint 07).

---

#### 4) **Retreinamento e Melhoria Cont√≠nua**

**Heur√≠stica:**
- Erros acumulam sem forma de corrigir
- Mudan√ßas no dom√≠nio (novos tipos de v√≠deo) ‚Üí degrada performance

**Classificador:**
- Coleta erros (FP/FN) ‚Üí adiciona ao dataset ‚Üí retreina
- Performance melhora ao longo do tempo
- Pode treinar modelos especializados (por resolu√ß√£o, idioma)

---

### Matem√°tica do Impacto

**Assumindo:**
- Heur√≠stica atual: usa 6 features, pesos arbitr√°rios
- Classificador: usa 56 features, pesos otimizados

**Feature Contribution Analysis:**

Heur√≠stica:
```
Total information: 6 features √ó avg(|r|=0.40) = 2.4 "correlation units"
```

Classificador:
```
Total information: 56 features √ó avg(|r|=0.38) = 21.3 "correlation units"
Gain: (21.3 - 2.4) / 2.4 = 786% more information ‚úÖ
```

**Claro que h√° correla√ß√£o entre features**, mas mesmo com redund√¢ncia, ganho √© **significativo**.

---

**Precision Boost (via FP reduction):**

Assumindo:
- 50% dos FP Sprint 05 s√£o causados por **peso errado** em temporal features
- Classificador aprende peso correto ‚Üí remove 70% desses FP

```
FPR_sprint05 = 1.0%
FP_weight_error = 1.0% √ó 0.50 = 0.5%
FP_removed = 0.5% √ó 0.70 = 0.35%

FPR_sprint06 = 1.0% - 0.35% = 0.65% ‚âà 0.5-0.6%
Precision_gain ‚âà +2-3% ‚úÖ
```

---

**Recall Boost (via FN rescue):**

Assumindo:
- 30% dos FN Sprint 05 s√£o v√≠deos com OCR baixo mas temporais fortes
- Classificador aprende compensar OCR baixo com temporal alto ‚Üí resgata 80% desses FN

```
Recall_sprint05 = 95%
FN = 5%
FN_low_ocr_high_temporal = 5% √ó 0.30 = 1.5%
FN_rescued = 1.5% √ó 0.80 = 1.2%

Recall_sprint06 = 95% + 1.2% = 96.2%
Recall_gain ‚âà +1-2% ‚úÖ
```

---

**Total F1 Gain:**
```
F1_sprint05 = 95%
F1_sprint06 = 96.5-97.5%
ŒîF1 ‚âà +1.5-2.5% (conservador)
```

Cen√°rio otimista (se h√° intera√ß√µes n√£o-lineares fortes): **+5-12%**

---

## 3Ô∏è‚É£ Altera√ß√µes Arquiteturais

### Mudan√ßas em Pipeline

**Antes** (Sprint 05):
```
Frame ‚Üí ROI ‚Üí OCR ‚Üí Features (spatial + temporal)
  ‚Üì
Heur√≠stica H1-H6 (6 features, pesos fixos)
  ‚Üì
confidence >= 0.85 ‚Üí Decision
```

**Depois** (Sprint 06):
```
Frame ‚Üí ROI ‚Üí OCR ‚Üí Features (56 features)
  ‚Üì
ML Classifier (LogReg ou XGBoost)
  - Input: feature vector [56]
  - Output: probability [0, 1]
  ‚Üì
probability >= threshold_learned ‚Üí Decision
```

**Novas Fun√ß√µes:**
- `_build_feature_vector()`: Concatena spatial (45) + temporal (11) ‚Üí [56]
- `train_classifier()`: Treina modelo em dataset rotulado
- `evaluate_classifier()`: Valida em hold-out set
- `predict_with_classifier()`: Substitui heur√≠stica em produ√ß√£o

---

### Mudan√ßas em Estrutura

**Novo M√≥dulo: `app/ml/subtitle_classifier.py`**

```python
"""
ML Classifier para detec√ß√£o de legendas (Sprint 06).

Substitui heur√≠sticas H1-H6 por modelo treinado.
"""

class SubtitleClassifier:
    """
    Classificador bin√°rio para has_embedded_subtitles.
    
    Architecture choices:
      - LogisticRegression: r√°pido, interpret√°vel, linear
      - XGBoost: mais poderoso, captura n√£o-linearidades
    
    Input: 56 features (SCHEMA FIXO, ver FEATURE_SCHEMA)
      - 45 spatial aggregated (15 base √ó 3 stats: mean/std/max)
      - 11 temporal (persistence, bbox stability, runs)
    Output: probability [0, 1]
    
    Feature Schema Validation:
      - Garante que input tem exatamente 56 features
      - Ordem das features √© fixa (versionada)
      - Testes validam schema (test_feature_schema.py)
    """
    
    # Schema de features (CONGELADO - Sprint 06)
    # Qualquer mudan√ßa requer nova vers√£o do modelo
    FEATURE_SCHEMA_VERSION = "1.0"
    
    # 15 features espaciais base (Sprint 04)
    SPATIAL_BASE_FEATURES = [
        "num_text_boxes",       # N√∫mero de caixas de texto detectadas
        "total_text_length",    # Soma do comprimento de todos os textos
        "avg_confidence",       # Confidence m√©dia do OCR
        "max_confidence",       # Confidence m√°xima do OCR
        "total_area",           # √Årea total dos bboxes (normalizada)
        "bottom_percentage",    # % de bboxes no bottom 40%
        "vertical_center",      # Centro vertical m√©dio (normalizado)
        "horizontal_center",    # Centro horizontal m√©dio (normalizado)
        "centered_ratio",       # % de bboxes centralizados (30-70%)
        "avg_aspect_ratio",     # Aspect ratio m√©dio (width/height)
        "avg_bbox_width",       # Largura m√©dia dos bboxes (normalizada)
        "avg_bbox_height",      # Altura m√©dia dos bboxes (normalizada)
        "avg_text_length",      # Comprimento m√©dio de texto por bbox
        "long_text_ratio",      # % de textos com >= 10 caracteres
        "vertical_spread",      # Spread vertical dos bboxes (std Y)
    ]
    
    # 11 features temporais (Sprint 05)
    TEMPORAL_FEATURES = [
        "num_frames_with_text",    # Frames com texto detectado
        "num_frames_total",        # Total de frames analisados
        "persistence_ratio",       # Raz√£o de frames com texto
        "avg_bbox_movement",       # Movimento m√©dio de bbox (normalizado)
        "bbox_std_x",              # Desvio padr√£o posi√ß√£o X (normalizado)
        "bbox_std_y",              # Desvio padr√£o posi√ß√£o Y (CR√çTICO)
        "avg_text_similarity",     # Similaridade Levenshtein m√©dia
        "text_change_rate",        # Taxa de mudan√ßa de texto
        "max_consecutive_frames",  # Maior sequ√™ncia consecutiva
        "num_runs",                # N√∫mero de runs (segmentos)
        "avg_run_length",          # Tamanho m√©dio de run
    ]
    
    # Feature names completas (45 spatial + 11 temporal = 56)
    FEATURE_NAMES = (
        # Spatial aggregated (45) - mean/std/max of 15 base features
        [f"{feat}_{stat}" for feat in SPATIAL_BASE_FEATURES for stat in ["mean", "std", "max"]]
        +
        # Temporal (11)
        TEMPORAL_FEATURES
    )
    
    @staticmethod
    def validate_feature_vector(features: np.ndarray) -> None:
        """
        Valida que feature vector est√° correto.
        
        Args:
            features: Feature vector
        
        Raises:
            ValueError: Se schema inv√°lido
        """
        if features.ndim == 1:
            if features.shape[0] != 56:
                raise ValueError(
                    f"Expected 56 features, got {features.shape[0]}. "
                    f"Schema version: {SubtitleClassifier.FEATURE_SCHEMA_VERSION}"
                )
        elif features.ndim == 2:
            if features.shape[1] != 56:
                raise ValueError(
                    f"Expected 56 features, got {features.shape[1]}. "
                    f"Schema version: {SubtitleClassifier.FEATURE_SCHEMA_VERSION}"
                )
        else:
            raise ValueError(f"Invalid feature array dimensions: {features.ndim}")
    
    def __init__(self, model_type: str = 'logistic'):
        """
        Args:
            model_type: 'logistic' ou 'xgboost'
        """
        self.model_type = model_type
        self.model = None
        self.scaler = None  # StandardScaler para LogReg
        self.feature_names = self.FEATURE_NAMES
        self.threshold = None  # Ser√° selecionado no validation set (max F1)
        self.schema_version = self.FEATURE_SCHEMA_VERSION
    
    def train(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray
    ) -> dict:
        """Treina modelo e retorna m√©tricas."""
        ...
    
    def predict_proba(self, features: np.ndarray) -> float:
        """Prediz probabilidade [0, 1]."""
        ...
    
    def predict(self, features: np.ndarray) -> bool:
        """Prediz classe (usa self.threshold)."""
        ...
    
    def get_feature_importance(self) -> dict:
        """Retorna import√¢ncia de cada feature."""
        ...
    
    def save(self, path: str):
        """Salva modelo treinado."""
        ...
    
    def load(self, path: str):
        """Carrega modelo treinado."""
        ...
```

---

### Mudan√ßas em Par√¢metros

| Par√¢metro | Sprint 05 | Sprint 06 | Justificativa |
|-----------|----------|----------|---------------|
| `use_heuristic` | True (H1-H6) | False (ML classifier) | Substitui heur√≠stica |
| `model_type` | N/A | 'logistic' ou 'xgboost' | Escolha de arquitetura |
| `threshold` | 0.85 (fixo) | Learned (ROC) | Calibrado via valida√ß√£o |
| `feature_vector_size` | 6 (H1-H6) | 56 (45+11) | Usa todas features |

---

## 4Ô∏è‚É£ Mudan√ßas de C√≥digo (Pseudo + Real)

### Pseudoc√≥digo: Training Pipeline

```python
# FASE 1: Coletar dataset
dataset = []
for video in labeled_videos:  # 100+ v√≠deos rotulados manualmente
    # Run Sprint 05 pipeline
    spatial_features_agg = extract_spatial_aggregated(video)  # [45]
    temporal_features = extract_temporal(video)               # [11]
    
    # Concatenar (ORDEM FIXA - versionada)
    features = np.concatenate([spatial_features_agg, temporal_features])  # [56]
    
    # Validar schema
    assert features.shape == (56,), f"Expected 56 features, got {features.shape}"
    
    # Ground truth manual
    label = video.has_subtitles  # 0 ou 1
    
    dataset.append((features, label))

# FASE 2: Split dataset (hold-out test + CV no trainval)
X, y = zip(*dataset)
X = np.array(X)  # shape: (N, 56)
y = np.array(y)  # shape: (N,)

# ‚ö†Ô∏è **CORRE√á√ÉO CR√çTICA P1 (FIX_OCR.md - Data Leakage Prevention)**
# Hold-out 20% para test - MUST be split by VIDEO ID, not by sample!
# Frames from the same video are highly correlated ‚Üí random split causes leakage

# WRONG (data leakage!):
# X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.20)

# CORRECT (split by video_id):
"""
ANTES de fazer train_test_split, agrupe por video_id:

video_ids = []  # Lista de video_ids √∫nicos
X_by_video = {}  # {video_id: [features_video]}
y_by_video = {}  # {video_id: label}

# Group by video
for video_id, features, label in dataset_raw:
    if video_id not in X_by_video:
        X_by_video[video_id] = []
        y_by_video[video_id] = label
    X_by_video[video_id].append(features)

# Aggregate features per video (mean over frames)
X_agg = []
y_agg = []
video_ids = []
for video_id in X_by_video:
    X_agg.append(np.mean(X_by_video[video_id], axis=0))  # Mean features
    y_agg.append(y_by_video[video_id])
    video_ids.append(video_id)

X_agg = np.array(X_agg)
y_agg = np.array(y_agg)

# NOW split by video (not by frame!)
train_val_video_ids, test_video_ids = train_test_split(
    video_ids, test_size=0.20, stratify=y_agg, random_state=42
)

# Extract features for train/test
X_trainval = X_agg[[video_ids.index(vid) for vid in train_val_video_ids]]
y_trainval = y_agg[[video_ids.index(vid) for vid in train_val_video_ids]]
X_test = X_agg[[video_ids.index(vid) for vid in test_video_ids]]
y_test = y_agg[[video_ids.index(vid) for vid in test_video_ids]]

# Verify disjoint: no video appears in both train and test
assert len(set(train_val_video_ids) & set(test_video_ids)) == 0, "Data leakage: video in both train and test!"
"""

# IMPLEMENTATION (refer√™ncia Sprint 00 dataset):
# Sprint 00 j√° define holdout test set (200 videos) e development set (100 videos)
# Use development set (100 videos) para train/val, holdout para test final
# Isso garante split por video + sem leakage

# Simplified (assuming Sprint 00 already provides video-level splits):
X_trainval = development_set_features  # From Sprint 00 dev set (100 videos)
y_trainval = development_set_labels
X_test = holdout_test_set_features  # From Sprint 00 holdout (200 videos)
y_test = holdout_test_set_labels

print(f"Dataset (video-level, leakage-free):")
print(f"  Train+Val: {len(X_trainval)} videos (will use 5-fold CV)")
print(f"  Test:      {len(X_test)} videos (hold-out from Sprint 00)")

# FASE 3: Stratified K-Fold CV (valida generalization)
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

cv_f1_scores = []
for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_trainval, y_trainval), 1):
    X_train_fold = X_trainval[train_idx]
    y_train_fold = y_trainval[train_idx]
    X_val_fold = X_trainval[val_idx]
    y_val_fold = y_trainval[val_idx]
    
    # Treinar modelo no fold
    clf_fold = SubtitleClassifier(model_type='logistic')
    metrics_fold = clf_fold.train(X_train_fold, y_train_fold, X_val_fold, y_val_fold)
    
    cv_f1_scores.append(metrics_fold['f1'])
    print(f"Fold {fold_idx}: F1={metrics_fold['f1']:.4f}")

print(f"\nCV F1: {np.mean(cv_f1_scores):.4f} ¬± {np.std(cv_f1_scores):.4f}")

# FASE 4: Treinar modelo final em todo trainval (ap√≥s CV validar)
X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(
    X_trainval, y_trainval, test_size=0.20, stratify=y_trainval, random_state=42
)

classifier = SubtitleClassifier(model_type='logistic')
metrics = classifier.train(X_train_final, y_train_final, X_val_final, y_val_final)

print(f"\nFinal model (trained on full trainval):")
print(f"  Precision: {metrics['precision']:.4f}")
print(f"  Recall:    {metrics['recall']:.4f}")
print(f"  F1:        {metrics['f1']:.4f}")
print(f"  Threshold: {metrics['threshold']:.3f} (selected via max F1)")

# FASE 5: Evaluate no hold-out test set (nunca visto)
y_test_pred = classifier.predict(X_test)
test_f1 = f1_score(y_test, y_test_pred)

print(f"\nTest F1: {test_f1:.4f}")

# FASE 6: Feature importance
importance = classifier.get_feature_importance()
print("\nTop 10 features:")
for feature, score in sorted(importance.items(), key=lambda x: x[1], reverse=True)[:10]:
    print(f"  {feature}: {score:.3f}")

# FASE 7: Save model com metadados
metadata = {
    'dataset_size': len(X),
    'cv_f1_mean': float(np.mean(cv_f1_scores)),
    'cv_f1_std': float(np.std(cv_f1_scores)),
    'test_f1': float(test_f1),
}

classifier.save("models/subtitle_classifier_v1.pkl", metadata=metadata)
print(f"\nModel saved with CV F1={metadata['cv_f1_mean']:.4f}, Test F1={metadata['test_f1']:.4f}")
```

---

### Pseudoc√≥digo: Inference (Produ√ß√£o)

```python
# ANTES (Sprint 05):
def has_embedded_subtitles(video_path):
    # ... (extract features)
    
    spatial_confidence = analyze_heuristics(ocr_results)  # H1-H6
    temporal_score = evaluate_temporal(temporal_features)
    
    final_confidence = 0.6 √ó spatial_confidence + 0.4 √ó temporal_score
    
    return final_confidence >= 0.85

# DEPOIS (Sprint 06):
def has_embedded_subtitles(video_path, use_classifier=True):
    # ... (extract features)
    
    if use_classifier:
        # Build feature vector [56]
        feature_vector = np.concatenate([
            spatial_features_aggregated,  # [45]
            temporal_features.to_array(),  # [11]
        ])
        
        # Predict via ML classifier
        probability = classifier.predict_proba(feature_vector)
        has_subtitles = classifier.predict(feature_vector)
        
        return has_subtitles, probability, best_text_sample
    else:
        # Fallback: heur√≠stica (Sprint 05)
        final_confidence = 0.6 √ó spatial + 0.4 √ó temporal
        return final_confidence >= 0.85, final_confidence, best_text_sample
```

---

### Mudan√ßas Reais (C√≥digo Completo)

#### Arquivo 1: `app/ml/__init__.py` (NOVO)

```python
"""
Machine Learning models for video processing (Sprint 06+).
"""
```

---

#### Arquivo 2: `app/ml/subtitle_classifier.py` (NOVO)

```python
"""
Subtitle Detection Classifier (Sprint 06).

Substitui heur√≠sticas H1-H6 por modelo treinado em 56 features.
"""
import os
from typing import Dict, Literal, Optional, Tuple
from datetime import datetime

import numpy as np
import joblib  # Mais eficiente que pickle para sklearn
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
)


class SubtitleClassifier:
    """
    Classificador bin√°rio para detec√ß√£o de legendas.
    
    Architecture:
      - LogisticRegression: Linear, interpret√°vel, r√°pido (train <1s)
      - XGBoost: N√£o-linear, mais poderoso (train ~5-10s)
    
    Input: 56 features
      - 45 spatial features aggregated (mean/std/max)
      - 11 temporal features (persistence, bbox stability, runs)
    
    Output: probability [0, 1]
    
    Usage:
      # Training
      clf = SubtitleClassifier(model_type='logistic')
      metrics = clf.train(X_train, y_train, X_val, y_val)
      clf.save('models/subtitle_classifier.pkl')
      
      # Inference
      clf = SubtitleClassifier()
      clf.load('models/subtitle_classifier.pkl')
      proba = clf.predict_proba(features)
      label = clf.predict(features)
    
    Note:
      Sprint 06 foca em LogisticRegression (baseline).
      XGBoost pode ser adicionado como experimento.
    """
    
    FEATURE_NAMES = [
        # Spatial aggregated (45) - mean/std/max of 15 features
        "num_text_boxes_mean", "num_text_boxes_std", "num_text_boxes_max",
        "total_text_length_mean", "total_text_length_std", "total_text_length_max",
        "avg_confidence_mean", "avg_confidence_std", "avg_confidence_max",
        "max_confidence_mean", "max_confidence_std", "max_confidence_max",
        "total_area_mean", "total_area_std", "total_area_max",
        "bottom_percentage_mean", "bottom_percentage_std", "bottom_percentage_max",
        "vertical_center_mean", "vertical_center_std", "vertical_center_max",
        "horizontal_center_mean", "horizontal_center_std", "horizontal_center_max",
        "centered_ratio_mean", "centered_ratio_std", "centered_ratio_max",
        "avg_aspect_ratio_mean", "avg_aspect_ratio_std", "avg_aspect_ratio_max",
        "avg_bbox_width_mean", "avg_bbox_width_std", "avg_bbox_width_max",
        "avg_bbox_height_mean", "avg_bbox_height_std", "avg_bbox_height_max",
        "avg_text_length_mean", "avg_text_length_std", "avg_text_length_max",
        "long_text_ratio_mean", "long_text_ratio_std", "long_text_ratio_max",
        "vertical_spread_mean", "vertical_spread_std", "vertical_spread_max",
        
        # Temporal (11)
        "num_frames_with_text",
        "num_frames_total",
        "persistence_ratio",
        "avg_bbox_movement",
        "bbox_std_x",
        "bbox_std_y",
        "avg_text_similarity",
        "text_change_rate",
        "max_consecutive_frames",
        "num_runs",
        "avg_run_length",
    ]
    
    def __init__(
        self,
        model_type: Literal['logistic', 'xgboost'] = 'logistic',
        random_state: int = 42
    ):
        """
        Initialize classifier.
        
        Args:
            model_type: 'logistic' ou 'xgboost'
            random_state: Seed para reproducibilidade
        """
        self.model_type = model_type
        self.random_state = random_state
        
        self.model = None
        self.scaler = None
        self.threshold = 0.5  # Inicial, tunado via ROC (Sprint 07)
        self.feature_names = self.FEATURE_NAMES
        
        self._initialize_model()
    
    def _initialize_model(self):
        """Inicializa modelo e scaler."""
        if self.model_type == 'logistic':
            # LogisticRegression com regulariza√ß√£o L2
            self.model = LogisticRegression(
                C=1.0,  # Regulariza√ß√£o (tunable via grid search)
                max_iter=1000,
                random_state=self.random_state,
                class_weight='balanced',  # Handle imbalanced dataset
            )
            # Padroniza√ß√£o necess√°ria para LogReg
            self.scaler = StandardScaler()
        
        elif self.model_type == 'xgboost':
            try:
                import xgboost as xgb
                self.model = xgb.XGBClassifier(
                    n_estimators=100,
                    max_depth=4,
                    learning_rate=0.1,
                    random_state=self.random_state,
                    use_label_encoder=False,
                    eval_metric='logloss',
                )
                # XGBoost n√£o precisa de scaling
                self.scaler = None
            except ImportError:
                raise ImportError(
                    "XGBoost not installed. Install via: pip install xgboost"
                )
        else:
            raise ValueError(f"Unsupported model_type: {self.model_type}")
    
    def train(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: Optional[np.ndarray] = None,
        y_val: Optional[np.ndarray] = None,
        verbose: bool = True
    ) -> Dict[str, float]:
        """
        Treina classificador e seleciona threshold √≥timo no validation set.
        
        Args:
            X_train: Features shape (N, 56)
            y_train: Labels shape (N,)
            X_val: Validation features (OBRIGAT√ìRIO para threshold tuning)
            y_val: Validation labels (OBRIGAT√ìRIO para threshold tuning)
            verbose: Se True, print m√©tricas
        
        Returns:
            Dict com m√©tricas de valida√ß√£o
        
        Note:
            - Valida schema de features (deve ser exatamente 56)
            - Treina modelo com StandardScaler (se LogReg)
            - Seleciona threshold √≥timo via max F1 no validation set
            - Threshold √© persistido em self.threshold
        """
        # Validate shapes
        assert X_train.shape[1] == 56, f"Expected 56 features, got {X_train.shape[1]}"
        assert len(self.FEATURE_NAMES) == 56, f"Feature schema mismatch: {len(self.FEATURE_NAMES)} names"
        
        # Validate feature vectors
        self.validate_feature_vector(X_train)
        if X_val is not None:
            self.validate_feature_vector(X_val)
        
        # Scale features (se necess√°rio)
        if self.scaler is not None:
            X_train_scaled = self.scaler.fit_transform(X_train)
            if X_val is not None:
                X_val_scaled = self.scaler.transform(X_val)
        else:
            X_train_scaled = X_train
            X_val_scaled = X_val
        
        # Train
        if self.model_type == 'xgboost' and X_val is not None:
            # XGBoost com early stopping
            self.model.fit(
                X_train_scaled,
                y_train,
                eval_set=[(X_val_scaled, y_val)],
                early_stopping_rounds=10,
                verbose=False
            )
        else:
            self.model.fit(X_train_scaled, y_train)
        
        # Evaluate on validation e selecionar threshold √≥timo
        if X_val is not None and y_val is not None:
            y_val_proba = self.model.predict_proba(X_val_scaled)[:, 1]
            
            # Selecionar threshold que maximiza F1 no validation set
            from sklearn.metrics import f1_score as compute_f1
            
            best_f1 = 0.0
            best_threshold = 0.5
            
            # Grid search de threshold (0.3 a 0.9, step 0.05)
            for threshold in np.arange(0.30, 0.91, 0.05):
                y_val_pred_temp = (y_val_proba >= threshold).astype(int)
                f1_temp = compute_f1(y_val, y_val_pred_temp, zero_division=0)
                
                if f1_temp > best_f1:
                    best_f1 = f1_temp
                    best_threshold = threshold
            
            # Persistir threshold √≥timo
            self.threshold = best_threshold
            
            # Recalcular m√©tricas com threshold √≥timo
            y_val_pred = (y_val_proba >= self.threshold).astype(int)
            
            metrics = {
                'accuracy': accuracy_score(y_val, y_val_pred),
                'precision': precision_score(y_val, y_val_pred, zero_division=0),
                'recall': recall_score(y_val, y_val_pred, zero_division=0),
                'f1': f1_score(y_val, y_val_pred, zero_division=0),
                'roc_auc': roc_auc_score(y_val, y_val_proba),
                'threshold': self.threshold,  # Threshold selecionado
            }
            
            if verbose:
                print("Validation Metrics:")
                for metric, value in metrics.items():
                    print(f"  {metric}: {value:.4f}")
                print(f"\nOptimal threshold selected: {self.threshold:.3f} (max F1={best_f1:.4f})")
            
            return metrics
        else:
            # AVISO: Sem validation set, usa threshold padr√£o 0.5
            if self.threshold is None:
                self.threshold = 0.5
                print("WARNING: No validation set provided. Using default threshold=0.5")
            return {}
    
    def predict_proba(self, features: np.ndarray) -> float:
        """
        Prediz probabilidade.
        
        Args:
            features: Feature vector shape (56,) ou (N, 56)
        
        Returns:
            Probability [0, 1] (ou array se N > 1)
        """
        if self.model is None:
            raise ValueError("Model not trained. Call train() or load() first.")
        
        # Reshape if single sample
        if features.ndim == 1:
            features = features.reshape(1, -1)
        
        # Scale
        if self.scaler is not None:
            features_scaled = self.scaler.transform(features)
        else:
            features_scaled = features
        
        # Predict
        proba = self.model.predict_proba(features_scaled)[:, 1]
        
        # Return scalar if single sample
        if proba.shape[0] == 1:
            return float(proba[0])
        return proba
    
    def predict(self, features: np.ndarray) -> bool:
        """
        Prediz classe (usa self.threshold aprendido no validation set).
        
        Args:
            features: Feature vector shape (56,) ou (N, 56)
        
        Returns:
            Boolean (ou array se N > 1)
        
        Note:
            Usa threshold selecionado durante treinamento (max F1 no validation).
            Se threshold n√£o foi definido, usa 0.5 (fallback).
        """
        if self.threshold is None:
            raise ValueError("Threshold not set. Train model first or set manually.")
        
        proba = self.predict_proba(features)
        
        if isinstance(proba, float):
            return proba >= self.threshold
        return proba >= self.threshold
    
    def get_feature_importance(self) -> Dict[str, float]:
        """
        Retorna import√¢ncia de features.
        
        Returns:
            Dict {feature_name: importance}
        
        Note:
            - LogisticRegression: coefficients (peso linear)
            - XGBoost: feature_importances_ (gain ou weight)
        """
        if self.model is None:
            raise ValueError("Model not trained.")
        
        if self.model_type == 'logistic':
            # Coefficients (abs para ranking)
            coef = np.abs(self.model.coef_[0])
        elif self.model_type == 'xgboost':
            coef = self.model.feature_importances_
        else:
            raise NotImplementedError
        
        importance = {
            name: float(score)
            for name, score in zip(self.feature_names, coef)
        }
        
        return importance
    
    def save(self, path: str, metadata: Optional[Dict] = None):
        """
        Salva modelo treinado com metadados.
        
        Args:
            path: Caminho do arquivo .pkl
            metadata: Metadados opcionais (dataset size, treino date, m√©tricas)
        
        Note:
            Usa joblib (mais eficiente que pickle para sklearn).
            Salva: modelo, scaler, threshold, schema version, feature names, metadata.
        """
        if self.model is None:
            raise ValueError("Model not trained.")
        
        if self.threshold is None:
            raise ValueError("Threshold not set. Train with validation set first.")
        
        # Create directory if not exists
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        # Preparar dados para salvar
        from datetime import datetime
        import joblib
        
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'threshold': self.threshold,
            'model_type': self.model_type,
            'feature_names': self.feature_names,
            'schema_version': self.schema_version,
            'trained_at': datetime.now().isoformat(),
            'metadata': metadata or {},
        }
        
        # Save com joblib (mais eficiente para sklearn)
        joblib.dump(model_data, path, compress=3)
        
        print(f"Model saved to {path}")
        print(f"  Schema version: {self.schema_version}")
        print(f"  Threshold: {self.threshold:.3f}")
        print(f"  Model type: {self.model_type}")
    
    def load(self, path: str):
        """
        Carrega modelo treinado.
        
        Args:
            path: Caminho do arquivo .pkl
        
        Raises:
            FileNotFoundError: Se arquivo n√£o existe
            ValueError: Se schema version incompat√≠vel
        """
        if not os.path.exists(path):
            raise FileNotFoundError(f"Model file not found: {path}")
        
        import joblib
        
        data = joblib.load(path)
        
        # Validar schema version
        loaded_schema = data.get('schema_version', '0.0')
        if loaded_schema != self.FEATURE_SCHEMA_VERSION:
            raise ValueError(
                f"Schema version mismatch: model={loaded_schema}, "
                f"current={self.FEATURE_SCHEMA_VERSION}. Retrain model."
            )
        
        self.model = data['model']
        self.scaler = data['scaler']
        self.threshold = data['threshold']
        self.model_type = data['model_type']
        self.feature_names = data['feature_names']
        self.schema_version = data['schema_version']
        
        print(f"Model loaded from {path}")
        print(f"  Schema version: {self.schema_version}")
        print(f"  Threshold: {self.threshold:.3f}")
        print(f"  Trained at: {data.get('trained_at', 'unknown')}")
```

---

#### Arquivo 3: `scripts/train_subtitle_classifier.py` (NOVO)

```python
"""
Script para treinar classificador de legendas (Sprint 06).

Usage:
  python scripts/train_subtitle_classifier.py --dataset data/labeled_videos.csv --output models/subtitle_classifier.pkl
"""
import argparse
from pathlib import Path
from typing import Dict, Tuple

import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.metrics import make_scorer, f1_score

from app.ml.subtitle_classifier import SubtitleClassifier


def load_dataset(csv_path: str) -> Tuple[np.ndarray, np.ndarray]:
    """
    Carrega dataset de v√≠deos rotulados.
    
    Args:
        csv_path: Caminho do CSV com features + ground truth
    
    Returns:
        X (features), y (labels)
    
    CSV Format:
        video_path,has_subtitles,num_text_boxes_mean,...,avg_run_length
        /path/video1.mp4,1,2.5,...,8.3
        /path/video2.mp4,0,0.8,...,1.2
    """
    df = pd.read_csv(csv_path)
    
    # Separar features e labels
    y = df['has_subtitles'].values
    X = df.drop(columns=['video_path', 'has_subtitles']).values
    
    print(f"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features")
    print(f"  Positive: {y.sum()} ({y.sum()/len(y)*100:.1f}%)")
    print(f"  Negative: {len(y) - y.sum()} ({(len(y)-y.sum())/len(y)*100:.1f}%)")
    
    return X, y


def main():
    parser = argparse.ArgumentParser(description='Train subtitle classifier')
    parser.add_argument('--dataset', required=True, help='Path to labeled dataset CSV')
    parser.add_argument('--output', default='models/subtitle_classifier.pkl', help='Output model path')
    parser.add_argument('--model-type', default='logistic', choices=['logistic', 'xgboost'])
    parser.add_argument('--n-folds', type=int, default=5, help='Number of CV folds (stratified)')
    parser.add_argument('--test-size', type=float, default=0.20, help='Test set size (hold-out)')
    args = parser.parse_args()
    
    # Load dataset
    X, y = load_dataset(args.dataset)
    
    # Hold-out test set (20% fixo para avalia√ß√£o final)
    from sklearn.model_selection import train_test_split
    
    X_trainval, X_test, y_trainval, y_test = train_test_split(
        X, y,
        test_size=args.test_size,
        stratify=y,
        random_state=42
    )
    
    print(f"\nSplit:")
    print(f"  Train+Val: {len(X_trainval)} samples (will use {args.n_folds}-fold CV)")
    print(f"  Test:      {len(X_test)} samples (hold-out)")
    
    # Stratified K-Fold Cross-Validation no train+val
    print(f"\n{'='*60}")
    print(f"Stratified {args.n_folds}-Fold Cross-Validation")
    print(f"{'='*60}")
    
    cv_f1_scores = []
    cv_precision_scores = []
    cv_recall_scores = []
    
    skf = StratifiedKFold(n_splits=args.n_folds, shuffle=True, random_state=42)
    
    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_trainval, y_trainval), 1):
        print(f"\nFold {fold_idx}/{args.n_folds}:")
        
        X_train_fold = X_trainval[train_idx]
        y_train_fold = y_trainval[train_idx]
        X_val_fold = X_trainval[val_idx]
        y_val_fold = y_trainval[val_idx]
        
        print(f"  Train: {len(X_train_fold)} samples")
        print(f"  Val:   {len(X_val_fold)} samples")
        
        # Treinar modelo no fold
        clf_fold = SubtitleClassifier(model_type=args.model_type)
        metrics_fold = clf_fold.train(
            X_train_fold, y_train_fold,
            X_val_fold, y_val_fold,
            verbose=False
        )
        
        cv_f1_scores.append(metrics_fold['f1'])
        cv_precision_scores.append(metrics_fold['precision'])
        cv_recall_scores.append(metrics_fold['recall'])
        
        print(f"  Precision: {metrics_fold['precision']:.4f}")
        print(f"  Recall:    {metrics_fold['recall']:.4f}")
        print(f"  F1:        {metrics_fold['f1']:.4f}")
        print(f"  Threshold: {metrics_fold['threshold']:.3f}")
    
    # Reportar m√©tricas agregadas com intervalo
    print(f"\n{'='*60}")
    print(f"Cross-Validation Results (mean ¬± std):")
    print(f"{'='*60}")
    print(f"  Precision: {np.mean(cv_precision_scores):.4f} ¬± {np.std(cv_precision_scores):.4f}")
    print(f"  Recall:    {np.mean(cv_recall_scores):.4f} ¬± {np.std(cv_recall_scores):.4f}")
    print(f"  F1:        {np.mean(cv_f1_scores):.4f} ¬± {np.std(cv_f1_scores):.4f}")
    
    # Treinar modelo final em TODO o trainval (ap√≥s CV validar que n√£o h√° overfitting)
    print(f"\n{'='*60}")
    print(f"Training final model on full train+val set...")
    print(f"{'='*60}")
    
    # Split interno para threshold selection (80/20 do trainval)
    X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(
        X_trainval, y_trainval,
        test_size=0.20,
        stratify=y_trainval,
        random_state=42
    )
    
    print(f"  Final train: {len(X_train_final)} samples")
    print(f"  Final val:   {len(X_val_final)} samples (for threshold selection)")
    
    # Train final classifier
    clf = SubtitleClassifier(model_type=args.model_type)
    val_metrics = clf.train(X_train_final, y_train_final, X_val_final, y_val_final, verbose=True)
    
    # Evaluate on hold-out test set
    print(f"\n{'='*60}")
    print(f"Hold-Out Test Set Evaluation:")
    print(f"{'='*60}")
    
    y_test_pred = clf.predict(X_test)
    y_test_proba = clf.predict_proba(X_test)
    
    from sklearn.metrics import classification_report
    print(classification_report(y_test, y_test_pred, target_names=['No Subtitle', 'Has Subtitle']))
    
    # Feature importance
    print(f"\n{'='*60}")
    print(f"Top 15 Most Important Features:")
    print(f"{'='*60}")
    
    importance = clf.get_feature_importance()
    for i, (feature, score) in enumerate(sorted(importance.items(), key=lambda x: x[1], reverse=True)[:15], 1):
        print(f"  {i:2d}. {feature:40s}: {score:.4f}")
    
    # Save model com metadados
    metadata = {
        'dataset_size': len(X),
        'train_size': len(X_train_final),
        'val_size': len(X_val_final),
        'test_size': len(X_test),
        'cv_folds': args.n_folds,
        'cv_f1_mean': float(np.mean(cv_f1_scores)),
        'cv_f1_std': float(np.std(cv_f1_scores)),
        'test_f1': float(f1_score(y_test, y_test_pred, zero_division=0)),
        'test_precision': float(precision_score(y_test, y_test_pred, zero_division=0)),
        'test_recall': float(recall_score(y_test, y_test_pred, zero_division=0)),
    }
    
    clf.save(args.output, metadata=metadata)
    print(f"\n‚úÖ Model saved to {args.output}")
    print(f"   CV F1: {metadata['cv_f1_mean']:.4f} ¬± {metadata['cv_f1_std']:.4f}")
    print(f"   Test F1: {metadata['test_f1']:.4f}")


if __name__ == '__main__':
    main()
```

---

#### Arquivo 4: `tests/test_feature_schema.py` (NOVO)

**Teste: Valida√ß√£o do Schema de Features**

```python
"""
Testes de valida√ß√£o do schema de features (Sprint 06).

Garante que feature extraction gera exatamente 56 features na ordem correta.
"""
import pytest
import numpy as np

from app.ml.subtitle_classifier import SubtitleClassifier
from app.video_processing.video_validator import VideoValidator
from app.models.temporal_features import TemporalFeatures


def test_feature_schema_length():
    """Testa que schema tem exatamente 56 features."""
    feature_names = SubtitleClassifier.FEATURE_NAMES
    
    assert len(feature_names) == 56, f"Expected 56 features, got {len(feature_names)}"
    
    # 45 spatial aggregated (15 base √ó 3 stats)
    spatial_count = sum(1 for name in feature_names if any(stat in name for stat in ['_mean', '_std', '_max']) and 'frames' not in name)
    assert spatial_count == 45, f"Expected 45 spatial aggregated, got {spatial_count}"
    
    # 11 temporal
    temporal_count = sum(1 for name in feature_names if name in SubtitleClassifier.TEMPORAL_FEATURES)
    assert temporal_count == 11, f"Expected 11 temporal, got {temporal_count}"


def test_feature_schema_uniqueness():
    """Testa que n√£o h√° features duplicadas."""
    feature_names = SubtitleClassifier.FEATURE_NAMES
    
    unique_names = set(feature_names)
    assert len(unique_names) == len(feature_names), "Duplicate feature names found"


def test_feature_vector_validation():
    """Testa que valida√ß√£o de feature vector funciona."""
    # Feature vector v√°lido (56)
    valid_features = np.random.rand(56)
    SubtitleClassifier.validate_feature_vector(valid_features)  # N√£o deve lan√ßar erro
    
    # Feature vector inv√°lido (55)
    invalid_features = np.random.rand(55)
    with pytest.raises(ValueError, match="Expected 56 features"):
        SubtitleClassifier.validate_feature_vector(invalid_features)
    
    # Feature vector inv√°lido (57)
    invalid_features = np.random.rand(57)
    with pytest.raises(ValueError, match="Expected 56 features"):
        SubtitleClassifier.validate_feature_vector(invalid_features)


def test_build_feature_vector_shape():
    """Testa que _build_feature_vector gera vetor de 56 features."""
    validator = VideoValidator()
    
    # Mock spatial features aggregated (45)
    spatial_agg = {
        "mean": {feat: np.random.rand() for feat in SubtitleClassifier.SPATIAL_BASE_FEATURES},
        "std": {feat: np.random.rand() for feat in SubtitleClassifier.SPATIAL_BASE_FEATURES},
        "max": {feat: np.random.rand() for feat in SubtitleClassifier.SPATIAL_BASE_FEATURES},
    }
    
    # Mock temporal features (11)
    temporal = TemporalFeatures(
        num_frames_with_text=15,
        num_frames_total=30,
        persistence_ratio=0.50,
        avg_bbox_movement=0.02,
        bbox_std_x=0.01,
        bbox_std_y=0.008,
        avg_text_similarity=0.85,
        text_change_rate=0.15,
        max_consecutive_frames=10,
        num_runs=3,
        avg_run_length=5.0,
    )
    
    # Build feature vector
    feature_vector = validator._build_feature_vector(spatial_agg, temporal)
    
    # Validar shape
    assert feature_vector.shape == (56,), f"Expected shape (56,), got {feature_vector.shape}"
    
    # Validar schema
    SubtitleClassifier.validate_feature_vector(feature_vector)


def test_temporal_features_to_array_length():
    """Testa que TemporalFeatures.to_array() retorna 11 features."""
    temporal = TemporalFeatures(
        num_frames_with_text=15,
        num_frames_total=30,
        persistence_ratio=0.50,
        avg_bbox_movement=0.02,
        bbox_std_x=0.01,
        bbox_std_y=0.008,
        avg_text_similarity=0.85,
        text_change_rate=0.15,
        max_consecutive_frames=10,
        num_runs=3,
        avg_run_length=5.0,
    )
    
    temporal_array = temporal.to_array()
    
    assert temporal_array.shape == (11,), f"Expected shape (11,), got {temporal_array.shape}"
    assert len(SubtitleClassifier.TEMPORAL_FEATURES) == 11, "Temporal feature schema mismatch"
```

---

#### Arquivo 5: `app/video_processing/video_validator.py` (MODIFICAR) (MODIFICAR)

**Nova Fun√ß√£o: `_build_feature_vector`**

```python
def _build_feature_vector(
    self,
    spatial_features_aggregated: dict,
    temporal_features: TemporalFeatures
) -> np.ndarray:
    """
    Constr√≥i feature vector [56] para classificador.
    
    Args:
        spatial_features_aggregated: Dict com mean/std/max de 15 features espaciais
        temporal_features: TemporalFeatures dataclass
    
    Returns:
        Feature vector shape (56,)
    
    Note:
        Ordem das features:
          [0:45]  : spatial aggregated (mean/std/max √ó 15)
          [45:56] : temporal (11 features)
    """
    # Spatial aggregated (45)
    spatial_vector = []
    for feature_name in [
        "num_text_boxes", "total_text_length", "avg_confidence",
        "max_confidence", "total_area", "bottom_percentage",
        "vertical_center", "horizontal_center", "centered_ratio",
        "avg_aspect_ratio", "avg_bbox_width", "avg_bbox_height",
        "avg_text_length", "long_text_ratio", "vertical_spread"
    ]:
        spatial_vector.extend([
            spatial_features_aggregated["mean"][feature_name],
            spatial_features_aggregated["std"][feature_name],
            spatial_features_aggregated["max"][feature_name],
        ])
    
    # Temporal (11)
    temporal_vector = temporal_features.to_array()  # shape (11,)
    
    # Concatenate
    feature_vector = np.concatenate([spatial_vector, temporal_vector])
    
    assert feature_vector.shape == (56,), f"Expected shape (56,), got {feature_vector.shape}"
    
    return feature_vector
```

---

**Modifica√ß√£o: `has_embedded_subtitles` - Usar Classifier**

```python
def has_embedded_subtitles(
    self, 
    video_path: str, 
    timeout: int = 60,
    roi_bottom_percent: float = 0.60,
    preprocessing_mode: str = 'clahe',
    log_features: bool = True,
    use_temporal_aggregation: bool = True,
    use_classifier: bool = True,  # ‚Üê NOVO: Sprint 06
    classifier_path: Optional[str] = None  # Path to trained model
) -> Tuple[bool, float, str]:
    """
    Detecta legendas embutidas em v√≠deo.
    
    Args:
        ... (argumentos anteriores)
        use_classifier: Se True, usa ML classifier (Sprint 06)
        classifier_path: Caminho do modelo treinado (.pkl)
    
    Returns:
        (has_subtitles, confidence/probability, text_sample)
    """
    # ... (c√≥digo anterior: extract frames, compute features) ...
    
    # Sprint 04: Agregar features espaciais
    if log_features and features_per_frame:
        spatial_features_aggregated = self._aggregate_features_per_video(features_per_frame)
    else:
        spatial_features_aggregated = None
    
    # Sprint 05: Temporal aggregation
    if use_temporal_aggregation and frame_data:
        temporal_features = self._compute_temporal_features(
            frame_data,
            frame_width,
            frame_height
        )
    else:
        temporal_features = None
    
    # Sprint 06: ML Classifier
    if use_classifier and spatial_features_aggregated and temporal_features:
        # Load classifier (cache in instance)
        if not hasattr(self, '_classifier') or self._classifier is None:
            from app.ml.subtitle_classifier import SubtitleClassifier
            
            if classifier_path is None:
                classifier_path = "models/subtitle_classifier.pkl"
            
            self._classifier = SubtitleClassifier()
            self._classifier.load(classifier_path)
            
            logger.info("ML classifier loaded", extra={"model_path": classifier_path})
        
        # Build feature vector
        feature_vector = self._build_feature_vector(
            spatial_features_aggregated,
            temporal_features
        )
        
        # Predict
        probability = self._classifier.predict_proba(feature_vector)
        has_subtitles = self._classifier.predict(feature_vector)
        
        # Log
        if log_features:
            logger.info(
                "ML classifier prediction",
                extra={
                    "video_hash": hashlib.sha256(video_path.encode()).hexdigest()[:16],
                    "probability": probability,
                    "has_subtitles": has_subtitles,
                    "threshold": self._classifier.threshold,
                }
            )
        
        return has_subtitles, probability, best_text_sample
    
    # Fallback: Sprint 05 heuristic (se classifier desabilitado)
    else:
        # Temporal score baseado em runs
        if use_temporal_aggregation and temporal_features:
            persistence_component = temporal_features.persistence_ratio
            run_component = min(temporal_features.avg_run_length / 10.0, 1.0)
            
            temporal_score = 0.5 * persistence_component + 0.5 * run_component
            
            # Boost/penalize
            if temporal_features.max_consecutive_frames >= 5:
                temporal_score *= 1.3
            if temporal_features.bbox_std_y > 0.05:
                temporal_score *= 0.6
            if temporal_features.avg_text_similarity < 0.60:
                temporal_score *= 0.8
            if temporal_features.num_runs >= 2 and temporal_features.avg_run_length >= 3:
                temporal_score *= 1.2
            
            temporal_score = min(temporal_score, 1.0)
            
            # Combined score: 60% spatial, 40% temporal
            final_confidence = 0.6 * max_spatial_confidence + 0.4 * temporal_score
            final_confidence = min(final_confidence, 1.0)
        else:
            final_confidence = max_spatial_confidence
        
        # Decision
        has_subtitles = final_confidence >= 0.85
        
        return has_subtitles, final_confidence, best_text_sample
```

---

### Resumo das Mudan√ßas

| Arquivo | Fun√ß√µes Afetadas | Tipo Mudan√ßa | Linhas |
|---------|------------------|-------------|--------|
| `app/ml/__init__.py` **(NOVO)** | Module init | Criar m√≥dulo ML | +5 |
| `app/ml/subtitle_classifier.py` **(NOVO)** | `SubtitleClassifier` class completa + schema validation | Criar classificador | +400 |
| `scripts/train_subtitle_classifier.py` **(NOVO)** | Script de treinamento com Stratified K-Fold CV | CLI para treinar | +180 |
| `tests/test_feature_schema.py` **(NOVO)** | Testes de valida√ß√£o de schema de features | Garantir consist√™ncia | +60 |
| `video_validator.py` | `_build_feature_vector` **(NOVA)** | Construir input do classificador | +50 |
| `video_validator.py` | `has_embedded_subtitles` **(MODIFICADA)** | Integrar classificador | +45 |
| **TOTAL** | | | **~740 linhas** |

---

## 5Ô∏è‚É£ Plano de Valida√ß√£o

### Como Medir Impacto?

**M√©trica Principal**: **Precision + Recall** (vs Sprint 05)

---

### M√©todo

**1. Coletar Dataset Rotulado**

```bash
# Manual labeling de 100+ v√≠deos
$ python scripts/label_videos.py --input dataset/unlabeled/ --output dataset/labeled_videos.csv

Resultado esperado:
  - 100-200 v√≠deos
  - 50-60% positivos (com legenda)
  - 40-50% negativos (sem legenda)
  - Ground truth: revis√£o manual (2 annotators, Cohen's Kappa > 0.85)
```

**Nota**: Dataset √© **cr√≠tico** para Sprint 06. Qualidade do modelo depende de:
- Diversidade de v√≠deos (resolu√ß√µes, idiomas, tipos)
- Balan√ßo de classes (50/50 ideal)
- Qualidade da rotula√ß√£o (inter-annotator agreement)

---

**2. Extrair Features de Todos os V√≠deos**

```bash
$ python scripts/extract_features_for_ml.py --input dataset/labeled_videos.csv --output dataset/features.csv

# Para cada v√≠deo:
#   1. Run Sprint 05 pipeline
#   2. Extract spatial features aggregated (45)
#   3. Extract temporal features (11)
#   4. Save to CSV: [video_path, has_subtitles, feature1, ..., feature56]
```

---

**3. Treinar Classificador**

```bash
$ python scripts/train_subtitle_classifier.py \
    --dataset dataset/features.csv \
    --output models/subtitle_classifier_logistic.pkl \
    --model-type logistic

Esperado:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TRAINING LOGISTIC REGRESSION CLASSIFIER  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Dataset: 150 samples (90 train, 30 val, 30 test)
‚îÇ 
‚îÇ Validation Metrics:
‚îÇ   accuracy:  0.9667
‚îÇ   precision: 0.9500
‚îÇ   recall:    0.9500
‚îÇ   f1:        0.9500
‚îÇ   roc_auc:   0.9850
‚îÇ 
‚îÇ Test Metrics:
‚îÇ   accuracy:  0.9667
‚îÇ   precision: 0.9600
‚îÇ   recall:    0.9600
‚îÇ   f1:        0.9600
‚îÇ 
‚îÇ Top 10 Features:
‚îÇ   1. persistence_ratio:              0.8523
‚îÇ   2. avg_run_length:                 0.7234
‚îÇ   3. bbox_std_y:                     0.6891
‚îÇ   4. vertical_spread_mean:           0.5432
‚îÇ   5. bottom_percentage_mean:         0.4987
‚îÇ   6. max_consecutive_frames:         0.4654
‚îÇ   7. avg_confidence_max:             0.3987
‚îÇ   8. centered_ratio_mean:            0.3654
‚îÇ   9. num_runs:                       0.3421
‚îÇ  10. total_area_mean:                0.2987
‚îÇ 
‚îÇ ‚úÖ Model saved to models/subtitle_classifier_logistic.pkl
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

**4. A/B Test: Heuristic vs Classifier**

```bash
# Baseline: Sprint 05 (heuristic)
$ python measure_baseline.py --dataset test_dataset/ --use-classifier false

# Sprint 06: Classifier
$ python measure_baseline.py --dataset test_dataset/ --use-classifier true --classifier-path models/subtitle_classifier_logistic.pkl
```

---

**5. Post-Implementation (Sprint 06)**

```bash
$ python measure_baseline.py --dataset test_dataset/ --version sprint06

Esperado:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ POST-SPRINT-06 METRICS (classifier=ON)  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Recall: 97% (+2%) ‚úÖ                    ‚îÇ
‚îÇ Precis√£o: 97% (+2%) ‚úÖ                  ‚îÇ
‚îÇ FPR: 0.5% (-0.5%) ‚úÖ                    ‚îÇ
‚îÇ F1 Score: 97% (+2%) ‚úÖ‚úÖ                ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ Classifier impact:                      ‚îÇ
‚îÇ   - FP removed: 50% (via feature weight)‚îÇ
‚îÇ   - FN rescued: 40% (OCR baixo + temp)  ‚îÇ
‚îÇ   - Top feature: persistence_ratio      ‚îÇ
‚îÇ   - Model: LogisticRegression (L2)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

**6. Feature Importance Analysis**

```python
# Entender quais features mais contribuem
importance = classifier.get_feature_importance()

# Plot
import matplotlib.pyplot as plt
import seaborn as sns

top_20 = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:20]
features, scores = zip(*top_20)

plt.figure(figsize=(10, 8))
sns.barplot(x=scores, y=features)
plt.title("Top 20 Feature Importance (LogisticRegression)")
plt.xlabel("Absolute Coefficient")
plt.tight_layout()
plt.savefig("feature_importance_sprint06.png")
```

**Insight esperado:**
- Temporal features (persistence_ratio, avg_run_length) > Spatial
- bbox_std_y muito importante (Y est√°vel = legenda)
- Confidence OCR sozinho n√£o √© top-1 (|coef| < persistence_ratio)

---

**7. Erro Analysis**

```python
# Coletar FP e FN do classificador
errors = []

for video in test_set:
    y_true = video.has_subtitles
    y_pred = classifier.predict(video.features)
    
    if y_true != y_pred:
        errors.append({
            "video": video.path,
            "y_true": y_true,
            "y_pred": y_pred,
            "probability": classifier.predict_proba(video.features),
            "features": video.features,
        })

# Analisar padr√µes
fp_errors = [e for e in errors if e["y_true"] == 0 and e["y_pred"] == 1]
fn_errors = [e for e in errors if e["y_true"] == 1 and e["y_pred"] == 0]

print(f"False Positives: {len(fp_errors)}")
for e in fp_errors[:5]:
    print(f"  {e['video']}: prob={e['probability']:.2f}")
    print(f"    persistence_ratio={e['features'][47]:.2f}")  # Index 47

print(f"False Negatives: {len(fn_errors)}")
for e in fn_errors[:5]:
    print(f"  {e['video']}: prob={e['probability']:.2f}")
    print(f"    avg_confidence_mean={e['features'][6]:.2f}")  # Index 6
```

---

### M√©trica de Valida√ß√£o

| M√©trica | Threshold | Status |
|---------|-----------|--------|
| **Œî Recall** | ‚â• +1% vs Sprint 05 | ‚úÖ Aceita sprint |
| **Œî Precis√£o** | ‚â• +1% vs Sprint 05 | ‚úÖ Aceita sprint |
| **F1 Score** | ‚â• 96% | ‚úÖ Aceita sprint |
| **ROC AUC** | ‚â• 0.97 | ‚úÖ Aceita sprint (valida√ß√£o set) |
| **Feature Informativeness** | Top-3 features |r| > 0.50 | ‚úÖ Valida hip√≥tese |

---

## 6Ô∏è‚É£ Risco & Trade-offs

### Riscos Identificados

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|--------------|--------|-----------|
| **Dataset pequeno** (<100 v√≠deos) | 40% | ALTO | Coletar 150-200 v√≠deos; usar Stratified K-Fold CV para melhor uso dos dados |
| **Dataset desbalanceado** (80% positivos) | 30% | M√âDIO | Use `class_weight='balanced'` em LogReg; amostragem estratificada |
| **Overfitting** (alta performance em val, baixa em test) | 25% | ALTO | Regulariza√ß√£o L2 (C=1.0); validar em hold-out set; early stopping (XGBoost) |
| **Features n√£o-informativas** (|r| < 0.30) | 15% | M√âDIO | Feature selection via correlation; remover features redundantes |
| **Lat√™ncia aumenta** (inference ~10ms vs 1ms) | 20% | BAIXO | Aceit√°vel; LogReg √© r√°pido (<1ms); XGBoost ~5ms |

---

### Trade-offs

#### Trade-off 1: LogisticRegression vs XGBoost

**Op√ß√£o A**: LogisticRegression ‚Üê **RECOMENDADO Sprint 06 v1**
- ‚úÖ R√°pido (train <1s, inference <1ms)
- ‚úÖ Interpret√°vel (coefficients = import√¢ncia)
- ‚úÖ Simples (poucos hyperparameters)
- ‚ùå Linear (n√£o captura intera√ß√µes n√£o-lineares)

**Op√ß√£o B**: XGBoost
- ‚úÖ Mais poderoso (captura n√£o-linearidades)
- ‚úÖ Melhor performance (se h√° intera√ß√µes complexas)
- ‚ùå Mais lento (train ~10s, inference ~5ms)
- ‚ùå Menos interpret√°vel (√°rvore = black box)
- ‚ùå Mais hyperparameters (n_estimators, max_depth, learning_rate)

‚Üí **Decis√£o**: LogReg para Sprint 06 v1 (baseline).  
‚Üí XGBoost como experimento comparativo (se LogReg F1 < 96%).

---

#### Trade-off 2: Feature Scaling

**Op√ß√£o A**: StandardScaler (LogReg) ‚Üê **OBRIGAT√ìRIO**
- ‚úÖ LogReg precisa de features normalizadas
- ‚úÖ Evita features com range maior dominarem
- ‚ùå Adiciona lat√™ncia m√≠nima (~0.1ms)

**Op√ß√£o B**: Sem scaling (XGBoost)
- ‚úÖ XGBoost √© tree-based (n√£o precisa scaling)
- ‚úÖ Menos preprocessing
- ‚ùå N√£o aplic√°vel a LogReg

‚Üí **Decis√£o**: Usar StandardScaler para LogReg.

---

#### Trade-off 3: Dataset Size

**Op√ß√£o A**: 100 v√≠deos (m√≠nimo) ‚Üê **ACEIT√ÅVEL**
- ‚úÖ Vi√°vel coletar em 2-3 dias
- ‚ùå Pode ter overfitting (se 60/20/20 split ‚Üí 60 train samples)

**Op√ß√£o B**: 200 v√≠deos (ideal)
- ‚úÖ Mais robusto (120 train samples)
- ‚úÖ Melhor generaliza√ß√£o
- ‚ùå Mais trabalhoso (4-5 dias de labeling)

**Op√ß√£o C**: 50 v√≠deos (insuficiente)
- ‚ùå Alto risco de overfitting
- ‚ùå N√£o recomendado

‚Üí **Decis√£o**: Alvo 150-200 v√≠deos, m√≠nimo 100.  
‚Üí Se <100: considerar semi-supervised (pseudo-labeling em unlabeled).

---

#### Trade-off 4: Threshold

**Op√ß√£o A**: threshold learned via max F1 no validation set ‚Üê **IMPLEMENTADO Sprint 06**
- ‚úÖ Otimizado para maximizar F1
- ‚úÖ Selecionado automaticamente durante treinamento
- ‚úÖ Persistido no modelo
- ‚úÖ Grid search de 0.30 a 0.90 (step 0.05)

**Op√ß√£o B**: threshold=0.5 (default fixo)
- ‚ùå N√£o otimizado
- ‚ùå Pode n√£o ser √≥timo para F1
- ‚ùå N√£o recomendado

‚Üí **Decis√£o**: Threshold learned (Op√ß√£o A) j√° implementado na Sprint 06.  
‚Üí Sprint 07 far√° calibra√ß√£o adicional (Platt/Isotonic) se necess√°rio.

---

## 7Ô∏è‚É£ Crit√©rio de Aceite da Sprint

### Criterios T√©cnicos de Aceita√ß√£o

```
‚úÖ CR√çTICO (MUST HAVE)
  ‚ñ° SubtitleClassifier implementado (LogisticRegression)
  ‚ñ° Dataset rotulado coletado (‚â•100 v√≠deos)
  ‚ñ° Features extra√≠das para dataset (56 features por v√≠deo)
  ‚ñ° Modelo treinado (train/val/test split 60/20/20)
  ‚ñ° Classifier integrado em has_embedded_subtitles()
  ‚ñ° Fallback para heur√≠stica (se classifier desabilitado)
  ‚ñ° No regression em recall/precision vs Sprint 05

‚úÖ IMPORTANTE (SHOULD HAVE)
  ‚ñ° Recall: ‚â• +1% vs Sprint 05 (ou mant√©m 95%)
  ‚ñ° Precis√£o: ‚â• +1% vs Sprint 05 (ou mant√©m 95%)
  ‚ñ° F1 Score: ‚â• 96%
  ‚ñ° ROC AUC: ‚â• 0.97 (validation set)
  ‚ñ° Top-3 features: |r| > 0.50 com ground truth
  ‚ñ° Feature importance analysis (plot + interpreta√ß√£o)

‚úÖ NICE TO HAVE (COULD HAVE)
  ‚ñ° XGBoost como experimento comparativo
  ‚ñ° Grid search de hyperparameters (C, max_depth)
  ‚ñ° An√°lise de erros (FP/FN patterns)
  ‚ñ° Calibration plot (probabilidades calibradas)
```

### Defini√ß√£o de "Sucesso" para Sprint 06

**Requisito de Aprova√ß√£o:**

1. ‚úÖ C√≥digo completo (SubtitleClassifier + integration)
2. ‚úÖ Dataset ‚â•100 v√≠deos rotulados (ground truth manual)
3. ‚úÖ F1 Score: ‚â• 96% (validation set)
4. ‚úÖ ROC AUC: ‚â• 0.97
5. ‚úÖ Recall: ‚â• 95% (no drop vs Sprint 05)
6. ‚úÖ Precis√£o: ‚â• 95% (no drop vs Sprint 05)
7. ‚úÖ Feature importance: temporal features no top-5
8. ‚úÖ Inference lat√™ncia: < +10ms (aceit√°vel)
9. ‚úÖ Fallback funcional (degrada√ß√£o graceful se modelo falha)
10. ‚úÖ C√≥digo review aprovado (2 reviewers)
11. ‚úÖ Testes unit√°rios: test_subtitle_classifier.py (coverage 95%)

---

### Checklist de Implementa√ß√£o

```
Dataset Phase:
  ‚òê Coletar 100-200 v√≠deos (diversidade: resolu√ß√µes, idiomas, tipos)
  ‚òê Rotular manualmente (ground truth: 2 annotators, Cohen's Kappa > 0.85)
  ‚òê Validar balan√ßo de classes (50/50 ideal)
  ‚òê Extrair features via Sprint 05 pipeline
  ‚òê Validar schema: 56 features por v√≠deo (45+11)
  ‚òê Salvar em CSV: [video_path, has_subtitles, feature1, ..., feature56]

Code Implementation:
  ‚òê app/ml/__init__.py criado
  ‚òê app/ml/subtitle_classifier.py implementado (~400 linhas)
    ‚òê FEATURE_SCHEMA_VERSION congelado
    ‚òê SPATIAL_BASE_FEATURES (15) definido
    ‚òê TEMPORAL_FEATURES (11) definido
    ‚òê validate_feature_vector() implementado
  ‚òê scripts/train_subtitle_classifier.py implementado (~180 linhas)
    ‚òê Stratified K-Fold CV (5-fold)
    ‚òê Hold-out test set (20%)
    ‚òê Threshold selection via max F1
  ‚òê tests/test_feature_schema.py implementado (~60 linhas)
    ‚òê test_feature_schema_length()
    ‚òê test_feature_vector_validation()
    ‚òê test_build_feature_vector_shape()
  ‚òê video_validator.py: _build_feature_vector() implementada
  ‚òê video_validator.py: has_embedded_subtitles() integra classifier
  ‚òê Fallback para heur√≠stica (se classifier=False)

Training & Validation:
  ‚òê Stratified 5-Fold CV no train+val (reportar mean ¬± std)
  ‚òê Treinar LogisticRegression (C=1.0, class_weight='balanced')
  ‚òê Selecionar threshold via max F1 no validation set
  ‚òê Validar em hold-out test set (F1 ‚â• 96%, ROC AUC ‚â• 0.97)
  ‚òê Salvar modelo com joblib: models/subtitle_classifier.pkl
  ‚òê Persistir threshold, schema_version, metadata
  ‚òê Feature importance analysis
  ‚òê Plot top-20 features

Testing:
  ‚òê Testes escritos:
    ‚òê test_subtitle_classifier.py (train, predict, save/load)
    ‚òê test_classifier_integration.py (video_validator integration)
    ‚òê test_fallback.py (degrada√ß√£o se modelo n√£o carrega)
  ‚òê Coverage ‚â• 95%

Documentation:
  ‚òê Docstrings completos
  ‚òê README: instru√ß√µes de treinamento
  ‚òê Feature importance report (interpreta√ß√£o)

Deployment:
  ‚òê Code review feito
  ‚òê A/B test Sprint 05 (heuristic) vs Sprint 06 (classifier)
  ‚òê F1 validado (‚â• 96%)
  ‚òê Lat√™ncia validada (< +10ms)
  ‚òê Aprova√ß√£o de PM/Tech Lead
  ‚òê Merge para main
  ‚òê Deploy em produ√ß√£o (10% tr√°fego, A/B test)
  ‚òê Monitoramento 48h (F1 + lat√™ncia)
  ‚òê 100% rollout se F1 ‚â• 96%
```

---

## üìã Resumo da Sprint

| Aspecto | Detalhe |
|---------|---------|
| **Objetivo** | Substituir heur√≠sticas H1-H6 por classificador ML treinado |
| **Problema** | Pesos fixos arbitr√°rios (1.3, 1.1, 0.8) n√£o otimizados, desperdi√ßam 50 features |
| **Solu√ß√£o** | Treinar LogisticRegression em 56 features **com schema fixo e validado** |
| **Impacto** | +1-2% precision/recall (conservador), +2-5% (realista) |
| **Arquitetura** | SubtitleClassifier class ‚Üí treina com K-Fold CV ‚Üí prediz probabilidade |
| **Risco** | M√âDIO (depende dataset quality, size ‚â•90 v√≠deos p/ CV) |
| **Esfor√ßo** | ~10-12h (dataset labeling 50%, code 40%, validation 10%) |
| **Lat√™ncia** | +1-5ms (LogReg inference, aceit√°vel) |
| **Linhas de c√≥digo** | ~740 linhas (SubtitleClassifier + scripts + tests + integration) |
| **Features usadas** | **56 (schema fixo v1.0): 45 spatial + 11 temporal** |
| **Valida√ß√£o** | **Stratified 5-Fold CV + hold-out test (20%)** |
| **Threshold** | **Selecionado via max F1 no validation set (persistido no modelo)** |
| **Depend√™ncias** | Sprint 05 (temporal features), Dataset rotulado (100+ v√≠deos) |
| **Pr√≥xima Sprint** | Sprint 07 (ROC Calibration & Threshold Tuning Avan√ßado) |

---

## üöÄ Pr√≥ximos Passos

1. ‚úÖ Sprint 06 documentada
2. ‚è≥ **Coletar dataset rotulado** (100-200 v√≠deos) - CR√çTICO!
3. ‚è≥ Extrair features (Sprint 05 pipeline)
4. ‚è≥ Treinar classificador (LogisticRegression)
5. üîÑ Validar Sprint 06 (F1 ‚â• 96%, ROC AUC ‚â• 0.97)
6. üìä Feature importance analysis
7. ‚û°Ô∏è Proceder para Sprint 07 (ROC Calibration & Threshold Tuning)

---

**Nota Final:**

Sprint 06 √© **incremental** mas **fundamental**:
- Remove arbitrariedade de heur√≠sticas
- Aprende pesos √≥timos automaticamente
- Prepara ground para Sprint 07 (threshold tuning via ROC)
- Permite retreinamento cont√≠nuo (melhoria iterativa)

**Dataset √© o gargalo cr√≠tico**: sem 100+ v√≠deos rotulados com qualidade, modelo n√£o generaliza.

Investimento em dataset labeling (2-3 dias) compensa via melhoria de +1-5% F1 + manutenibilidade futura.
