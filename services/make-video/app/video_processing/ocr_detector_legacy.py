"""
OCR Detection Module

Detecta presen√ßa de legendas em frames usando EasyOCR com otimiza√ß√µes avan√ßadas
"""

import os
import cv2
import numpy as np
import easyocr
import re
import logging
from typing import Tuple, Optional, List, Set
from dataclasses import dataclass
from app.infrastructure.metrics import ocr_confidence_distribution

logger = logging.getLogger(__name__)


def _get_ocr_gpu_setting() -> bool:
    """
    Retorna configura√ß√£o de GPU para EasyOCR a partir do ambiente.
    
    Returns:
        True se OCR_USE_GPU=true (case-insensitive), False caso contr√°rio
    """
    gpu_env = os.getenv('OCR_USE_GPU', 'false').lower().strip()
    use_gpu = gpu_env in ('true', '1', 'yes', 'on')
    
    if use_gpu:
        # Verificar se CUDA est√° dispon√≠vel
        try:
            import torch
            cuda_available = torch.cuda.is_available()
            if not cuda_available:
                logger.warning("‚ö†Ô∏è OCR_USE_GPU=true mas CUDA n√£o dispon√≠vel. Usando CPU.")
                return False
            logger.info(f"üéÆ GPU detectada: {torch.cuda.get_device_name(0)}")
            return True
        except ImportError:
            logger.warning("‚ö†Ô∏è OCR_USE_GPU=true mas PyTorch n√£o instalado. Usando CPU.")
            return False
    
    return False


@dataclass
class OCRResult:
    """Resultado de OCR em um frame"""
    text: str
    confidence: float
    word_count: int
    has_subtitle: bool
    readable_words: List[str]  # Palavras leg√≠veis detectadas


class OCRDetector:
    """
    Detector de legendas usando EasyOCR com valida√ß√£o de palavras leg√≠veis
    
    Pipeline de processamento:
    1. EasyOCR extrai texto
    2. Regex limpa texto (apenas letras e n√∫meros)
    3. Remove letras/n√∫meros isolados
    4. Filtra palavras com >2 caracteres
    5. Valida se h√° palavras leg√≠veis em PT/EN
    """
    
    # Palavras comuns em portugu√™s e ingl√™s para valida√ß√£o
    COMMON_WORDS_PT = {
        'que', 'n√£o', 'uma', 'para', 'com', 'por', 'isso', 'mais', 'este', 'esta',
        'seu', 'sua', 'foi', 'ser', 'tem', 'pode', 'mas', 'como', 'muito', 'quando',
        'sem', 'sim', 'bem', 'tamb√©m', 's√≥', 'at√©', 'depois', 'antes', 'entre', 'sobre',
        'ent√£o', 'agora', 'sempre', 'nunca', 'outro', 'nova', 'novo', 'grande', 'mesmo',
        'ainda', 'onde', 'ano', 'dia', 'vez', 'porque', 'aqui', 'l√°', 'ali', 'hoje',
        'ontem', 'amanh√£', 'noite', 'manh√£', 'tarde', 'hora', 'minuto', 'segundo',
        'casa', 'pai', 'm√£e', 'filho', 'filha', 'irm√£o', 'irm√£', 'homem', 'mulher',
        'vida', 'morte', 'amor', 'olhar', 'ver', 'fazer', 'dar', 'ter', 'vir', 'ir',
        'dizer', 'falar', 'pensar', 'querer', 'saber', 'poder', 'dever', 'achar'
    }
    
    COMMON_WORDS_EN = {
        'the', 'and', 'for', 'you', 'are', 'not', 'this', 'that', 'with', 'from',
        'have', 'was', 'were', 'been', 'will', 'can', 'but', 'what', 'all', 'when',
        'time', 'year', 'day', 'way', 'its', 'may', 'any', 'only', 'now', 'new',
        'make', 'work', 'know', 'take', 'see', 'come', 'get', 'use', 'find', 'give',
        'tell', 'ask', 'try', 'call', 'hand', 'part', 'about', 'after', 'back',
        'just', 'good', 'another', 'where', 'every', 'much', 'before', 'right',
        'mean', 'old', 'great', 'same', 'because', 'turn', 'here', 'show', 'why',
        'help', 'put', 'different', 'away', 'again', 'off', 'went', 'number'
    }

# ===== SINGLETON PATTERN (P1 Optimization) =====
_global_ocr_detector = None
_detector_lock = None

def get_ocr_detector() -> 'OCRDetector':
    """
    Retorna inst√¢ncia singleton de OCRDetector (P1 Optimization)
    
    Thread-safe para uso em Celery workers.
    Reduz uso de mem√≥ria de ~500MB por worker para ~50MB overhead.
    
    Returns:
        Inst√¢ncia singleton de OCRDetector
    """
    global _global_ocr_detector, _detector_lock
    
    # Inicializar lock na primeira chamada
    if _detector_lock is None:
        import threading
        _detector_lock = threading.Lock()
    
    if _global_ocr_detector is None:
        with _detector_lock:
            # Double-check locking
            if _global_ocr_detector is None:
                logger.info("üîß Creating OCRDetector singleton instance...")
                _global_ocr_detector = OCRDetector()
                logger.info("‚úÖ OCRDetector singleton created")
    
    return _global_ocr_detector


class OCRDetector:
    """
    Detector de legendas em frames usando EasyOCR
    
    IMPORTANTE: Use get_ocr_detector() ao inv√©s de instanciar diretamente
    para aproveitar otimiza√ß√£o singleton (P1).
    """
    
    def __init__(self):
        """
        Inicializa detector com EasyOCR configurado para PT e EN
        
        Configura√ß√£o GPU/CPU via vari√°vel de ambiente OCR_USE_GPU:
        - OCR_USE_GPU=true: Usa GPU (requer CUDA)
        - OCR_USE_GPU=false: Usa CPU (padr√£o)
        """
        use_gpu = _get_ocr_gpu_setting()
        mode = "GPU" if use_gpu else "CPU"
        
        logger.info(f"üöÄ Initializing EasyOCR detector (pt+en, {mode})...")
        try:
            # Inicializar EasyOCR com portugu√™s e ingl√™s
            self.reader = easyocr.Reader(['pt', 'en'], gpu=use_gpu, verbose=False)
            self.use_gpu = use_gpu
            logger.info(f"‚úÖ EasyOCR detector initialized successfully ({mode})")
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize EasyOCR: {e}")
            raise
    
    def detect_subtitle_in_frame(
        self,
        frame: np.ndarray,
        min_confidence: float = 60.0
    ) -> OCRResult:
        """
        Detecta legenda em um frame usando EasyOCR com valida√ß√£o de palavras leg√≠veis
        
        Pipeline:
        1. Pr√©-processamento da imagem
        2. EasyOCR extrai texto
        3. Limpeza com regex (apenas letras/n√∫meros)
        4. Remo√ß√£o de caracteres isolados
        5. Filtragem de palavras >2 caracteres
        6. Valida√ß√£o de palavras leg√≠veis (PT/EN)
        
        Args:
            frame: Frame BGR do cv2
            min_confidence: Confian√ßa m√≠nima (0-100) para aceitar detec√ß√£o
        
        Returns:
            OCRResult com texto processado e lista de palavras leg√≠veis
        """
        # Pr√©-processar para melhorar OCR
        processed = self._preprocess_for_ocr(frame)
        
        # Executar EasyOCR
        try:
            ocr_results = self.reader.readtext(processed, detail=1)
        except Exception as e:
            logger.warning(f"EasyOCR failed: {e}")
            return OCRResult(
                text="",
                confidence=0.0,
                word_count=0,
                has_subtitle=False,
                readable_words=[]
            )
        
        # Processar resultados do EasyOCR aplicando threshold
        raw_text, confidence, readable_words = self._process_easyocr_results(ocr_results, min_confidence)
        
        # Crit√©rio de valida√ß√£o: presen√ßa de palavras leg√≠veis
        has_subtitle = len(readable_words) > 0
        word_count = len(readable_words)
        
        # Registrar m√©trica
        ocr_confidence_distribution.observe(confidence)
        
        logger.debug(
            f"üìù OCR: conf={confidence:.1f}%, words={word_count}, "
            f"readable={readable_words}, has_subtitle={has_subtitle}"
        )
        
        return OCRResult(
            text=raw_text,
            confidence=confidence,
            word_count=word_count,
            has_subtitle=has_subtitle,
            readable_words=readable_words
        )
    
    def _preprocess_for_ocr(self, frame: np.ndarray) -> np.ndarray:
        """
        Pr√©-processa frame para melhorar OCR
        
        - Converte para grayscale
        - Aplica threshold adaptativo
        - Inverte cores (texto branco ‚Üí preto)
        
        Args:
            frame: Frame completo em BGR
        
        Returns:
            Imagem processada para OCR
        """
        # Converter para grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # Threshold adaptativo (binariza√ß√£o)
        binary = cv2.adaptiveThreshold(
            gray,
            255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY,
            11,
            2
        )
        
        # Inverter cores se necess√°rio (texto branco em fundo preto ‚Üí preto em branco)
        # Tesseract funciona melhor com texto escuro em fundo claro
        mean_val = np.mean(binary)
        if mean_val < 127:  # Imagem predominantemente escura
            binary = cv2.bitwise_not(binary)
        
        return binary
    
    def _process_easyocr_results(self, ocr_results: List, min_confidence: float = 60.0) -> Tuple[str, float, List[str]]:
        """
        Processa resultados do EasyOCR aplicando pipeline de limpeza
        
        Pipeline:
        1. Extrai texto bruto e confian√ßa (filtrando por threshold)
        2. Aplica regex: mant√©m apenas letras e n√∫meros
        3. Remove caracteres isolados (letras/n√∫meros sozinhos)
        4. Filtra palavras >2 caracteres
        5. Valida palavras leg√≠veis em PT/EN
        
        Args:
            ocr_results: Lista de tuplas (bbox, text, confidence) do EasyOCR
            min_confidence: Confian√ßa m√≠nima (0-100) para aceitar detec√ß√£o
        
        Returns:
            (texto_bruto, confian√ßa_m√©dia, lista_palavras_leg√≠veis)
        """
        if not ocr_results:
            return "", 0.0, []
        
        # Extrair textos e confian√ßas (filtrar por threshold)
        all_texts = []
        confidences = []
        
        for bbox, text, conf in ocr_results:
            conf_percent = conf * 100  # Converter para percentual
            # Aplicar threshold de confian√ßa
            if text.strip() and conf_percent >= min_confidence:
                all_texts.append(text)
                confidences.append(conf_percent)
        
        if not all_texts:
            return "", 0.0, []
        
        # Texto bruto concatenado
        raw_text = " ".join(all_texts)
        
        # Confian√ßa m√©dia
        avg_confidence = sum(confidences) / len(confidences)
        
        # STEP 1: Regex - manter apenas letras e n√∫meros
        cleaned_text = re.sub(r'[^a-zA-Z0-9\s]', '', raw_text)
        
        # STEP 2: Dividir em palavras
        words = cleaned_text.split()
        
        # STEP 3: Remover caracteres isolados (letras/n√∫meros sozinhos)
        # STEP 4: Filtrar palavras com >2 caracteres
        filtered_words = [w.lower() for w in words if len(w) > 2]
        
        # STEP 5: Validar palavras leg√≠veis (presentes em dicion√°rios PT/EN)
        readable_words = [
            w for w in filtered_words
            if w in self.COMMON_WORDS_PT or w in self.COMMON_WORDS_EN
        ]
        
        logger.debug(
            f"üìä Pipeline: raw='{raw_text}' ‚Üí cleaned='{cleaned_text}' ‚Üí "
            f"filtered={filtered_words} ‚Üí readable={readable_words}"
        )
        
        return raw_text, avg_confidence, readable_words
    
    def extract_frame_at_timestamp(
        self,
        video_path: str,
        timestamp: float
    ) -> Optional[np.ndarray]:
        """
        Extrai frame em um timestamp espec√≠fico
        
        Args:
            video_path: Path do v√≠deo
            timestamp: Timestamp em segundos
        
        Returns:
            Frame BGR ou None se falhar
        """
        cap = cv2.VideoCapture(video_path)
        
        try:
            # Setar posi√ß√£o do v√≠deo
            cap.set(cv2.CAP_PROP_POS_MSEC, timestamp * 1000)
            
            # Ler frame
            ret, frame = cap.read()
            
            if not ret:
                logger.warning(f"Failed to extract frame at {timestamp}s")
                return None
            
            return frame
        
        finally:
            cap.release()
