# üîß PLANO DE CORRE√á√ïES v4 - EXECU√á√ÉO DETALHADA

**Data:** 2025-11-01  
**Base:** analisev4.md  
**Status:** Pronto para Implementa√ß√£o  

---

## üìã VALIDA√á√ÉO DA AN√ÅLISE

### ‚úÖ Problemas Confirmados:

1. **‚úì Isolamento Vocal com IA**: Confirmado - 100+ refer√™ncias encontradas
2. **‚úì Refer√™ncias GPU**: Confirmado - torch/cuda em m√∫ltiplos m√©todos
3. **‚úì Requisi√ß√µes Duplicadas**: Confirmado - job_id usa timestamp (n√£o idempotente)
4. **‚úì Progresso em Chunks**: Confirmado - flag `is_chunk=True` desabilita updates

### ‚úÖ Solu√ß√µes Validadas:

1. **‚úì Remo√ß√£o Completa**: Solu√ß√£o vi√°vel - remover imports, m√©todos, par√¢metros
2. **‚úì 100% CPU**: Solu√ß√£o vi√°vel - remover torch mant√©m pydub/scipy/numpy
3. **‚úì Idempot√™ncia**: Solu√ß√£o vi√°vel - hash sem timestamp + verifica√ß√£o Redis
4. **‚úì Progresso Real-Time**: Solu√ß√£o vi√°vel - updates dentro do loop de chunks

---

## üéØ PLANO DE EXECU√á√ÉO

---

## FASE 1: REMOVER ISOLAMENTO VOCAL + GPU (audio-normalization)

### ‚úÖ ARQUIVO 1: `services/audio-normalization/requirements.txt`

**A√ß√£o:** Remover depend√™ncias ML/GPU

**C√≥digo Atual:**
```txt
# === ML-BASED VOCAL ISOLATION ===
openunmix==1.3.0
torch==2.9.0
torchaudio==2.9.0
```

**C√≥digo Novo:**
```txt
# (remover se√ß√£o completa)
```

**Valida√ß√£o:**
- requirements.txt n√£o deve conter: openunmix, torch, torchaudio

---

### ‚úÖ ARQUIVO 2: `services/audio-normalization/app/config.py`

**A√ß√£o:** Remover configura√ß√£o OpenUnmix

**Localiza√ß√£o:** Linhas 81-87

**C√≥digo Atual:**
```python
# ===== OPENUNMIX =====
'openunmix': {
    'model_name': os.getenv('OPENUNMIX_MODEL_NAME', 'umx'),
    'target': os.getenv('OPENUNMIX_TARGET', 'vocals'),
    'device': os.getenv('OPENUNMIX_DEVICE', 'cpu'),
    'pretrained': os.getenv('OPENUNMIX_PRETRAINED', 'true').lower() == 'true',
},
```

**C√≥digo Novo:**
```python
# (remover se√ß√£o completa)
```

**Valida√ß√£o:**
- Dicion√°rio `settings` n√£o deve ter chave `'openunmix'`

---

### ‚úÖ ARQUIVO 3: `services/audio-normalization/app/processor.py`

**MODIFICA√á√ÉO 1: Remover Imports**

**Localiza√ß√£o:** Linhas 19-29

**C√≥digo Atual:**
```python
# Para isolamento vocal com openunmix
try:
    import torch
    import openunmix
    OPENUNMIX_AVAILABLE = True
    TORCH_AVAILABLE = True
    logger.info("‚úÖ PyTorch e OpenUnmix dispon√≠veis para isolamento vocal")
except ImportError:
    OPENUNMIX_AVAILABLE = False
    TORCH_AVAILABLE = False
    logger.warning("‚ö†Ô∏è OpenUnmix n√£o dispon√≠vel. Isolamento vocal ser√° desabilitado")
```

**C√≥digo Novo:**
```python
# (remover bloco completo - sem imports torch/openunmix)
```

---

**MODIFICA√á√ÉO 2: Remover Atributos de GPU no __init__**

**Localiza√ß√£o:** Linhas 35-38

**C√≥digo Atual:**
```python
self._openunmix_model = None
self.device = None  # Will be set when loading model

self._detect_device()
```

**C√≥digo Novo:**
```python
# (remover linhas completas - sem atributos de GPU)
```

---

**MODIFICA√á√ÉO 3: Remover M√©todo `_detect_device()`**

**Localiza√ß√£o:** Linhas 40-64

**A√ß√£o:** Deletar m√©todo completo (25 linhas)

---

**MODIFICA√á√ÉO 4: Remover M√©todo `_test_gpu()`**

**Localiza√ß√£o:** Linhas 66-91

**A√ß√£o:** Deletar m√©todo completo (26 linhas)

---

**MODIFICA√á√ÉO 5: Remover M√©todo `_load_openunmix_model()`**

**Localiza√ß√£o:** Linhas 253-300

**A√ß√£o:** Deletar m√©todo completo (~47 linhas)

---

**MODIFICA√á√ÉO 6: Remover M√©todo `_isolate_vocals()`**

**Localiza√ß√£o:** Buscar m√©todo (n√£o visualizado, mas existe)

**A√ß√£o:** Deletar m√©todo completo

**Buscar por:**
```python
async def _isolate_vocals(self, audio: AudioSegment)
```

---

**MODIFICA√á√ÉO 7: Remover Bloco de Isolamento Vocal em `_apply_processing_operations()`**

**Localiza√ß√£o:** Linhas 523-534

**C√≥digo Atual:**
```python
# 1. Isolamento vocal (primeiro, pois pode afetar outras opera√ß√µes)
if job.isolate_vocals:
    try:
        logger.info("Aplicando isolamento vocal...")
        audio = await self._isolate_vocals(audio)
        if not is_chunk:
            current_progress += progress_step
            job.progress = current_progress
            if self.job_store:
                self.job_store.update_job(job)
    except Exception as e:
        logger.error(f"Erro no isolamento vocal: {e}")
        raise AudioNormalizationException(f"Falha no isolamento vocal: {str(e)}")
```

**C√≥digo Novo:**
```python
# (remover bloco completo - sem processamento de isolamento vocal)
```

**NOTA:** Ajustar coment√°rios e numera√ß√£o dos outros passos (2, 3, 4, 5 ‚Üí 1, 2, 3, 4)

---

**MODIFICA√á√ÉO 8: Ajustar Contagem de Opera√ß√µes**

**Localiza√ß√£o:** Linha 513

**C√≥digo Atual:**
```python
operations_count = sum([
    job.remove_noise, job.convert_to_mono, job.apply_highpass_filter,
    job.set_sample_rate_16k, job.isolate_vocals
])
```

**C√≥digo Novo:**
```python
operations_count = sum([
    job.remove_noise, job.convert_to_mono, job.apply_highpass_filter,
    job.set_sample_rate_16k
])
```

---

**MODIFICA√á√ÉO 9: Adicionar Progresso em Chunks no `_process_audio_with_streaming()`**

**Localiza√ß√£o:** Loop de chunks (aproximadamente linha 530-560)

**C√≥digo Atual:**
```python
for i, chunk_file in enumerate(chunk_files):
    chunk_num = i + 1
    logger.info(f"üì¶ Processando chunk {chunk_num}/{total_chunks}...")
    
    # Carrega chunk
    chunk_audio = AudioSegment.from_file(str(chunk_file))
    
    # Processa chunk
    processed_chunk = await self._apply_processing_operations(
        chunk_audio, job, is_chunk=True
    )
    
    # Salva chunk processado
    processed_chunks.append(processed_chunk)
    
    # ‚ùå SEM atualiza√ß√£o de progresso aqui

# Merge (ap√≥s o loop)
job.progress = 90.0
if self.job_store: self.job_store.update_job(job)
```

**C√≥digo Novo:**
```python
for i, chunk_file in enumerate(chunk_files):
    chunk_num = i + 1
    logger.info(f"üì¶ Processando chunk {chunk_num}/{total_chunks}...")
    
    # ‚úÖ ATUALIZA PROGRESSO ANTES DE PROCESSAR
    # Progresso: 10% (prep) + 70% (chunks) + 10% (merge) + 10% (save)
    chunk_progress_before = 10.0 + ((chunk_num - 1) / total_chunks) * 70.0
    job.progress = chunk_progress_before
    if self.job_store:
        self.job_store.update_job(job)
        logger.info(f"üìä Progresso: {chunk_progress_before:.1f}% (iniciando chunk {chunk_num}/{total_chunks})")
    
    # Carrega chunk
    chunk_audio = AudioSegment.from_file(str(chunk_file))
    
    # Processa chunk
    processed_chunk = await self._apply_processing_operations(
        chunk_audio, job, is_chunk=True
    )
    
    # Salva chunk processado
    processed_chunks.append(processed_chunk)
    
    # ‚úÖ ATUALIZA PROGRESSO AP√ìS PROCESSAR
    chunk_progress_after = 10.0 + (chunk_num / total_chunks) * 70.0
    job.progress = chunk_progress_after
    if self.job_store:
        self.job_store.update_job(job)
        logger.info(f"‚úÖ Chunk {chunk_num}/{total_chunks} conclu√≠do ({chunk_progress_after:.1f}%)")

# Merge (ap√≥s o loop)
logger.info("üîó Mesclando chunks processados...")
job.progress = 85.0
if self.job_store: self.job_store.update_job(job)

# ... c√≥digo de merge ...

job.progress = 90.0
if self.job_store: self.job_store.update_job(job)
logger.info("‚úÖ Merge de chunks conclu√≠do (90%)")
```

---

**Valida√ß√£o do processor.py:**
```bash
# Deve retornar 0 resultados:
grep -i "torch\|cuda\|gpu\|openunmix\|isolate_vocals" services/audio-normalization/app/processor.py
```

---

### ‚úÖ ARQUIVO 4: `services/audio-normalization/app/models.py`

**MODIFICA√á√ÉO 1: Remover Campo de AudioProcessingRequest**

**Localiza√ß√£o:** Linha ~20

**C√≥digo Atual:**
```python
class AudioProcessingRequest(BaseModel):
    """Request para processamento de √°udio com par√¢metros booleanos"""
    remove_noise: bool = False
    convert_to_mono: bool = False
    apply_highpass_filter: bool = False
    set_sample_rate_16k: bool = False
    isolate_vocals: bool = False
```

**C√≥digo Novo:**
```python
class AudioProcessingRequest(BaseModel):
    """Request para processamento de √°udio com par√¢metros booleanos"""
    remove_noise: bool = False
    convert_to_mono: bool = False
    apply_highpass_filter: bool = False
    set_sample_rate_16k: bool = False
```

---

**MODIFICA√á√ÉO 2: Remover Campo de Job**

**Localiza√ß√£o:** Linha ~40

**C√≥digo Atual:**
```python
# Par√¢metros de processamento
remove_noise: bool = False
convert_to_mono: bool = False
apply_highpass_filter: bool = False
set_sample_rate_16k: bool = False
isolate_vocals: bool = False
```

**C√≥digo Novo:**
```python
# Par√¢metros de processamento
remove_noise: bool = False
convert_to_mono: bool = False
apply_highpass_filter: bool = False
set_sample_rate_16k: bool = False
```

---

**MODIFICA√á√ÉO 3: Remover "v" de processing_operations**

**Localiza√ß√£o:** Linhas ~55-59

**C√≥digo Atual:**
```python
if self.apply_highpass_filter:
    operations.append("h")
if self.set_sample_rate_16k:
    operations.append("s")
if self.isolate_vocals:
    operations.append("v")
return "".join(operations) if operations else "none"
```

**C√≥digo Novo:**
```python
if self.apply_highpass_filter:
    operations.append("h")
if self.set_sample_rate_16k:
    operations.append("s")
return "".join(operations) if operations else "none"
```

---

**MODIFICA√á√ÉO 4: Remover Par√¢metro de create_new()**

**Localiza√ß√£o:** Linhas ~62-66, ~80-81, ~96

**C√≥digo Atual:**
```python
@classmethod
def create_new(
    cls, 
    filename: str, 
    remove_noise: bool = False,
    convert_to_mono: bool = False,
    apply_highpass_filter: bool = False,
    set_sample_rate_16k: bool = False,
    isolate_vocals: bool = False
) -> "Job":
    ...
    logger.info(f"üîç DEBUG Job.create_new - isolate_vocals: {isolate_vocals}")
    ...
    operations = [
        "n" if remove_noise else "",
        "m" if convert_to_mono else "",
        "h" if apply_highpass_filter else "",
        "s" if set_sample_rate_16k else "",
        "v" if isolate_vocals else ""
    ]
    ...
    return cls(
        ...
        isolate_vocals=isolate_vocals,
        ...
    )
```

**C√≥digo Novo:**
```python
@classmethod
def create_new(
    cls, 
    filename: str, 
    remove_noise: bool = False,
    convert_to_mono: bool = False,
    apply_highpass_filter: bool = False,
    set_sample_rate_16k: bool = False
) -> "Job":
    ...
    # (remover log de isolate_vocals)
    ...
    operations = [
        "n" if remove_noise else "",
        "m" if convert_to_mono else "",
        "h" if apply_highpass_filter else "",
        "s" if set_sample_rate_16k else ""
    ]
    ...
    return cls(
        ...
        # (remover isolate_vocals=isolate_vocals)
        ...
    )
```

---

### ‚úÖ ARQUIVO 5: `services/audio-normalization/app/main.py`

**MODIFICA√á√ÉO 1: Remover Form Parameter**

**Localiza√ß√£o:** Linha ~135

**C√≥digo Atual:**
```python
isolate_vocals: str = Form("false")
```

**C√≥digo Novo:**
```python
# (remover linha completa)
```

---

**MODIFICA√á√ÉO 2: Remover Docstring**

**Localiza√ß√£o:** Linha ~147

**C√≥digo Atual:**
```python
- **isolate_vocals**: Isola vocais usando OpenUnmix (padr√£o: False)
```

**C√≥digo Novo:**
```python
# (remover linha completa)
```

---

**MODIFICA√á√ÉO 3: Remover Convers√£o**

**Localiza√ß√£o:** Linha ~172

**C√≥digo Atual:**
```python
isolate_vocals_bool = str_to_bool(isolate_vocals)
```

**C√≥digo Novo:**
```python
# (remover linha completa)
```

---

**MODIFICA√á√ÉO 4: Remover Log**

**Localiza√ß√£o:** Linha ~177

**C√≥digo Atual:**
```python
logger.info(f"  isolate_vocals: '{isolate_vocals}' -> {isolate_vocals_bool}")
```

**C√≥digo Novo:**
```python
# (remover linha completa)
```

---

**MODIFICA√á√ÉO 5: Remover Passagem para Job**

**Localiza√ß√£o:** Linha ~192

**C√≥digo Atual:**
```python
job = Job.create_new(
    filename=file.filename,
    remove_noise=remove_noise_bool,
    convert_to_mono=convert_to_mono_bool,
    apply_highpass_filter=apply_highpass_filter_bool,
    set_sample_rate_16k=set_sample_rate_16k_bool,
    isolate_vocals=isolate_vocals_bool
)
```

**C√≥digo Novo:**
```python
job = Job.create_new(
    filename=file.filename,
    remove_noise=remove_noise_bool,
    convert_to_mono=convert_to_mono_bool,
    apply_highpass_filter=apply_highpass_filter_bool,
    set_sample_rate_16k=set_sample_rate_16k_bool
)
```

---

### ‚úÖ ARQUIVO 6: `services/audio-normalization/app/celery_tasks.py`

**MODIFICA√á√ÉO: Remover `vocals=` do Log**

**Localiza√ß√£o:** Linha ~186

**C√≥digo Atual:**
```python
logger.info(f"üìã Processing params: noise={job.remove_noise}, highpass={job.apply_highpass_filter}, vocals={job.isolate_vocals}")
```

**C√≥digo Novo:**
```python
logger.info(f"üìã Processing params: noise={job.remove_noise}, highpass={job.apply_highpass_filter}")
```

---

## FASE 2: REMOVER ISOLAMENTO VOCAL (orchestrator)

### ‚úÖ ARQUIVO 7: `orchestrator/modules/config.py`

**MODIFICA√á√ÉO 1: Remover default_isolate_vocals**

**Localiza√ß√£o:** Linha ~67

**C√≥digo Atual:**
```python
"default_isolate_vocals": os.getenv("DEFAULT_ISOLATE_VOCALS", "true").lower() == "true",
```

**C√≥digo Novo:**
```python
# (remover linha completa)
```

---

**MODIFICA√á√ÉO 2: Remover isolate_vocals de default_params**

**Localiza√ß√£o:** Linha ~104

**C√≥digo Atual:**
```python
"default_params": {
    "remove_noise": settings["default_remove_noise"],
    "convert_to_mono": settings["default_convert_mono"],
    "set_sample_rate_16k": settings["default_sample_rate_16k"],
    "apply_highpass_filter": False,
    "isolate_vocals": False
}
```

**C√≥digo Novo:**
```python
"default_params": {
    "remove_noise": settings["default_remove_noise"],
    "convert_to_mono": settings["default_convert_mono"],
    "set_sample_rate_16k": settings["default_sample_rate_16k"],
    "apply_highpass_filter": False
}
```

---

### ‚úÖ ARQUIVO 8: `orchestrator/modules/models.py`

**MODIFICA√á√ÉO 1: Remover Campo de PipelineJob**

**Localiza√ß√£o:** Linha ~88

**C√≥digo Atual:**
```python
class PipelineJob(BaseModel):
    ...
    isolate_vocals: bool = False
```

**C√≥digo Novo:**
```python
class PipelineJob(BaseModel):
    ...
    # (remover isolate_vocals)
```

---

**MODIFICA√á√ÉO 2: Remover Campo de PipelineRequest**

**Localiza√ß√£o:** Linha ~185

**C√≥digo Atual:**
```python
isolate_vocals: Optional[bool] = Field(settings["default_isolate_vocals"], description="Isolar vocais (separa voz de m√∫sica)")
```

**C√≥digo Novo:**
```python
# (remover linha completa)
```

---

**MODIFICA√á√ÉO 3: Adicionar M√©todo `generate_id()` Est√°tico**

**Localiza√ß√£o:** Adicionar ANTES de `create_new()`

**C√≥digo Novo:**
```python
@staticmethod
def generate_id(
    youtube_url: str,
    language: str,
    language_out: Optional[str],
    remove_noise: bool,
    convert_to_mono: bool,
    apply_highpass_filter: bool,
    set_sample_rate_16k: bool
) -> str:
    """
    Gera ID determin√≠stico baseado em par√¢metros (idempotente)
    
    IMPORTANTE: N√ÉO usa timestamp para permitir deduplica√ß√£o
    Mesmos par√¢metros = mesmo job_id
    """
    # Normaliza URL (remove query params desnecess√°rios)
    from urllib.parse import urlparse, parse_qs
    parsed = urlparse(youtube_url)
    video_id = parse_qs(parsed.query).get('v', [''])[0] if parsed.query else youtube_url
    
    # Cria string de opera√ß√µes
    operation_string = f"{video_id}"
    operation_string += f"_lang{language}_out{language_out or 'none'}"
    operation_string += f"_n{int(remove_noise)}_m{int(convert_to_mono)}"
    operation_string += f"_h{int(apply_highpass_filter)}_s{int(set_sample_rate_16k)}"
    
    # Gera hash determin√≠stico
    job_id = hashlib.md5(operation_string.encode()).hexdigest()[:16]
    return job_id
```

---

**MODIFICA√á√ÉO 4: Modificar `create_new()` para Usar `generate_id()`**

**Localiza√ß√£o:** M√©todo `create_new()`

**C√≥digo Atual:**
```python
@classmethod
def create_new(cls, youtube_url: str, ...) -> "PipelineJob":
    job_id = hashlib.md5(f"{youtube_url}{datetime.now().isoformat()}".encode()).hexdigest()[:16]
    ...
```

**C√≥digo Novo:**
```python
@classmethod
def create_new(
    cls,
    youtube_url: str,
    language: str,
    language_out: Optional[str] = None,
    remove_noise: bool = False,
    convert_to_mono: bool = False,
    apply_highpass_filter: bool = False,
    set_sample_rate_16k: bool = False
) -> "PipelineJob":
    """Cria novo job de pipeline com ID determin√≠stico (idempotente)"""
    
    # Gera ID determin√≠stico (sem timestamp)
    job_id = cls.generate_id(
        youtube_url=youtube_url,
        language=language,
        language_out=language_out,
        remove_noise=remove_noise,
        convert_to_mono=convert_to_mono,
        apply_highpass_filter=apply_highpass_filter,
        set_sample_rate_16k=set_sample_rate_16k
    )
    
    now = datetime.now()
    
    return cls(
        id=job_id,
        youtube_url=youtube_url,
        language=language,
        language_out=language_out,
        remove_noise=remove_noise,
        convert_to_mono=convert_to_mono,
        apply_highpass_filter=apply_highpass_filter,
        set_sample_rate_16k=set_sample_rate_16k,
        # (remover isolate_vocals)
        status=PipelineStatus.QUEUED,
        created_at=now,
        expires_at=now + timedelta(hours=24)
    )
```

---

### ‚úÖ ARQUIVO 9: `orchestrator/modules/orchestrator.py`

**MODIFICA√á√ÉO: Remover isolate_vocals do Form Data**

**Localiza√ß√£o:** Linha ~456

**C√≥digo Atual:**
```python
"isolate_vocals": _bool_to_str(job.isolate_vocals if job.isolate_vocals is not None else defaults.get("isolate_vocals", False)),
```

**C√≥digo Novo:**
```python
# (remover linha completa)
```

---

### ‚úÖ ARQUIVO 10: `orchestrator/main.py`

**MODIFICA√á√ÉO 1: Remover isolate_vocals da Cria√ß√£o de Job**

**Localiza√ß√£o:** Linha ~150

**C√≥digo Atual:**
```python
job = PipelineJob.create_new(
    youtube_url=request.youtube_url,
    language=request.language or settings["default_language"],
    language_out=request.language_out,
    remove_noise=request.remove_noise if request.remove_noise is not None else settings["default_remove_noise"],
    convert_to_mono=request.convert_to_mono if request.convert_to_mono is not None else settings["default_convert_mono"],
    apply_highpass_filter=request.apply_highpass_filter if request.apply_highpass_filter is not None else False,
    set_sample_rate_16k=request.set_sample_rate_16k if request.set_sample_rate_16k is not None else settings["default_sample_rate_16k"],
    isolate_vocals=request.isolate_vocals if request.isolate_vocals is not None else False
)
```

**C√≥digo Novo:**
```python
job = PipelineJob.create_new(
    youtube_url=request.youtube_url,
    language=request.language or settings["default_language"],
    language_out=request.language_out,
    remove_noise=request.remove_noise if request.remove_noise is not None else settings["default_remove_noise"],
    convert_to_mono=request.convert_to_mono if request.convert_to_mono is not None else settings["default_convert_mono"],
    apply_highpass_filter=request.apply_highpass_filter if request.apply_highpass_filter is not None else False,
    set_sample_rate_16k=request.set_sample_rate_16k if request.set_sample_rate_16k is not None else settings["default_sample_rate_16k"]
)
```

---

**MODIFICA√á√ÉO 2: Adicionar Verifica√ß√£o de Job Existente (Idempot√™ncia)**

**Localiza√ß√£o:** Logo AP√ìS cria√ß√£o da vari√°vel `job` (antes de `redis_store.save_job(job)`)

**C√≥digo Atual:**
```python
# Cria job
job = PipelineJob.create_new(...)

# Salva no Redis
redis_store.save_job(job)
```

**C√≥digo Novo:**
```python
# Gera job_id determin√≠stico e verifica se j√° existe
job_id = PipelineJob.generate_id(
    youtube_url=request.youtube_url,
    language=request.language or settings["default_language"],
    language_out=request.language_out,
    remove_noise=request.remove_noise if request.remove_noise is not None else settings["default_remove_noise"],
    convert_to_mono=request.convert_to_mono if request.convert_to_mono is not None else settings["default_convert_mono"],
    apply_highpass_filter=request.apply_highpass_filter if request.apply_highpass_filter is not None else False,
    set_sample_rate_16k=request.set_sample_rate_16k if request.set_sample_rate_16k is not None else settings["default_sample_rate_16k"]
)

# Verifica se job j√° existe (idempot√™ncia)
existing_job = redis_store.get_job(job_id)
if existing_job:
    # Job j√° existe
    if existing_job.status in [PipelineStatus.PROCESSING, PipelineStatus.COMPLETED]:
        logger.info(f"‚ôªÔ∏è Job {job_id} j√° existe com status {existing_job.status.value} - retornando job existente")
        return PipelineResponse(
            job_id=job_id,
            status=existing_job.status.value,
            message=f"Job j√° existe e est√° {existing_job.status.value}",
            created_at=existing_job.created_at,
            stages=existing_job.stages
        )
    elif existing_job.status == PipelineStatus.FAILED:
        # Job falhou anteriormente, permite reprocessar
        logger.info(f"üîÑ Job {job_id} falhou anteriormente - permitindo reprocessamento")
    # Se QUEUED, continua para recriar

# Cria novo job com ID pr√©-determinado
job = PipelineJob.create_new(...)

# Salva no Redis
redis_store.save_job(job)
```

---

## üìä CHECKLIST DE VALIDA√á√ÉO P√ìS-IMPLEMENTA√á√ÉO

### ‚úÖ Valida√ß√£o 1: Remo√ß√£o Completa de isolate_vocals

```bash
# Executar na raiz do projeto:
grep -r "isolate_vocals" services/audio-normalization/ orchestrator/
# Resultado esperado: 0 matches
```

### ‚úÖ Valida√ß√£o 2: Remo√ß√£o Completa de GPU/Torch

```bash
# Executar:
grep -ri "torch\|cuda\|gpu\|openunmix" services/audio-normalization/app/
# Resultado esperado: 0 matches (exceto em coment√°rios hist√≥ricos)
```

### ‚úÖ Valida√ß√£o 3: Requirements.txt Limpo

```bash
# Verificar:
cat services/audio-normalization/requirements.txt | grep -i "torch\|openunmix"
# Resultado esperado: nenhuma linha
```

### ‚úÖ Valida√ß√£o 4: Progresso em Chunks

**Teste Manual:**
1. Upload arquivo > 50MB para `/jobs`
2. Monitorar `GET /jobs/{job_id}` em loop
3. Verificar: progresso deve atualizar continuamente (10% ‚Üí 25% ‚Üí 40% ‚Üí 55% ‚Üí 70% ‚Üí 85% ‚Üí 100%)
4. N√ÉO deve ficar parado em 10% por minutos

### ‚úÖ Valida√ß√£o 5: Idempot√™ncia

**Teste Manual:**
1. Enviar POST `/process` com mesma URL/params
2. Aguardar 1 segundo
3. Enviar POST `/process` com MESMA URL/params novamente
4. Verificar: AMBOS devem retornar o MESMO `job_id`
5. Verificar Redis: apenas 1 job deve existir

**Teste Automatizado:**
```bash
curl -X POST "http://localhost:8080/process" -H "Content-Type: application/json" \
  -d '{"youtube_url": "https://youtube.com/watch?v=TEST123", "language": "pt"}' > resp1.json

curl -X POST "http://localhost:8080/process" -H "Content-Type: application/json" \
  -d '{"youtube_url": "https://youtube.com/watch?v=TEST123", "language": "pt"}' > resp2.json

# Comparar job_id:
diff <(jq -r '.job_id' resp1.json) <(jq -r '.job_id' resp2.json)
# Resultado esperado: sem diferen√ßas (mesmo job_id)
```

### ‚úÖ Valida√ß√£o 6: Build e Startup

```bash
# Build:
time docker-compose build audio-normalization
# Tempo esperado: ~50% mais r√°pido que antes

# Startup:
docker-compose up audio-normalization
# Verificar logs: deve subir em poucos segundos, sem carregar modelos torch
```

---

## üöÄ ORDEM DE EXECU√á√ÉO

1. **Commit Estado Atual** (backup)
2. **Executar FASE 1** (arquivos 1-6)
3. **Testar audio-normalization isoladamente**
4. **Executar FASE 2** (arquivos 7-10)
5. **Testar sistema completo**
6. **Executar Valida√ß√µes 1-6**
7. **Commit Final**

---

## üìù NOTAS IMPORTANTES

### Sobre Imports:
- Ap√≥s remover torch/openunmix, N√ÉO adicionar substitui√ß√µes
- pydub/scipy/numpy/librosa s√£o suficientes para noise reduction e filters

### Sobre Progresso:
- C√°lculo: 10% (prep) + 70% (chunks) + 10% (merge) + 10% (save)
- Update ANTES e DEPOIS de cada chunk
- Logs detalhados para debugging

### Sobre Idempot√™ncia:
- Hash N√ÉO inclui timestamp
- URL √© normalizada (extrai video_id)
- Jobs FAILED podem ser reprocessados
- Jobs PROCESSING/COMPLETED s√£o retornados como-est√£o

---

**FIM DO PLANO DE CORRE√á√ïES v4**
