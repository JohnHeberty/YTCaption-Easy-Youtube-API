# üêõ BUGS E PROBLEMAS IDENTIFICADOS - YouTube Caption Orchestrator

## ‚ö†Ô∏è CR√çTICOS (P0) - RESOLVIDOS

### ‚úÖ 1. Jobs ficando travados em "queued" (RESOLVIDO)
**Status:** CORRIGIDO ‚úÖ  
**Descri√ß√£o:** Jobs ficavam permanentemente em status "queued" sem nunca executar.  
**Causa Raiz:** Orchestrator n√£o salvava o job no Redis durante a execu√ß√£o do pipeline.  
**Sintomas:**
- Job criado com sucesso via POST /process
- Status retorna sempre "queued", progress 0%
- Logs mostram execu√ß√£o normal do pipeline
- Redis n√£o refletia progresso em tempo real

**Solu√ß√£o Implementada:**
- Passou `redis_store` como par√¢metro para `PipelineOrchestrator.__init__()`
- Adicionou 6 pontos de salvamento Redis:
  * Ap√≥s status = DOWNLOADING
  * Ap√≥s conclus√£o de download
  * Ap√≥s status = NORMALIZING  
  * Ap√≥s conclus√£o de normaliza√ß√£o
  * Ap√≥s status = TRANSCRIBING
  * Ap√≥s conclus√£o de transcri√ß√£o

**Arquivos Modificados:**
- `orchestrator/main.py` - linha 52: `orchestrator = PipelineOrchestrator(redis_store=redis_store)`
- `orchestrator/modules/orchestrator.py` - linhas 287, 303, 318, 348, 367, 408

**Teste de Valida√ß√£o:**
```powershell
# Status mudou de "queued" para "downloading" em 3s
POST /process ‚Üí job_id
GET /jobs/{job_id} ap√≥s 3s ‚Üí status: "downloading" ‚úì
```

---

## üî• CR√çTICOS (P0) - PENDENTES

### ‚ùå 2. Factory Reset n√£o limpa filas Redis nos microservi√ßos
**Status:** N√ÉO CORRIGIDO ‚ùå  
**Prioridade:** P0 (Cr√≠tico)  
**Descri√ß√£o:** Endpoint `/admin/factory-reset` do orchestrator chama `/admin/cleanup?deep=true` nos microservi√ßos, mas os servi√ßos **n√£o limpam as filas Celery do Redis**.

**Impacto:**
- Ap√≥s factory reset, jobs antigos permanecem nas filas Celery
- Workers processam jobs fantasmas que n√£o existem mais
- Logs ficam polu√≠dos com erros de "job not found"
- Imposs√≠vel ter um reset limpo do sistema

**Servi√ßos Afetados:**
1. **video-downloader** (Redis DB 0)
   - Fila: `video_downloader_queue`
   - Cleanup remove apenas keys `video_job:*`
   - **FALTA:** Limpar fila Celery

2. **audio-normalization** (Redis DB 1)
   - Fila: `audio_normalization_queue`
   - Cleanup remove apenas keys `audio_job:*`
   - **FALTA:** Limpar fila Celery

3. **audio-transcriber** (Redis DB 2)
   - Fila: `audio_transcription_queue`
   - Cleanup remove apenas keys `transcription_job:*`
   - **FALTA:** Limpar fila Celery

**C√≥digo Atual (video-downloader/app/main.py:398):**
```python
async def _perform_total_cleanup():
    redis = Redis.from_url(redis_url, decode_responses=True)
    keys = redis.keys("video_job:*")  # ‚ùå S√≥ remove jobs
    for key in keys:
        redis.delete(key)
    # ‚ùå FALTA: Limpar fila Celery!
```

**Solu√ß√£o Necess√°ria:**
```python
async def _perform_total_cleanup():
    from celery import Celery
    from redis import Redis
    
    # 1. Limpar jobs do Redis
    redis = Redis.from_url(redis_url, decode_responses=True)
    keys = redis.keys("video_job:*")
    for key in keys:
        redis.delete(key)
    
    # 2. ‚úÖ LIMPAR FILA CELERY
    celery_app = Celery()
    celery_app.config_from_object('app.celery_config')
    
    # Purge da fila
    celery_app.control.purge()
    
    # Ou limpar espec√≠fico por fila
    from kombu import Connection
    with Connection(redis_url) as conn:
        conn.default_channel.queue_purge('video_downloader_queue')
    
    logger.warning("üî• Fila Celery purgada!")
```

**Arquivos a Modificar:**
- `services/video-downloader/app/main.py` (linha ~398)
- `services/audio-normalization/app/main.py` (linha similar)
- `services/audio-transcriber/app/main.py` (linha similar)

**Teste de Valida√ß√£o:**
```bash
# 1. Criar jobs
POST /process ‚Üí job1, job2, job3

# 2. Factory reset
POST /admin/factory-reset

# 3. Verificar Redis
redis-cli -n 0 KEYS "video_job:*"  # Deve retornar vazio
redis-cli -n 0 LLEN video_downloader_queue  # Deve retornar 0

# 4. Verificar logs dos workers
# N√ÉO deve ter "job not found" ap√≥s reset
```

---

### ‚ùå 3. Jobs ficando parados sem logs de erro
**Status:** INVESTIGA√á√ÉO EM ANDAMENTO üîç  
**Prioridade:** P0 (Cr√≠tico)  
**Descri√ß√£o:** Jobs permanecem em estado "downloading" indefinidamente sem logs de erro no orchestrator ou microservi√ßos.

**Sintomas:**
- Job fica em "downloading" por >5 minutos
- Overall progress = 0%
- Download stage: status="pending", progress=0%
- **Sem logs de erro** no orchestrator
- **Sem logs de erro** no video-downloader
- Health checks todos OK

**Hip√≥teses (em ordem de probabilidade):**

#### **H1: Job submetido mas n√£o recebido pelo worker Celery** (75%)
**Evid√™ncia:**
- Orchestrator logs mostram: `"Submitting JSON to video-downloader: http://ytcaption-video-downloader:8000/jobs"`
- Video-downloader recebe POST mas n√£o enfileira no Celery
- Worker Celery n√£o processa porque n√£o h√° task na fila

**Como Verificar:**
```bash
# Verificar se h√° tasks na fila
docker exec ytcaption-video-downloader-celery celery -A app.celery_config inspect active
docker exec ytcaption-video-downloader-celery celery -A app.celery_config inspect reserved

# Verificar se worker est√° ouvindo a fila correta
docker logs ytcaption-video-downloader-celery | grep "video_downloader_queue"
```

**Poss√≠vel Causa:**
- Worker n√£o est√° registrado na fila
- Celery n√£o est√° conectado ao Redis
- Task n√£o foi enfileirada corretamente

**C√≥digo Suspeito (video-downloader/app/main.py):**
```python
@app.post("/jobs")
async def create_download_job(request: DownloadRequest, background_tasks: BackgroundTasks):
    job = VideoJob(...)
    redis_store.save_job(job)  # ‚úì Salva no Redis
    
    # ‚ùå SUSPEITA: Task Celery pode n√£o estar sendo enfileirada
    background_tasks.add_task(...)  # Usa FastAPI background, n√£o Celery?
    
    return {"job_id": job.id}
```

**Se usar FastAPI background_tasks ao inv√©s de Celery:**
- Task roda no processo do uvicorn
- Se uvicorn reiniciar, task √© perdida
- N√£o h√° persist√™ncia da tarefa

**Corre√ß√£o Necess√°ria:**
```python
from app.celery_tasks import process_download_task

@app.post("/jobs")
async def create_download_job(request: DownloadRequest):
    job = VideoJob(...)
    redis_store.save_job(job)
    
    # ‚úÖ Usar Celery para persist√™ncia
    process_download_task.apply_async(
        args=[job.id],
        queue='video_downloader_queue'
    )
    
    return {"job_id": job.id}
```

#### **H2: Polling travado sem atualizar progress** (15%)
**Evid√™ncia:**
- `_wait_until_done()` faz polling mas n√£o atualiza `stage.progress`
- Orchestrator pode estar travado no loop de polling

**Como Verificar:**
```python
# Adicionar logs detalhados no polling
async def _wait_until_done(self, client, job_id, stage):
    attempts = 0
    while attempts < self.max_attempts:
        logger.info(f"[POLL] Attempt {attempts}: job={job_id}, stage={stage.name}")  # ‚Üê ADD
        status = await client.get_job_status(job_id)
        logger.info(f"[POLL] Response: {status}")  # ‚Üê ADD
        # ...
```

#### **H3: Network timeout entre containers** (5%)
**Evid√™ncia:**
- Container orchestrator n√£o consegue conectar ao video-downloader
- Mas health check funciona (inconsist√™ncia)

**Como Verificar:**
```bash
# Testar conectividade entre containers
docker exec ytcaption-orchestrator ping ytcaption-video-downloader
docker exec ytcaption-orchestrator curl http://ytcaption-video-downloader:8000/health
```

#### **H4: Race condition no Redis** (5%)
**Evid√™ncia:**
- Job salvo mas imediatamente sobrescrito
- Orchestrator l√™ vers√£o desatualizada

**Como Verificar:**
```bash
# Monitorar opera√ß√µes Redis em tempo real
docker exec orchestrator-redis redis-cli MONITOR | grep "video_job"
```

**A√ß√µes Imediatas:**
1. ‚úÖ Adicionar logs verbosos no polling (`_wait_until_done`)
2. ‚úÖ Adicionar logs no endpoint `/jobs` dos microservi√ßos
3. ‚úÖ Verificar se Celery workers est√£o processando
4. ‚úÖ Verificar filas Celery com `celery inspect`
5. ‚úÖ Adicionar timeout expl√≠cito no polling (j√° existe: `max_poll_attempts`)

**Teste de Reprodu√ß√£o:**
```bash
# 1. Limpar tudo
POST /admin/factory-reset

# 2. Criar job
POST /process ‚Üí job_id

# 3. Monitorar em paralelo:
# Terminal 1: Logs orchestrator
docker logs -f ytcaption-orchestrator

# Terminal 2: Logs video-downloader
docker logs -f ytcaption-video-downloader

# Terminal 3: Logs Celery worker
docker logs -f ytcaption-video-downloader-celery

# Terminal 4: Filas Redis
watch -n 1 'redis-cli -n 0 LLEN video_downloader_queue'

# Terminal 5: Polling status
watch -n 2 'curl -s http://localhost:8004/jobs/{job_id} | jq .status'
```

---

## ‚ö†Ô∏è ALTOS (P1)

### 4. Circuit Breaker pode bloquear servi√ßos saud√°veis temporariamente
**Status:** DESIGN ISSUE üü°  
**Prioridade:** P1 (Alto)  
**Descri√ß√£o:** Circuit breaker abre ap√≥s 3 falhas consecutivas e bloqueia requisi√ß√µes por 60s, mesmo que o servi√ßo se recupere rapidamente.

**Cen√°rios Problem√°ticos:**
- Microservi√ßo reinicia (downtime de 5s)
- Circuit breaker detecta 3 falhas e abre
- Servi√ßo fica bloqueado por 60s mesmo estando saud√°vel

**Configura√ß√£o Atual:**
```python
# orchestrator/modules/config.py
"circuit_breaker_max_failures": 3,
"circuit_breaker_recovery_timeout": 60  # segundos
```

**Impacto:**
- Pipeline falha desnecessariamente
- Lat√™ncia adicional de at√© 60s

**Solu√ß√£o Proposta:**
1. Reduzir recovery_timeout para 15s
2. Implementar half-open state (permite 1 requisi√ß√£o teste)
3. Adicionar exponential backoff no recovery

```python
class MicroserviceClient:
    def _is_circuit_open(self) -> bool:
        if not self._circuit_open:
            return False
        
        # Half-open: Permite 1 teste ap√≥s timeout
        if datetime.now() - self.last_failure_time > timedelta(seconds=15):
            logger.info(f"[{self.service_name}] Circuit breaker HALF-OPEN - testing")
            return False  # Permite 1 requisi√ß√£o
        
        return True
```

---

### 5. Logs de erro HTTP n√£o incluem response body
**Status:** MELHORIA üü°  
**Prioridade:** P1 (Alto)  
**Descri√ß√£o:** Quando microservi√ßos retornam erro 4xx/5xx, apenas o status code √© logado, n√£o o corpo da resposta com detalhes do erro.

**C√≥digo Atual:**
```python
except httpx.HTTPStatusError as e:
    raise RuntimeError(f"[{self.service_name}] HTTP error: {e}")  # ‚ùå Sem detalhes
```

**Solu√ß√£o:**
```python
except httpx.HTTPStatusError as e:
    error_body = e.response.text if e.response else "No response body"
    logger.error(f"[{self.service_name}] HTTP {e.response.status_code}: {error_body}")
    raise RuntimeError(f"[{self.service_name}] HTTP {e.response.status_code}: {error_body}")
```

---

### 6. Max file size n√£o configur√°vel por microservi√ßo
**Status:** LIMITA√á√ÉO üü°  
**Prioridade:** P1 (Alto)  
**Descri√ß√£o:** Limite de tamanho de arquivo (`max_file_size_mb`) √© global para todos os servi√ßos, mas cada servi√ßo tem necessidades diferentes.

**Problema:**
- Video-downloader pode gerar arquivos grandes (500MB+)
- Audio-normalization recebe/gera arquivos menores (100MB t√≠pico)
- Transcriber precisa apenas do √°udio (50MB t√≠pico)

**Solu√ß√£o:**
```python
# config.py
"video-downloader": {
    "max_file_size_mb": 500,  # V√≠deos grandes
    ...
},
"audio-normalization": {
    "max_file_size_mb": 200,  # √Åudio normalizado
    ...
},
"audio-transcriber": {
    "max_file_size_mb": 100,  # √Åudio final
    ...
}
```

---

## üìã M√âDIOS (P2)

### 7. Polling interval fixo pode desperdi√ßar recursos
**Status:** OTIMIZA√á√ÉO üü¢  
**Prioridade:** P2 (M√©dio)  
**Descri√ß√£o:** Polling usa intervalo fixo de 2s independente do tipo de job (v√≠deo curto vs longo).

**Impacto:**
- Jobs r√°pidos (<1min): polling a cada 2s √© bom
- Jobs longos (>10min): polling a cada 2s desperdi√ßa requisi√ß√µes

**Solu√ß√£o Implementada (Parcial):**
```python
# Polling adaptativo j√° existe!
if attempts < 10:
    poll_delay = self.poll_interval_initial  # 2s
elif attempts < 50:
    poll_delay = min(self.poll_interval_initial * 2, self.poll_interval_max)  # 4s
else:
    poll_delay = self.poll_interval_max  # 5s
```

**Melhoria Adicional:**
- Usar WebSocket/SSE do microservi√ßo para push de atualiza√ß√µes
- Implementar long-polling no microservi√ßo

---

### 8. Falta tratamento de disco cheio
**Status:** EDGE CASE üü¢  
**Prioridade:** P2 (M√©dio)  
**Descri√ß√£o:** Se disco ficar cheio durante download/processamento, erro n√£o √© tratado graciosamente.

**Solu√ß√£o:**
```python
import shutil

def check_disk_space(path="/app/cache", required_mb=100):
    """Verifica espa√ßo em disco antes de processar"""
    stat = shutil.disk_usage(path)
    free_mb = stat.free / (1024 * 1024)
    if free_mb < required_mb:
        raise RuntimeError(f"Insufficient disk space: {free_mb:.0f}MB < {required_mb}MB required")
    return free_mb
```

---

### 9. Retry exponential backoff pode ser muito lento
**Status:** CONFIGURA√á√ÉO üü¢  
**Prioridade:** P2 (M√©dio)  
**Descri√ß√£o:** Backoff exponencial `2^attempt` pode resultar em delays muito longos (2s, 4s, 8s, 16s, 32s...).

**C√°lculo Atual (5 attempts):**
- Attempt 1: delay 2s
- Attempt 2: delay 4s  
- Attempt 3: delay 8s
- Attempt 4: delay 16s
- Total: ~30s at√© falhar

**Solu√ß√£o:**
```python
delay = min(self.retry_delay * (2 ** attempt), 10)  # Cap em 10s
```

---

## üîç OBSERVA√á√ïES

### Pontos Positivos do C√≥digo Atual:
‚úÖ Circuit breaker implementado  
‚úÖ Retry com exponential backoff  
‚úÖ Health checks  
‚úÖ Polling adaptativo  
‚úÖ Valida√ß√£o de tamanho de arquivo  
‚úÖ Logs estruturados  
‚úÖ Timeouts configur√°veis  
‚úÖ Separa√ß√£o de concerns (client, orchestrator, models)

### Pontos de Aten√ß√£o:
‚ö†Ô∏è Falta monitoramento de m√©tricas (Prometheus/Grafana)  
‚ö†Ô∏è Falta tracing distribu√≠do (OpenTelemetry)  
‚ö†Ô∏è Falta rate limiting  
‚ö†Ô∏è Falta autentica√ß√£o entre servi√ßos  
‚ö†Ô∏è Redis single point of failure (sem replica√ß√£o)

---

## üìä RESUMO POR PRIORIDADE

| Prioridade | Total | Resolvidos | Pendentes |
|------------|-------|------------|-----------|
| **P0 (Cr√≠tico)** | 3 | 1 ‚úÖ | 2 ‚ùå |
| **P1 (Alto)** | 3 | 0 | 3 üü° |
| **P2 (M√©dio)** | 3 | 0 | 3 üü¢ |
| **TOTAL** | **9** | **1** | **8** |

---

## üéØ PR√ìXIMOS PASSOS (Prioridade)

1. ‚ùå **URGENTE:** Corrigir factory reset para limpar filas Celery (#2)
2. ‚ùå **URGENTE:** Investigar e resolver jobs parados (#3)
   - Adicionar logs verbosos no polling
   - Verificar integra√ß√£o FastAPI/Celery
   - Monitorar filas Redis em tempo real
3. üü° Melhorar circuit breaker com half-open state (#4)
4. üü° Adicionar response body nos logs de erro HTTP (#5)
5. üü° Configurar max file size por servi√ßo (#6)

---

**√öltima Atualiza√ß√£o:** 2025-10-30 02:00 BRT  
**Respons√°vel:** GitHub Copilot + John Freitas  
**Vers√£o:** 1.0
